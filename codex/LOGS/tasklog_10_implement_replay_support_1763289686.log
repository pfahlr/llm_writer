OpenAI Codex v0.57.0 (research preview)
--------
workdir: /var/home/rick/Development/llm_writer
model: gpt-5-codex
provider: openai
approval: never
sandbox: workspace-write [workdir, /tmp, $TMPDIR]
reasoning effort: high
reasoning summaries: auto
session id: 019a8c41-614e-70f2-b7dd-c34a5a248518
--------
user
Implement the functionality described in codex/TASKS/10_implement_replay_support.yaml, then verify with any available tests.
ERROR: MCP client for `vibe-check-mcp-server` timed out after 10 seconds. Add or adjust `startup_timeout_sec` in your config.toml:
[mcp_servers.vibe-check-mcp-server]
startup_timeout_sec = XX
ERROR: MCP client for `context7-mcp` failed to start: handshaking with MCP server failed: connection closed: initialize response
ERROR: MCP client for `exa` failed to start: handshaking with MCP server failed: connection closed: initialize response
ERROR: MCP client for `mcp` failed to start: handshaking with MCP server failed: connection closed: initialize response

thinking
**Evaluating task complexity and planning steps**
exec
bash -lc ls in /var/home/rick/Development/llm_writer succeeded in 38ms:
AGENTS.md
codex
codex.toml
pyproject.toml
README.md
requirements.txt
src
tests
venv

thinking
**Opening task file**
exec
bash -lc 'ls codex/TASKS' in /var/home/rick/Development/llm_writer succeeded in 39ms:
01_bootstrap_project_and_cli.yaml
02_implement_config_models_and_loader.yaml
03_implement_model_registry_and_litellm_integration.yaml
04_define_task_spec_and_loader.yaml
05_implement_prompt_builders.yaml
06_implement_mcp_types_and_normalization.yaml
07_implement_automated_task_runner.yaml
08_implement_planning_log_writer.yaml
09_implement_planning_repl.yaml
10_implement_replay_support.yaml
11_implement_mcp_prompt_policy_modes.yaml
12_add_textual_source_browser_stub.yaml
CODEX_TODO.md
master_spec.yaml
work_list

thinking
**Reviewing next portion**
exec
bash -lc 'cat codex/TASKS/10_implement_replay_support.yaml' in /var/home/rick/Development/llm_writer succeeded in 38ms:
id: 10
filename: 10_implement_replay_support.yaml
title: Implement replay and prompt reconstruction from logs
description: >
  Implement basic replay functionality that can reconstruct a prompt for a
  given planning turn from a log file, and optionally run it through an LLM.

dependencies:
  - 08
  - 09

goals:
  - reconstruct_prompt_for_turn(log_path, turn_index) parses the log and
    builds a reasonable prompt representing that turn's context.
  - run_replay_prompt(registry, prompt, meta) runs the prompt through a model.

artifacts:
  - src/simple_rag_writer/replay/reconstruct.py
  - tests/test_replay_reconstruct.py


thinking
**Inspecting source structure**
exec
bash -lc 'ls src/simple_rag_writer' in /var/home/rick/Development/llm_writer succeeded in 40ms:
cli
config
__init__.py
llm
logging
mcp
planning
prompts
__pycache__
replay
runner
tasks

thinking
**Listing replay folder contents**
exec
bash -lc 'ls src/simple_rag_writer/replay' in /var/home/rick/Development/llm_writer succeeded in 41ms:
__init__.py
__pycache__
reconstruct.py

thinking
**Opening file for review**
exec
bash -lc "sed -n '1,160p' src/simple_rag_writer/replay/reconstruct.py" in /var/home/rick/Development/llm_writer succeeded in 38ms:
from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Tuple

from simple_rag_writer.llm.registry import ModelRegistry


@dataclass
class ReplayMeta:
  turn_index: int


def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
  """Very rough placeholder: returns full log as prompt."""
  text = log_path.read_text(encoding="utf-8")
  return text, ReplayMeta(turn_index=turn_index)



thinking
**Planning logging implementation**
exec
bash -lc 'rg -n "Turn" -n' in /var/home/rick/Development/llm_writer succeeded in 44ms:
tests/test_planning_log_writer.py:66:  assert "## Turn 1" in log_text
src/simple_rag_writer/logging/planning_log.py:90:    self._fh.write(f"## Turn {turn_index}\n\n")
codex/TASKS/10_implement_replay_support.yaml:23:    - Finds the target "## Turn N" section.
codex/LOGS/tasklog_10_implement_replay_support_1763289686.log:133:bash -lc 'rg -n "Turn" -n' in /var/home/rick/Development/llm_writer
src/simple_rag_writer/cli/replay.py:27:    console.rule(f"Reconstructed Prompt for Turn {turn_index}")
src/simple_rag_writer/cli/main.py:58:    help="Turn index (1-based) to reconstruct",
codex/LOGS/tasklog_08_implement_planning_log_writer_1763289052.log:453:  assert "## Turn 1" in log_text
codex/LOGS/tasklog_08_implement_planning_log_writer_1763289052.log:616:+  assert "## Turn 1" in log_text
codex/LOGS/tasklog_08_implement_planning_log_writer_1763289052.log:777:+  assert "## Turn 1" in log_text
codex/LOGS/tasklog_08_implement_planning_log_writer_1763289052.log:963:+  assert "## Turn 1" in log_text
codex/LOGS/tasklog_08_implement_planning_log_writer_1763289052.log:1149:+  assert "## Turn 1" in log_text
codex/LOGS/tasklog_08_implement_planning_log_writer_1763289052.log:1614:+  assert "## Turn 1" in log_text
codex/LOGS/tasklog_08_implement_planning_log_writer_1763289052.log:1937:+  assert "## Turn 1" in log_text
codex/LOGS/tasklog_08_implement_planning_log_writer_1763289052.log:2278:+  assert "## Turn 1" in log_text
codex/LOGS/tasklog_08_implement_planning_log_writer_1763289052.log:2625:+  assert "## Turn 1" in log_text
codex/LOGS/tasklog_08_implement_planning_log_writer_1763289052.log:2955:+  assert "## Turn 1" in log_text
codex/LOGS/tasklog_08_implement_planning_log_writer_1763289052.log:3303:+  assert "## Turn 1" in log_text
codex/LOGS/tasklog_08_implement_planning_log_writer_1763289052.log:3651:+  assert "## Turn 1" in log_text
codex/LOGS/tasklog_08_implement_planning_log_writer_1763289052.log:3999:+  assert "## Turn 1" in log_text
codex/LOGS/tasklog_08_implement_planning_log_writer_1763289052.log:4341:+  assert "## Turn 1" in log_text

thinking
**Inspecting planning log writer**
exec
bash -lc "sed -n '1,200p' src/simple_rag_writer/logging/planning_log.py" in /var/home/rick/Development/llm_writer succeeded in 40ms:
from __future__ import annotations

from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Set

import yaml

from simple_rag_writer.config.models import AppConfig


@dataclass
class McpLogItem:
  idx: int
  server: str
  tool: str
  label: Optional[str]
  normalized_id: Optional[str]
  title: Optional[str]

thinking
**Checking replay CLI availability**
exec
bash -lc "sed -n '1,200p' src/simple_rag_writer/cli/replay.py" in /var/home/rick/Development/llm_writer succeeded in 38ms:
from __future__ import annotations

from pathlib import Path

from rich.console import Console

from simple_rag_writer.config.models import AppConfig
from simple_rag_writer.llm.registry import ModelRegistry
from simple_rag_writer.replay.reconstruct import (
  reconstruct_prompt_for_turn,
  run_replay_prompt,
)

console = Console()


def run_replay_mode(
  config: AppConfig,
  log_path: Path,
  turn_index: int,

thinking
**Preparing to run tests**
exec
bash -lc 'ls tests' in /var/home/rick/Development/llm_writer succeeded in 40ms:
conftest.py
__pycache__
test_cli_parser.py
test_config_loader.py
test_llm_registry.py
test_mcp_normalization.py
test_planning_log_writer.py
test_planning_repl.py
test_prompt_building.py
test_runner_run_tasks.py
test_task_loading.py

thinking
**Preparing to write reconstruction tests**
exec
bash -lc "sed -n '660,760p' codex/TASKS/master_spec.yaml" in /var/home/rick/Development/llm_writer succeeded in 39ms:
            - close() to flush and close the file.
      config_dependencies:
        - logging.planning.enabled
        - logging.planning.dir
        - logging.planning.include_mcp_events
        - logging.planning.mcp_inline
      data_structures:
        - name: "McpLogItem"
          description: "Normalized representation of a single MCP result item for logging."
          fields:
            idx: int
            server: string
            tool: string
            label: string | null
            normalized_id: string | null
            title: string | null
            type: string | null
            snippet: string | null
            body: string | null
            url: string | null

thinking
**Searching master spec for replay section**
exec
bash -lc 'rg -n "replay" codex/TASKS/master_spec.yaml' in /var/home/rick/Development/llm_writer succeeded in 39ms:
9:    execution of YAML-described writing tasks into Markdown, and replay of
19:    - Support reproducible debugging via log replay.
110:  replay:
111:    id: replay
147:      - name: "replay"
743:      responsibility: "argparse-based CLI wiring; selects plan vs run vs replay; handles config path."
769:    - path: "simple_rag_writer/replay.py"
838:    replay_mode:
880:      support generic summarization/truncation, logging, and replay, while

thinking
**Reviewing lines from line 110**
exec
bash -lc "sed -n '110,240p' codex/TASKS/master_spec.yaml" in /var/home/rick/Development/llm_writer succeeded in 38ms:
  replay:
    id: replay
    description: >
      Reconstruct and optionally re-run the exact prompt used for a specific
      planning turn by reading a Markdown log file, including stored MCP
      reference payloads and model parameters.
    features:
      - Input: path to a planning log file and a turn index.
      - Reconstruct:
        - System prompt used for planning.
        - MCP context injected at that turn (from mcp-yaml block).
        - Recent conversation history window.
      - Output options:
        - Show reconstructed prompt as plain text / Markdown.
        - Optionally re-send the prompt to a chosen model for comparison.

cli:
  program_name: "srw"
  parser:
    uses_argparse: true

thinking
**Exploring replay feature requirements**
exec
bash -lc "sed -n '800,900p' codex/TASKS/master_spec.yaml" in /var/home/rick/Development/llm_writer succeeded in 38ms:
        - Parse CLI args; load AppConfig.
        - Expand any glob patterns into concrete task file paths.
        - Initialize ModelRegistry and McpClient.
        - For each task file:
          - Load TaskSpec from YAML.
          - Optional: load outline file and extract relevant snippet.
          - For each reference:
            - If type=url, create URL blob (optionally summarized via MCP later).
            - If type=mcp:
              - Call McpClient.call_tool(server, tool, params).
              - On MCP error:
                - If task.mcp_error_mode == "skip_with_warning":
                  - Log a warning via Rich and skip this reference.
                - If task.mcp_error_mode == "fail_task":
                  - Abort this task and report failure.
              - If successful:
                - Normalize results into a standard schema (id/title/snippet/body/url/metadata/type).
                  - Use ReferenceSpec.item_type as a hint for normalized.type if server
                    does not provide a type.
                - Apply MCP prompt policy:

thinking
**Investigating planning modules**
exec
bash -lc 'ls src/simple_rag_writer/planning' in /var/home/rick/Development/llm_writer succeeded in 38ms:
__init__.py
__pycache__
repl.py

thinking
**Opening repl.py file**
exec
bash -lc "sed -n '1,240p' src/simple_rag_writer/planning/repl.py" in /var/home/rick/Development/llm_writer succeeded in 38ms:
from __future__ import annotations

from typing import List, Optional, Tuple

from rich.console import Console
from rich.panel import Panel

from simple_rag_writer.config.models import AppConfig
from simple_rag_writer.llm.registry import ModelRegistry
from simple_rag_writer.logging.planning_log import PlanningLogWriter
from simple_rag_writer.prompts.planning import (
  DEFAULT_HISTORY_WINDOW,
  build_planning_prompt,
)

console = Console()
HISTORY_WINDOW = DEFAULT_HISTORY_WINDOW


class PlanningRepl:

thinking
**Opening planning prompt file**
exec
bash -lc "sed -n '1,240p' src/simple_rag_writer/prompts/planning.py" in /var/home/rick/Development/llm_writer succeeded in 38ms:
from __future__ import annotations

from typing import List, Optional, Tuple

DEFAULT_HISTORY_WINDOW = 5


def build_planning_prompt(
  history: List[Tuple[str, str]],
  user_message: str,
  mcp_context: Optional[str] = None,
  history_window: int = DEFAULT_HISTORY_WINDOW,
) -> str:
  """Build planning prompt from optional MCP context, recent history, and new user text."""
  window = max(history_window, 0)
  recent_history = history[-window:] if window else []

  parts: List[str] = [
    (
      "You are a planning assistant helping the user design and refine writing tasks.\n"

thinking
**Reviewing planning log writer tests**
exec
bash -lc "sed -n '1,200p' tests/test_planning_log_writer.py" in /var/home/rick/Development/llm_writer succeeded in 39ms:
from __future__ import annotations

from pathlib import Path

import yaml

from simple_rag_writer.config.models import (
  AppConfig,
  LoggingConfig,
  ModelConfig,
  PlanningLoggingConfig,
  ProviderConfig,
)
from simple_rag_writer.logging.planning_log import McpLogItem, PlanningLogWriter


def _make_config(
  tmp_path: Path,
  *,
  include_mcp_events: bool = True,

thinking
**Planning multi-step implementation**

I need to parse `ModelRegistry` and handle defaults like the history window, then focus on TDD by writing tests first. Since the implementation involves multiple tasks, I'll create a multi-step plan including analyzing the spec, designing tests, updating code, and running tests to keep things organized and effective.
Plan update
  → Read task spec and inspect existing replay/log structures to understand required behavior.
  • Add tests covering prompt reconstruction behavior for multi-turn logs.
  • Implement replay reconstruction and model run logic to satisfy tests, then run pytest.

thinking
**Planning tests for reconstruct_prompt_for_turn**
exec
bash -lc "sed -n '1,200p' src/simple_rag_writer/replay/__init__.py" in /var/home/rick/Development/llm_writer succeeded in 40ms:


thinking
**Planning log reconstruction approach**

I’m outlining how to parse the log file by splitting it into turns using the "## Turn" marker and extracting user, assistant, and optional MCP context from YAML code blocks. The specification hints at including prior turns and MCP data in the prompt, but the current implementation doesn’t yet inject MCP context, so I’ll handle it as optional and keep investigating how MCP is actually used elsewhere.
exec
bash -lc 'rg -n "mcp_context" -n src -g"*"' in /var/home/rick/Development/llm_writer succeeded in 44ms:
src/simple_rag_writer/prompts/planning.py:11:  mcp_context: Optional[str] = None,
src/simple_rag_writer/prompts/planning.py:25:  if mcp_context:
src/simple_rag_writer/prompts/planning.py:30:        mcp_context.strip(),
src/simple_rag_writer/planning/repl.py:31:    self._mcp_context: Optional[str] = None
src/simple_rag_writer/planning/repl.py:62:      prompt = build_planning_prompt(history_slice, line, self._mcp_context)

thinking
**Inspecting test expectations for prompt building**
exec
bash -lc "sed -n '1,200p' tests/test_planning_repl.py" in /var/home/rick/Development/llm_writer succeeded in 39ms:
from __future__ import annotations

from dataclasses import dataclass
from typing import List, Optional, Sequence, Tuple
from rich.panel import Panel

from simple_rag_writer.config.models import AppConfig, ModelConfig, ProviderConfig
from simple_rag_writer.planning import repl as repl_module
from simple_rag_writer.planning.repl import PlanningRepl


def _make_config() -> AppConfig:
  return AppConfig(
    default_model="writer",
    providers={"local": ProviderConfig(type="openai", api_key="dummy")},
    models=[
      ModelConfig(id="writer", provider="local", model_name="Writer Model"),
      ModelConfig(id="editor", provider="local", model_name="Editor Model"),
    ],
  )

thinking
**Inspecting ModelRegistry for reconstruction**
exec
bash -lc "sed -n '1,240p' src/simple_rag_writer/llm/registry.py" in /var/home/rick/Development/llm_writer succeeded in 39ms:
from __future__ import annotations

import os
from typing import Any, Dict, List, Optional

try:
  import litellm
except ImportError:  # pragma: no cover - only triggered when dependency missing
  litellm = None

from simple_rag_writer.config.models import AppConfig, ModelConfig, ProviderConfig
from .params import merge_generation_params


class ModelRegistry:
  def __init__(self, config: AppConfig):
    self._config = config
    self._models: Dict[str, ModelConfig] = {m.id: m for m in config.models}
    if config.default_model not in self._models:
      raise ValueError(f"default_model {config.default_model} not found in models")

thinking
**Considering prompt replay and reconstruction testing**
exec
bash -lc 'rg -n "ReplayMeta" -n' in /var/home/rick/Development/llm_writer succeeded in 47ms:
src/simple_rag_writer/replay/reconstruct.py:11:class ReplayMeta:
src/simple_rag_writer/replay/reconstruct.py:15:def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
src/simple_rag_writer/replay/reconstruct.py:18:  return text, ReplayMeta(turn_index=turn_index)
src/simple_rag_writer/replay/reconstruct.py:21:def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
codex/LOGS/tasklog_10_implement_replay_support_1763289686.log:119:class ReplayMeta:
codex/LOGS/tasklog_10_implement_replay_support_1763289686.log:123:def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
codex/LOGS/tasklog_10_implement_replay_support_1763289686.log:126:  return text, ReplayMeta(turn_index=turn_index)
codex/LOGS/tasklog_10_implement_replay_support_1763289686.log:473:bash -lc 'rg -n "ReplayMeta" -n' in /var/home/rick/Development/llm_writer
codex/LOGS/tasklog_07_implement_automated_task_runner_1763288534.log:305:src/simple_rag_writer/replay/reconstruct.py:15:def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
codex/LOGS/tasklog_07_implement_automated_task_runner_1763288534.log:307:src/simple_rag_writer/replay/reconstruct.py:21:def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:


thinking
**Designing prompt reconstruction and tests**
thinking
**Preparing prompt reconstruction tests**

I’m outlining tests to verify prompt rebuilding with and without MCP context, and to catch missing turns; I’ll craft sample logs with turns and YAML blocks, then assert prompts include user history, MCP references, and raise errors if turn absent.

thinking
**Correcting patch syntax**
file update
A /var/home/rick/Development/llm_writer/tests/test_replay_reconstruct.py
from __future__ import annotations

from pathlib import Path
from textwrap import dedent

import pytest

from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn


def _write_log(tmp_path: Path, text: str) -> Path:
  path = tmp_path / "plan-log.md"
  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
  return path


def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
  log_path = _write_log(
    tmp_path,
    """
    # Planning Session — 2024-05-01
    - Config: config.yaml
    - Default model: writer
    - Models used: writer

    ## Turn 1

    **User:**

    Need help outlining the chapter.

    **Assistant:**

    Start by listing sections and transitions.

    ## Turn 2

    **User:**

    Can you expand the outline with more details?

    **Assistant:**

    Let's add bullet points per section.
    """,
  )

  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)

  assert "You are a planning assistant" in prompt
  assert "User: Need help outlining the chapter." in prompt
  assert "Assistant: Start by listing sections and transitions." in prompt
  assert prompt.strip().endswith("Can you expand the outline with more details?")
  assert meta.turn_index == 2
  assert meta.user_text == "Can you expand the outline with more details?"
  assert meta.history_turns == (1,)


def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
  log_path = _write_log(
    tmp_path,
    """
    # Planning Session — 2024-05-01
    - Config: config.yaml
    - Default model: writer
    - Models used: writer

    ## Turn 1

    **User:**

    Summarize new notes.

    **Assistant:**

    Sure thing.

    ## Turn 2

    **User:**

    Use the MCP references from earlier.

    ### MCP References Injected

    | idx | server | tool | label | normalized_id | title |
    | --- | ------ | ---- | ----- | ------------- | ----- |
    | 1 | notes | search | Spec | notes#1 | Outline draft |

    ```mcp-yaml
    references:
      - idx: 1
        server: notes
        tool: search
        label: Spec
        normalized_id: notes#1
        title: Outline draft
        snippet: First few lines
        body: Full body text
      - idx: 2
        server: notes
        tool: search
        label: Plan
        normalized_id: notes#2
        title: Planning memo
        snippet: Another snippet
        body: Another body text
    ```

    **Assistant:**

    Injected the MCP references.
    """,
  )

  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)

  assert "## Context from external sources" in prompt
  assert "references:" in prompt
  assert "title: Outline draft" in prompt
  assert meta.mcp_reference_count == 2


def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
  log_path = _write_log(
    tmp_path,
    """
    # Planning Session — 2024-05-01
    - Config: config.yaml
    - Default model: writer
    - Models used: writer

    ## Turn 1

    **User:**

    Hello

    **Assistant:**

    Hi
    """,
  )

  with pytest.raises(ValueError):
    reconstruct_prompt_for_turn(log_path, 3)
apply_patch(auto_approved=true) exited 0 in 5ms:
Success. Updated the following files:
A tests/test_replay_reconstruct.py
file update:
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)

file update:
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)


thinking
**Updating plan progress**
Plan update
  ✓ Read task spec and inspect existing replay/log structures to understand required behavior.
  → Add tests covering prompt reconstruction behavior for multi-turn logs.
  • Implement replay reconstruction and model run logic to satisfy tests, then run pytest.
file update:
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)


thinking
**Preparing to run targeted tests**
exec
bash -lc 'pytest tests/test_replay_reconstruct.py' in /var/home/rick/Development/llm_writer exited 1 in 13.25s:
============================= test session starts ==============================
platform linux -- Python 3.13.9, pytest-8.4.2, pluggy-1.6.0
rootdir: /var/home/rick/Development/llm_writer
configfile: pyproject.toml
plugins: Faker-37.8.0, xdist-3.8.0, mock-3.15.1, metadata-3.1.1, cov-7.0.0, asyncio-1.2.0, html-4.1.1, hypothesis-6.141.1, anyio-4.8.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collected 3 items

tests/test_replay_reconstruct.py FFF                                     [100%]

=================================== FAILURES ===================================
____________ test_reconstruct_prompt_includes_previous_turn_context ____________

tmp_path = PosixPath('/tmp/pytest-of-rick/pytest-19/test_reconstruct_prompt_includ0')

    def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
      log_path = _write_log(
        tmp_path,
        """
        # Planning Session — 2024-05-01
file update:
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)


thinking
**Updating plan after test failure**
Plan update
  ✓ Read task spec and inspect existing replay/log structures to understand required behavior.
  ✓ Add tests covering prompt reconstruction behavior for multi-turn logs.
  → Implement replay reconstruction and model run logic to satisfy tests, then run pytest.
file update:
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)


thinking
**Starting implementation in reconstruct.py**
exec
bash -lc "sed -n '1,200p' src/simple_rag_writer/replay/reconstruct.py" in /var/home/rick/Development/llm_writer succeeded in 40ms:
from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Tuple

from simple_rag_writer.llm.registry import ModelRegistry


@dataclass
class ReplayMeta:
  turn_index: int


def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
  """Very rough placeholder: returns full log as prompt."""
  text = log_path.read_text(encoding="utf-8")
  return text, ReplayMeta(turn_index=turn_index)


file update:
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)


thinking
**Planning comprehensive replay prompt update**

I’m laying out a detailed plan to enhance replay prompt reconstruction by defining new dataclasses, parsing turn logs thoroughly, normalizing mcp YAML with error handling, and computing history and metadata with type hints and proper imports. I’m preparing helper functions to handle parsing, finalizing turns, and counting MCP references to ensure robust context reconstruction.
file update
M /var/home/rick/Development/llm_writer/src/simple_rag_writer/replay/reconstruct.py
@@ -4,5 +4,8 @@
 from pathlib import Path
-from typing import Tuple
+from typing import List, Optional, Tuple
 
+import yaml
+
 from simple_rag_writer.llm.registry import ModelRegistry
+from simple_rag_writer.prompts.planning import DEFAULT_HISTORY_WINDOW, build_planning_prompt
 
@@ -12,11 +15,133 @@
   turn_index: int
+  user_text: str
+  history_turns: Tuple[int, ...]
+  mcp_reference_count: int = 0
 
 
+@dataclass
+class _TurnRecord:
+  index: int
+  user_text: str
+  assistant_text: str
+  mcp_yaml: Optional[str] = None
+
+
 def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
-  """Very rough placeholder: returns full log as prompt."""
-  text = log_path.read_text(encoding="utf-8")
-  return text, ReplayMeta(turn_index=turn_index)
+  if turn_index < 1:
+    raise ValueError("turn_index must be >= 1")
 
+  turns = _parse_turns(log_path.read_text(encoding="utf-8"))
+  if not turns:
+    raise ValueError("No turns found in log")
 
+  target = next((t for t in turns if t.index == turn_index), None)
+  if target is None:
+    raise ValueError(f"Turn {turn_index} not found in log")
+
+  prior_turns = [t for t in turns if t.index < turn_index]
+  history_slice = prior_turns[-DEFAULT_HISTORY_WINDOW:]
+  history_pairs = [(t.user_text, t.assistant_text) for t in history_slice]
+  mcp_context, reference_count = _prepare_mcp_context(target.mcp_yaml)
+
+  prompt = build_planning_prompt(history_pairs, target.user_text, mcp_context)
+  meta = ReplayMeta(
+    turn_index=turn_index,
+    user_text=target.user_text,
+    history_turns=tuple(t.index for t in history_slice),
+    mcp_reference_count=reference_count,
+  )
+  return prompt, meta
+
+
 def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
   return registry.complete(prompt)
+
+
+def _parse_turns(text: str) -> List[_TurnRecord]:
+  turns: List[_TurnRecord] = []
+  current: Optional[dict] = None
+  block: Optional[str] = None
+  in_fence = False
+
+  def finalize() -> None:
+    nonlocal current
+    if not current:
+      return
+    turns.append(
+      _TurnRecord(
+        index=current["index"],
+        user_text="\n".join(current["user"]).strip(),
+        assistant_text="\n".join(current["assistant"]).strip(),
+        mcp_yaml="\n".join(current["mcp"]).strip() or None,
+      )
+    )
+    current = None
+
+  for line in text.splitlines():
+    if line.startswith("## Turn "):
+      finalize()
+      index_text = line[len("## Turn ") :].strip()
+      try:
+        idx = int(index_text)
+      except ValueError:
+        continue
+      current = {"index": idx, "user": [], "assistant": [], "mcp": []}
+      block = None
+      in_fence = False
+      continue
+
+    if current is None:
+      continue
+
+    stripped = line.strip()
+    if stripped.startswith("**User:**"):
+      block = "user"
+      continue
+    if stripped.startswith("**Assistant:**"):
+      block = "assistant"
+      continue
+    if stripped.startswith("```mcp-yaml"):
+      block = "mcp"
+      in_fence = True
+      continue
+    if in_fence and stripped.startswith("```"):
+      in_fence = False
+      block = None
+      continue
+
+    if block == "mcp" and in_fence:
+      current["mcp"].append(line)
+      continue
+    if block == "user":
+      current["user"].append(line)
+      continue
+    if block == "assistant":
+      current["assistant"].append(line)
+      continue
+
+  finalize()
+  return turns
+
+
+def _prepare_mcp_context(mcp_yaml: Optional[str]) -> Tuple[Optional[str], int]:
+  if not mcp_yaml:
+    return None, 0
+
+  raw = mcp_yaml.strip()
+  if not raw:
+    return None, 0
+
+  try:
+    payload = yaml.safe_load(raw)
+  except yaml.YAMLError:
+    return raw, 0
+
+  normalized = yaml.safe_dump(payload, sort_keys=False).strip()
+  ref_count = 0
+  if isinstance(payload, dict):
+    references = payload.get("references")
+    if isinstance(references, list):
+      ref_count = len(references)
+
+  context_text = normalized or raw
+  return context_text, ref_count
apply_patch(auto_approved=true) exited 0 in 7.37s:
Success. Updated the following files:
M src/simple_rag_writer/replay/reconstruct.py
file update:
diff --git a/src/simple_rag_writer/replay/reconstruct.py b/src/simple_rag_writer/replay/reconstruct.py
index 544bfab7edf7ea5ed426c0c72c20ed533294c73c..d3a0e168ad8d8de5b50113f6f86bb86fb32a401a
--- a/src/simple_rag_writer/replay/reconstruct.py
+++ b/src/simple_rag_writer/replay/reconstruct.py
@@ -2,21 +2,146 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import Tuple
+from typing import List, Optional, Tuple
 
+import yaml
+
 from simple_rag_writer.llm.registry import ModelRegistry
+from simple_rag_writer.prompts.planning import DEFAULT_HISTORY_WINDOW, build_planning_prompt
 
 
 @dataclass
 class ReplayMeta:
   turn_index: int
+  user_text: str
+  history_turns: Tuple[int, ...]
+  mcp_reference_count: int = 0
 
 
+@dataclass
+class _TurnRecord:
+  index: int
+  user_text: str
+  assistant_text: str
+  mcp_yaml: Optional[str] = None
+
+
 def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
-  """Very rough placeholder: returns full log as prompt."""
-  text = log_path.read_text(encoding="utf-8")
-  return text, ReplayMeta(turn_index=turn_index)
+  if turn_index < 1:
+    raise ValueError("turn_index must be >= 1")
 
+  turns = _parse_turns(log_path.read_text(encoding="utf-8"))
+  if not turns:
+    raise ValueError("No turns found in log")
 
+  target = next((t for t in turns if t.index == turn_index), None)
+  if target is None:
+    raise ValueError(f"Turn {turn_index} not found in log")
+
+  prior_turns = [t for t in turns if t.index < turn_index]
+  history_slice = prior_turns[-DEFAULT_HISTORY_WINDOW:]
+  history_pairs = [(t.user_text, t.assistant_text) for t in history_slice]
+  mcp_context, reference_count = _prepare_mcp_context(target.mcp_yaml)
+
+  prompt = build_planning_prompt(history_pairs, target.user_text, mcp_context)
+  meta = ReplayMeta(
+    turn_index=turn_index,
+    user_text=target.user_text,
+    history_turns=tuple(t.index for t in history_slice),
+    mcp_reference_count=reference_count,
+  )
+  return prompt, meta
+
+
 def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
   return registry.complete(prompt)
+
+
+def _parse_turns(text: str) -> List[_TurnRecord]:
+  turns: List[_TurnRecord] = []
+  current: Optional[dict] = None
+  block: Optional[str] = None
+  in_fence = False
+
+  def finalize() -> None:
+    nonlocal current
+    if not current:
+      return
+    turns.append(
+      _TurnRecord(
+        index=current["index"],
+        user_text="\n".join(current["user"]).strip(),
+        assistant_text="\n".join(current["assistant"]).strip(),
+        mcp_yaml="\n".join(current["mcp"]).strip() or None,
+      )
+    )
+    current = None
+
+  for line in text.splitlines():
+    if line.startswith("## Turn "):
+      finalize()
+      index_text = line[len("## Turn ") :].strip()
+      try:
+        idx = int(index_text)
+      except ValueError:
+        continue
+      current = {"index": idx, "user": [], "assistant": [], "mcp": []}
+      block = None
+      in_fence = False
+      continue
+
+    if current is None:
+      continue
+
+    stripped = line.strip()
+    if stripped.startswith("**User:**"):
+      block = "user"
+      continue
+    if stripped.startswith("**Assistant:**"):
+      block = "assistant"
+      continue
+    if stripped.startswith("```mcp-yaml"):
+      block = "mcp"
+      in_fence = True
+      continue
+    if in_fence and stripped.startswith("```"):
+      in_fence = False
+      block = None
+      continue
+
+    if block == "mcp" and in_fence:
+      current["mcp"].append(line)
+      continue
+    if block == "user":
+      current["user"].append(line)
+      continue
+    if block == "assistant":
+      current["assistant"].append(line)
+      continue
+
+  finalize()
+  return turns
+
+
+def _prepare_mcp_context(mcp_yaml: Optional[str]) -> Tuple[Optional[str], int]:
+  if not mcp_yaml:
+    return None, 0
+
+  raw = mcp_yaml.strip()
+  if not raw:
+    return None, 0
+
+  try:
+    payload = yaml.safe_load(raw)
+  except yaml.YAMLError:
+    return raw, 0
+
+  normalized = yaml.safe_dump(payload, sort_keys=False).strip()
+  ref_count = 0
+  if isinstance(payload, dict):
+    references = payload.get("references")
+    if isinstance(references, list):
+      ref_count = len(references)
+
+  context_text = normalized or raw
+  return context_text, ref_count
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)

file update:
diff --git a/src/simple_rag_writer/replay/reconstruct.py b/src/simple_rag_writer/replay/reconstruct.py
index 544bfab7edf7ea5ed426c0c72c20ed533294c73c..d3a0e168ad8d8de5b50113f6f86bb86fb32a401a
--- a/src/simple_rag_writer/replay/reconstruct.py
+++ b/src/simple_rag_writer/replay/reconstruct.py
@@ -2,21 +2,146 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import Tuple
+from typing import List, Optional, Tuple
 
+import yaml
+
 from simple_rag_writer.llm.registry import ModelRegistry
+from simple_rag_writer.prompts.planning import DEFAULT_HISTORY_WINDOW, build_planning_prompt
 
 
 @dataclass
 class ReplayMeta:
   turn_index: int
+  user_text: str
+  history_turns: Tuple[int, ...]
+  mcp_reference_count: int = 0
 
 
+@dataclass
+class _TurnRecord:
+  index: int
+  user_text: str
+  assistant_text: str
+  mcp_yaml: Optional[str] = None
+
+
 def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
-  """Very rough placeholder: returns full log as prompt."""
-  text = log_path.read_text(encoding="utf-8")
-  return text, ReplayMeta(turn_index=turn_index)
+  if turn_index < 1:
+    raise ValueError("turn_index must be >= 1")
 
+  turns = _parse_turns(log_path.read_text(encoding="utf-8"))
+  if not turns:
+    raise ValueError("No turns found in log")
 
+  target = next((t for t in turns if t.index == turn_index), None)
+  if target is None:
+    raise ValueError(f"Turn {turn_index} not found in log")
+
+  prior_turns = [t for t in turns if t.index < turn_index]
+  history_slice = prior_turns[-DEFAULT_HISTORY_WINDOW:]
+  history_pairs = [(t.user_text, t.assistant_text) for t in history_slice]
+  mcp_context, reference_count = _prepare_mcp_context(target.mcp_yaml)
+
+  prompt = build_planning_prompt(history_pairs, target.user_text, mcp_context)
+  meta = ReplayMeta(
+    turn_index=turn_index,
+    user_text=target.user_text,
+    history_turns=tuple(t.index for t in history_slice),
+    mcp_reference_count=reference_count,
+  )
+  return prompt, meta
+
+
 def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
   return registry.complete(prompt)
+
+
+def _parse_turns(text: str) -> List[_TurnRecord]:
+  turns: List[_TurnRecord] = []
+  current: Optional[dict] = None
+  block: Optional[str] = None
+  in_fence = False
+
+  def finalize() -> None:
+    nonlocal current
+    if not current:
+      return
+    turns.append(
+      _TurnRecord(
+        index=current["index"],
+        user_text="\n".join(current["user"]).strip(),
+        assistant_text="\n".join(current["assistant"]).strip(),
+        mcp_yaml="\n".join(current["mcp"]).strip() or None,
+      )
+    )
+    current = None
+
+  for line in text.splitlines():
+    if line.startswith("## Turn "):
+      finalize()
+      index_text = line[len("## Turn ") :].strip()
+      try:
+        idx = int(index_text)
+      except ValueError:
+        continue
+      current = {"index": idx, "user": [], "assistant": [], "mcp": []}
+      block = None
+      in_fence = False
+      continue
+
+    if current is None:
+      continue
+
+    stripped = line.strip()
+    if stripped.startswith("**User:**"):
+      block = "user"
+      continue
+    if stripped.startswith("**Assistant:**"):
+      block = "assistant"
+      continue
+    if stripped.startswith("```mcp-yaml"):
+      block = "mcp"
+      in_fence = True
+      continue
+    if in_fence and stripped.startswith("```"):
+      in_fence = False
+      block = None
+      continue
+
+    if block == "mcp" and in_fence:
+      current["mcp"].append(line)
+      continue
+    if block == "user":
+      current["user"].append(line)
+      continue
+    if block == "assistant":
+      current["assistant"].append(line)
+      continue
+
+  finalize()
+  return turns
+
+
+def _prepare_mcp_context(mcp_yaml: Optional[str]) -> Tuple[Optional[str], int]:
+  if not mcp_yaml:
+    return None, 0
+
+  raw = mcp_yaml.strip()
+  if not raw:
+    return None, 0
+
+  try:
+    payload = yaml.safe_load(raw)
+  except yaml.YAMLError:
+    return raw, 0
+
+  normalized = yaml.safe_dump(payload, sort_keys=False).strip()
+  ref_count = 0
+  if isinstance(payload, dict):
+    references = payload.get("references")
+    if isinstance(references, list):
+      ref_count = len(references)
+
+  context_text = normalized or raw
+  return context_text, ref_count
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)


thinking
**Improving context parsing and validation**
file update
M /var/home/rick/Development/llm_writer/src/simple_rag_writer/replay/reconstruct.py
@@ -145,3 +145,5 @@
 
-  context_text = normalized or raw
+  context_text = (normalized or raw).strip()
+  if not context_text:
+    return None, ref_count
   return context_text, ref_count
apply_patch(auto_approved=true) exited 0 in 4ms:
Success. Updated the following files:
M src/simple_rag_writer/replay/reconstruct.py
file update:
diff --git a/src/simple_rag_writer/replay/reconstruct.py b/src/simple_rag_writer/replay/reconstruct.py
index 544bfab7edf7ea5ed426c0c72c20ed533294c73c..ad10264e14f131f7475afd7c259d1478a1a2596b
--- a/src/simple_rag_writer/replay/reconstruct.py
+++ b/src/simple_rag_writer/replay/reconstruct.py
@@ -2,21 +2,148 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import Tuple
+from typing import List, Optional, Tuple
 
+import yaml
+
 from simple_rag_writer.llm.registry import ModelRegistry
+from simple_rag_writer.prompts.planning import DEFAULT_HISTORY_WINDOW, build_planning_prompt
 
 
 @dataclass
 class ReplayMeta:
   turn_index: int
+  user_text: str
+  history_turns: Tuple[int, ...]
+  mcp_reference_count: int = 0
 
 
+@dataclass
+class _TurnRecord:
+  index: int
+  user_text: str
+  assistant_text: str
+  mcp_yaml: Optional[str] = None
+
+
 def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
-  """Very rough placeholder: returns full log as prompt."""
-  text = log_path.read_text(encoding="utf-8")
-  return text, ReplayMeta(turn_index=turn_index)
+  if turn_index < 1:
+    raise ValueError("turn_index must be >= 1")
+
+  turns = _parse_turns(log_path.read_text(encoding="utf-8"))
+  if not turns:
+    raise ValueError("No turns found in log")
+
+  target = next((t for t in turns if t.index == turn_index), None)
+  if target is None:
+    raise ValueError(f"Turn {turn_index} not found in log")
+
+  prior_turns = [t for t in turns if t.index < turn_index]
+  history_slice = prior_turns[-DEFAULT_HISTORY_WINDOW:]
+  history_pairs = [(t.user_text, t.assistant_text) for t in history_slice]
+  mcp_context, reference_count = _prepare_mcp_context(target.mcp_yaml)
+
+  prompt = build_planning_prompt(history_pairs, target.user_text, mcp_context)
+  meta = ReplayMeta(
+    turn_index=turn_index,
+    user_text=target.user_text,
+    history_turns=tuple(t.index for t in history_slice),
+    mcp_reference_count=reference_count,
+  )
+  return prompt, meta
 
 
 def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
   return registry.complete(prompt)
+
+
+def _parse_turns(text: str) -> List[_TurnRecord]:
+  turns: List[_TurnRecord] = []
+  current: Optional[dict] = None
+  block: Optional[str] = None
+  in_fence = False
+
+  def finalize() -> None:
+    nonlocal current
+    if not current:
+      return
+    turns.append(
+      _TurnRecord(
+        index=current["index"],
+        user_text="\n".join(current["user"]).strip(),
+        assistant_text="\n".join(current["assistant"]).strip(),
+        mcp_yaml="\n".join(current["mcp"]).strip() or None,
+      )
+    )
+    current = None
+
+  for line in text.splitlines():
+    if line.startswith("## Turn "):
+      finalize()
+      index_text = line[len("## Turn ") :].strip()
+      try:
+        idx = int(index_text)
+      except ValueError:
+        continue
+      current = {"index": idx, "user": [], "assistant": [], "mcp": []}
+      block = None
+      in_fence = False
+      continue
+
+    if current is None:
+      continue
+
+    stripped = line.strip()
+    if stripped.startswith("**User:**"):
+      block = "user"
+      continue
+    if stripped.startswith("**Assistant:**"):
+      block = "assistant"
+      continue
+    if stripped.startswith("```mcp-yaml"):
+      block = "mcp"
+      in_fence = True
+      continue
+    if in_fence and stripped.startswith("```"):
+      in_fence = False
+      block = None
+      continue
+
+    if block == "mcp" and in_fence:
+      current["mcp"].append(line)
+      continue
+    if block == "user":
+      current["user"].append(line)
+      continue
+    if block == "assistant":
+      current["assistant"].append(line)
+      continue
+
+  finalize()
+  return turns
+
+
+def _prepare_mcp_context(mcp_yaml: Optional[str]) -> Tuple[Optional[str], int]:
+  if not mcp_yaml:
+    return None, 0
+
+  raw = mcp_yaml.strip()
+  if not raw:
+    return None, 0
+
+  try:
+    payload = yaml.safe_load(raw)
+  except yaml.YAMLError:
+    return raw, 0
+
+  normalized = yaml.safe_dump(payload, sort_keys=False).strip()
+  ref_count = 0
+  if isinstance(payload, dict):
+    references = payload.get("references")
+    if isinstance(references, list):
+      ref_count = len(references)
+
+  context_text = (normalized or raw).strip()
+  if not context_text:
+    return None, ref_count
+  return context_text, ref_count
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)

file update:
diff --git a/src/simple_rag_writer/replay/reconstruct.py b/src/simple_rag_writer/replay/reconstruct.py
index 544bfab7edf7ea5ed426c0c72c20ed533294c73c..ad10264e14f131f7475afd7c259d1478a1a2596b
--- a/src/simple_rag_writer/replay/reconstruct.py
+++ b/src/simple_rag_writer/replay/reconstruct.py
@@ -2,21 +2,148 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import Tuple
+from typing import List, Optional, Tuple
 
+import yaml
+
 from simple_rag_writer.llm.registry import ModelRegistry
+from simple_rag_writer.prompts.planning import DEFAULT_HISTORY_WINDOW, build_planning_prompt
 
 
 @dataclass
 class ReplayMeta:
   turn_index: int
+  user_text: str
+  history_turns: Tuple[int, ...]
+  mcp_reference_count: int = 0
 
 
+@dataclass
+class _TurnRecord:
+  index: int
+  user_text: str
+  assistant_text: str
+  mcp_yaml: Optional[str] = None
+
+
 def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
-  """Very rough placeholder: returns full log as prompt."""
-  text = log_path.read_text(encoding="utf-8")
-  return text, ReplayMeta(turn_index=turn_index)
+  if turn_index < 1:
+    raise ValueError("turn_index must be >= 1")
+
+  turns = _parse_turns(log_path.read_text(encoding="utf-8"))
+  if not turns:
+    raise ValueError("No turns found in log")
+
+  target = next((t for t in turns if t.index == turn_index), None)
+  if target is None:
+    raise ValueError(f"Turn {turn_index} not found in log")
+
+  prior_turns = [t for t in turns if t.index < turn_index]
+  history_slice = prior_turns[-DEFAULT_HISTORY_WINDOW:]
+  history_pairs = [(t.user_text, t.assistant_text) for t in history_slice]
+  mcp_context, reference_count = _prepare_mcp_context(target.mcp_yaml)
+
+  prompt = build_planning_prompt(history_pairs, target.user_text, mcp_context)
+  meta = ReplayMeta(
+    turn_index=turn_index,
+    user_text=target.user_text,
+    history_turns=tuple(t.index for t in history_slice),
+    mcp_reference_count=reference_count,
+  )
+  return prompt, meta
 
 
 def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
   return registry.complete(prompt)
+
+
+def _parse_turns(text: str) -> List[_TurnRecord]:
+  turns: List[_TurnRecord] = []
+  current: Optional[dict] = None
+  block: Optional[str] = None
+  in_fence = False
+
+  def finalize() -> None:
+    nonlocal current
+    if not current:
+      return
+    turns.append(
+      _TurnRecord(
+        index=current["index"],
+        user_text="\n".join(current["user"]).strip(),
+        assistant_text="\n".join(current["assistant"]).strip(),
+        mcp_yaml="\n".join(current["mcp"]).strip() or None,
+      )
+    )
+    current = None
+
+  for line in text.splitlines():
+    if line.startswith("## Turn "):
+      finalize()
+      index_text = line[len("## Turn ") :].strip()
+      try:
+        idx = int(index_text)
+      except ValueError:
+        continue
+      current = {"index": idx, "user": [], "assistant": [], "mcp": []}
+      block = None
+      in_fence = False
+      continue
+
+    if current is None:
+      continue
+
+    stripped = line.strip()
+    if stripped.startswith("**User:**"):
+      block = "user"
+      continue
+    if stripped.startswith("**Assistant:**"):
+      block = "assistant"
+      continue
+    if stripped.startswith("```mcp-yaml"):
+      block = "mcp"
+      in_fence = True
+      continue
+    if in_fence and stripped.startswith("```"):
+      in_fence = False
+      block = None
+      continue
+
+    if block == "mcp" and in_fence:
+      current["mcp"].append(line)
+      continue
+    if block == "user":
+      current["user"].append(line)
+      continue
+    if block == "assistant":
+      current["assistant"].append(line)
+      continue
+
+  finalize()
+  return turns
+
+
+def _prepare_mcp_context(mcp_yaml: Optional[str]) -> Tuple[Optional[str], int]:
+  if not mcp_yaml:
+    return None, 0
+
+  raw = mcp_yaml.strip()
+  if not raw:
+    return None, 0
+
+  try:
+    payload = yaml.safe_load(raw)
+  except yaml.YAMLError:
+    return raw, 0
+
+  normalized = yaml.safe_dump(payload, sort_keys=False).strip()
+  ref_count = 0
+  if isinstance(payload, dict):
+    references = payload.get("references")
+    if isinstance(references, list):
+      ref_count = len(references)
+
+  context_text = (normalized or raw).strip()
+  if not context_text:
+    return None, ref_count
+  return context_text, ref_count
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)


thinking
**Enhancing turn parsing robustness**
file update
M /var/home/rick/Development/llm_writer/src/simple_rag_writer/replay/reconstruct.py
@@ -80,5 +80,6 @@
   for line in text.splitlines():
-    if line.startswith("## Turn "):
+    stripped = line.strip()
+    if stripped.startswith("## Turn "):
       finalize()
-      index_text = line[len("## Turn ") :].strip()
+      index_text = stripped[len("## Turn ") :].strip()
       try:
@@ -95,3 +96,2 @@
 
-    stripped = line.strip()
     if stripped.startswith("**User:**"):
apply_patch(auto_approved=true) exited 0 in 6ms:
Success. Updated the following files:
M src/simple_rag_writer/replay/reconstruct.py
file update:
diff --git a/src/simple_rag_writer/replay/reconstruct.py b/src/simple_rag_writer/replay/reconstruct.py
index 544bfab7edf7ea5ed426c0c72c20ed533294c73c..5671929685d1d38a2620362fb2009d4d87a9b96c
--- a/src/simple_rag_writer/replay/reconstruct.py
+++ b/src/simple_rag_writer/replay/reconstruct.py
@@ -2,21 +2,148 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import Tuple
+from typing import List, Optional, Tuple
 
+import yaml
+
 from simple_rag_writer.llm.registry import ModelRegistry
+from simple_rag_writer.prompts.planning import DEFAULT_HISTORY_WINDOW, build_planning_prompt
 
 
 @dataclass
 class ReplayMeta:
   turn_index: int
+  user_text: str
+  history_turns: Tuple[int, ...]
+  mcp_reference_count: int = 0
 
 
+@dataclass
+class _TurnRecord:
+  index: int
+  user_text: str
+  assistant_text: str
+  mcp_yaml: Optional[str] = None
+
+
 def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
-  """Very rough placeholder: returns full log as prompt."""
-  text = log_path.read_text(encoding="utf-8")
-  return text, ReplayMeta(turn_index=turn_index)
+  if turn_index < 1:
+    raise ValueError("turn_index must be >= 1")
+
+  turns = _parse_turns(log_path.read_text(encoding="utf-8"))
+  if not turns:
+    raise ValueError("No turns found in log")
+
+  target = next((t for t in turns if t.index == turn_index), None)
+  if target is None:
+    raise ValueError(f"Turn {turn_index} not found in log")
+
+  prior_turns = [t for t in turns if t.index < turn_index]
+  history_slice = prior_turns[-DEFAULT_HISTORY_WINDOW:]
+  history_pairs = [(t.user_text, t.assistant_text) for t in history_slice]
+  mcp_context, reference_count = _prepare_mcp_context(target.mcp_yaml)
+
+  prompt = build_planning_prompt(history_pairs, target.user_text, mcp_context)
+  meta = ReplayMeta(
+    turn_index=turn_index,
+    user_text=target.user_text,
+    history_turns=tuple(t.index for t in history_slice),
+    mcp_reference_count=reference_count,
+  )
+  return prompt, meta
 
 
 def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
   return registry.complete(prompt)
+
+
+def _parse_turns(text: str) -> List[_TurnRecord]:
+  turns: List[_TurnRecord] = []
+  current: Optional[dict] = None
+  block: Optional[str] = None
+  in_fence = False
+
+  def finalize() -> None:
+    nonlocal current
+    if not current:
+      return
+    turns.append(
+      _TurnRecord(
+        index=current["index"],
+        user_text="\n".join(current["user"]).strip(),
+        assistant_text="\n".join(current["assistant"]).strip(),
+        mcp_yaml="\n".join(current["mcp"]).strip() or None,
+      )
+    )
+    current = None
+
+  for line in text.splitlines():
+    stripped = line.strip()
+    if stripped.startswith("## Turn "):
+      finalize()
+      index_text = stripped[len("## Turn ") :].strip()
+      try:
+        idx = int(index_text)
+      except ValueError:
+        continue
+      current = {"index": idx, "user": [], "assistant": [], "mcp": []}
+      block = None
+      in_fence = False
+      continue
+
+    if current is None:
+      continue
+
+    if stripped.startswith("**User:**"):
+      block = "user"
+      continue
+    if stripped.startswith("**Assistant:**"):
+      block = "assistant"
+      continue
+    if stripped.startswith("```mcp-yaml"):
+      block = "mcp"
+      in_fence = True
+      continue
+    if in_fence and stripped.startswith("```"):
+      in_fence = False
+      block = None
+      continue
+
+    if block == "mcp" and in_fence:
+      current["mcp"].append(line)
+      continue
+    if block == "user":
+      current["user"].append(line)
+      continue
+    if block == "assistant":
+      current["assistant"].append(line)
+      continue
+
+  finalize()
+  return turns
+
+
+def _prepare_mcp_context(mcp_yaml: Optional[str]) -> Tuple[Optional[str], int]:
+  if not mcp_yaml:
+    return None, 0
+
+  raw = mcp_yaml.strip()
+  if not raw:
+    return None, 0
+
+  try:
+    payload = yaml.safe_load(raw)
+  except yaml.YAMLError:
+    return raw, 0
+
+  normalized = yaml.safe_dump(payload, sort_keys=False).strip()
+  ref_count = 0
+  if isinstance(payload, dict):
+    references = payload.get("references")
+    if isinstance(references, list):
+      ref_count = len(references)
+
+  context_text = (normalized or raw).strip()
+  if not context_text:
+    return None, ref_count
+  return context_text, ref_count
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)

file update:
diff --git a/src/simple_rag_writer/replay/reconstruct.py b/src/simple_rag_writer/replay/reconstruct.py
index 544bfab7edf7ea5ed426c0c72c20ed533294c73c..5671929685d1d38a2620362fb2009d4d87a9b96c
--- a/src/simple_rag_writer/replay/reconstruct.py
+++ b/src/simple_rag_writer/replay/reconstruct.py
@@ -2,21 +2,148 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import Tuple
+from typing import List, Optional, Tuple
 
+import yaml
+
 from simple_rag_writer.llm.registry import ModelRegistry
+from simple_rag_writer.prompts.planning import DEFAULT_HISTORY_WINDOW, build_planning_prompt
 
 
 @dataclass
 class ReplayMeta:
   turn_index: int
+  user_text: str
+  history_turns: Tuple[int, ...]
+  mcp_reference_count: int = 0
 
 
+@dataclass
+class _TurnRecord:
+  index: int
+  user_text: str
+  assistant_text: str
+  mcp_yaml: Optional[str] = None
+
+
 def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
-  """Very rough placeholder: returns full log as prompt."""
-  text = log_path.read_text(encoding="utf-8")
-  return text, ReplayMeta(turn_index=turn_index)
+  if turn_index < 1:
+    raise ValueError("turn_index must be >= 1")
+
+  turns = _parse_turns(log_path.read_text(encoding="utf-8"))
+  if not turns:
+    raise ValueError("No turns found in log")
+
+  target = next((t for t in turns if t.index == turn_index), None)
+  if target is None:
+    raise ValueError(f"Turn {turn_index} not found in log")
+
+  prior_turns = [t for t in turns if t.index < turn_index]
+  history_slice = prior_turns[-DEFAULT_HISTORY_WINDOW:]
+  history_pairs = [(t.user_text, t.assistant_text) for t in history_slice]
+  mcp_context, reference_count = _prepare_mcp_context(target.mcp_yaml)
+
+  prompt = build_planning_prompt(history_pairs, target.user_text, mcp_context)
+  meta = ReplayMeta(
+    turn_index=turn_index,
+    user_text=target.user_text,
+    history_turns=tuple(t.index for t in history_slice),
+    mcp_reference_count=reference_count,
+  )
+  return prompt, meta
 
 
 def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
   return registry.complete(prompt)
+
+
+def _parse_turns(text: str) -> List[_TurnRecord]:
+  turns: List[_TurnRecord] = []
+  current: Optional[dict] = None
+  block: Optional[str] = None
+  in_fence = False
+
+  def finalize() -> None:
+    nonlocal current
+    if not current:
+      return
+    turns.append(
+      _TurnRecord(
+        index=current["index"],
+        user_text="\n".join(current["user"]).strip(),
+        assistant_text="\n".join(current["assistant"]).strip(),
+        mcp_yaml="\n".join(current["mcp"]).strip() or None,
+      )
+    )
+    current = None
+
+  for line in text.splitlines():
+    stripped = line.strip()
+    if stripped.startswith("## Turn "):
+      finalize()
+      index_text = stripped[len("## Turn ") :].strip()
+      try:
+        idx = int(index_text)
+      except ValueError:
+        continue
+      current = {"index": idx, "user": [], "assistant": [], "mcp": []}
+      block = None
+      in_fence = False
+      continue
+
+    if current is None:
+      continue
+
+    if stripped.startswith("**User:**"):
+      block = "user"
+      continue
+    if stripped.startswith("**Assistant:**"):
+      block = "assistant"
+      continue
+    if stripped.startswith("```mcp-yaml"):
+      block = "mcp"
+      in_fence = True
+      continue
+    if in_fence and stripped.startswith("```"):
+      in_fence = False
+      block = None
+      continue
+
+    if block == "mcp" and in_fence:
+      current["mcp"].append(line)
+      continue
+    if block == "user":
+      current["user"].append(line)
+      continue
+    if block == "assistant":
+      current["assistant"].append(line)
+      continue
+
+  finalize()
+  return turns
+
+
+def _prepare_mcp_context(mcp_yaml: Optional[str]) -> Tuple[Optional[str], int]:
+  if not mcp_yaml:
+    return None, 0
+
+  raw = mcp_yaml.strip()
+  if not raw:
+    return None, 0
+
+  try:
+    payload = yaml.safe_load(raw)
+  except yaml.YAMLError:
+    return raw, 0
+
+  normalized = yaml.safe_dump(payload, sort_keys=False).strip()
+  ref_count = 0
+  if isinstance(payload, dict):
+    references = payload.get("references")
+    if isinstance(references, list):
+      ref_count = len(references)
+
+  context_text = (normalized or raw).strip()
+  if not context_text:
+    return None, ref_count
+  return context_text, ref_count
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)



thinking
**Reviewing parsing edge cases for logs**
thinking
**Finalizing MCP section parsing logic**

I’m working out how to properly exit the MCP section state after finishing the code block and ensuring lines like tables or blank ones aren’t mistakenly parsed as user or assistant text. I’m also checking edge cases like missing code blocks or partial logs to keep parsing robust.
file update
M /var/home/rick/Development/llm_writer/src/simple_rag_writer/replay/reconstruct.py
@@ -45,3 +45,8 @@
 
-  prompt = build_planning_prompt(history_pairs, target.user_text, mcp_context)
+  prompt = build_planning_prompt(
+    history_pairs,
+    target.user_text,
+    mcp_context,
+    history_window=DEFAULT_HISTORY_WINDOW,
+  )
   meta = ReplayMeta(
@@ -64,2 +69,3 @@
   in_fence = False
+  in_mcp_section = False
 
@@ -102,2 +108,6 @@
       continue
+    if stripped.startswith("### MCP References Injected"):
+      block = None
+      in_mcp_section = True
+      continue
     if stripped.startswith("```mcp-yaml"):
@@ -109,2 +119,3 @@
       block = None
+      in_mcp_section = False
       continue
@@ -121,2 +132,5 @@
 
+    if in_mcp_section:
+      continue
+
   finalize()
apply_patch(auto_approved=true) exited 0 in 6ms:
Success. Updated the following files:
M src/simple_rag_writer/replay/reconstruct.py
file update:
diff --git a/src/simple_rag_writer/replay/reconstruct.py b/src/simple_rag_writer/replay/reconstruct.py
index 544bfab7edf7ea5ed426c0c72c20ed533294c73c..a08773dc8d33fd788e04aa9592ae0d3f030c1a80
--- a/src/simple_rag_writer/replay/reconstruct.py
+++ b/src/simple_rag_writer/replay/reconstruct.py
@@ -2,21 +2,162 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import Tuple
+from typing import List, Optional, Tuple
 
+import yaml
+
 from simple_rag_writer.llm.registry import ModelRegistry
+from simple_rag_writer.prompts.planning import DEFAULT_HISTORY_WINDOW, build_planning_prompt
 
 
 @dataclass
 class ReplayMeta:
   turn_index: int
+  user_text: str
+  history_turns: Tuple[int, ...]
+  mcp_reference_count: int = 0
 
 
+@dataclass
+class _TurnRecord:
+  index: int
+  user_text: str
+  assistant_text: str
+  mcp_yaml: Optional[str] = None
+
+
 def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
-  """Very rough placeholder: returns full log as prompt."""
-  text = log_path.read_text(encoding="utf-8")
-  return text, ReplayMeta(turn_index=turn_index)
+  if turn_index < 1:
+    raise ValueError("turn_index must be >= 1")
+
+  turns = _parse_turns(log_path.read_text(encoding="utf-8"))
+  if not turns:
+    raise ValueError("No turns found in log")
 
+  target = next((t for t in turns if t.index == turn_index), None)
+  if target is None:
+    raise ValueError(f"Turn {turn_index} not found in log")
 
+  prior_turns = [t for t in turns if t.index < turn_index]
+  history_slice = prior_turns[-DEFAULT_HISTORY_WINDOW:]
+  history_pairs = [(t.user_text, t.assistant_text) for t in history_slice]
+  mcp_context, reference_count = _prepare_mcp_context(target.mcp_yaml)
+
+  prompt = build_planning_prompt(
+    history_pairs,
+    target.user_text,
+    mcp_context,
+    history_window=DEFAULT_HISTORY_WINDOW,
+  )
+  meta = ReplayMeta(
+    turn_index=turn_index,
+    user_text=target.user_text,
+    history_turns=tuple(t.index for t in history_slice),
+    mcp_reference_count=reference_count,
+  )
+  return prompt, meta
+
+
 def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
   return registry.complete(prompt)
+
+
+def _parse_turns(text: str) -> List[_TurnRecord]:
+  turns: List[_TurnRecord] = []
+  current: Optional[dict] = None
+  block: Optional[str] = None
+  in_fence = False
+  in_mcp_section = False
+
+  def finalize() -> None:
+    nonlocal current
+    if not current:
+      return
+    turns.append(
+      _TurnRecord(
+        index=current["index"],
+        user_text="\n".join(current["user"]).strip(),
+        assistant_text="\n".join(current["assistant"]).strip(),
+        mcp_yaml="\n".join(current["mcp"]).strip() or None,
+      )
+    )
+    current = None
+
+  for line in text.splitlines():
+    stripped = line.strip()
+    if stripped.startswith("## Turn "):
+      finalize()
+      index_text = stripped[len("## Turn ") :].strip()
+      try:
+        idx = int(index_text)
+      except ValueError:
+        continue
+      current = {"index": idx, "user": [], "assistant": [], "mcp": []}
+      block = None
+      in_fence = False
+      continue
+
+    if current is None:
+      continue
+
+    if stripped.startswith("**User:**"):
+      block = "user"
+      continue
+    if stripped.startswith("**Assistant:**"):
+      block = "assistant"
+      continue
+    if stripped.startswith("### MCP References Injected"):
+      block = None
+      in_mcp_section = True
+      continue
+    if stripped.startswith("```mcp-yaml"):
+      block = "mcp"
+      in_fence = True
+      continue
+    if in_fence and stripped.startswith("```"):
+      in_fence = False
+      block = None
+      in_mcp_section = False
+      continue
+
+    if block == "mcp" and in_fence:
+      current["mcp"].append(line)
+      continue
+    if block == "user":
+      current["user"].append(line)
+      continue
+    if block == "assistant":
+      current["assistant"].append(line)
+      continue
+
+    if in_mcp_section:
+      continue
+
+  finalize()
+  return turns
+
+
+def _prepare_mcp_context(mcp_yaml: Optional[str]) -> Tuple[Optional[str], int]:
+  if not mcp_yaml:
+    return None, 0
+
+  raw = mcp_yaml.strip()
+  if not raw:
+    return None, 0
+
+  try:
+    payload = yaml.safe_load(raw)
+  except yaml.YAMLError:
+    return raw, 0
+
+  normalized = yaml.safe_dump(payload, sort_keys=False).strip()
+  ref_count = 0
+  if isinstance(payload, dict):
+    references = payload.get("references")
+    if isinstance(references, list):
+      ref_count = len(references)
+
+  context_text = (normalized or raw).strip()
+  if not context_text:
+    return None, ref_count
+  return context_text, ref_count
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)

file update:
diff --git a/src/simple_rag_writer/replay/reconstruct.py b/src/simple_rag_writer/replay/reconstruct.py
index 544bfab7edf7ea5ed426c0c72c20ed533294c73c..a08773dc8d33fd788e04aa9592ae0d3f030c1a80
--- a/src/simple_rag_writer/replay/reconstruct.py
+++ b/src/simple_rag_writer/replay/reconstruct.py
@@ -2,21 +2,162 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import Tuple
+from typing import List, Optional, Tuple
 
+import yaml
+
 from simple_rag_writer.llm.registry import ModelRegistry
+from simple_rag_writer.prompts.planning import DEFAULT_HISTORY_WINDOW, build_planning_prompt
 
 
 @dataclass
 class ReplayMeta:
   turn_index: int
+  user_text: str
+  history_turns: Tuple[int, ...]
+  mcp_reference_count: int = 0
 
 
+@dataclass
+class _TurnRecord:
+  index: int
+  user_text: str
+  assistant_text: str
+  mcp_yaml: Optional[str] = None
+
+
 def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
-  """Very rough placeholder: returns full log as prompt."""
-  text = log_path.read_text(encoding="utf-8")
-  return text, ReplayMeta(turn_index=turn_index)
+  if turn_index < 1:
+    raise ValueError("turn_index must be >= 1")
+
+  turns = _parse_turns(log_path.read_text(encoding="utf-8"))
+  if not turns:
+    raise ValueError("No turns found in log")
 
+  target = next((t for t in turns if t.index == turn_index), None)
+  if target is None:
+    raise ValueError(f"Turn {turn_index} not found in log")
 
+  prior_turns = [t for t in turns if t.index < turn_index]
+  history_slice = prior_turns[-DEFAULT_HISTORY_WINDOW:]
+  history_pairs = [(t.user_text, t.assistant_text) for t in history_slice]
+  mcp_context, reference_count = _prepare_mcp_context(target.mcp_yaml)
+
+  prompt = build_planning_prompt(
+    history_pairs,
+    target.user_text,
+    mcp_context,
+    history_window=DEFAULT_HISTORY_WINDOW,
+  )
+  meta = ReplayMeta(
+    turn_index=turn_index,
+    user_text=target.user_text,
+    history_turns=tuple(t.index for t in history_slice),
+    mcp_reference_count=reference_count,
+  )
+  return prompt, meta
+
+
 def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
   return registry.complete(prompt)
+
+
+def _parse_turns(text: str) -> List[_TurnRecord]:
+  turns: List[_TurnRecord] = []
+  current: Optional[dict] = None
+  block: Optional[str] = None
+  in_fence = False
+  in_mcp_section = False
+
+  def finalize() -> None:
+    nonlocal current
+    if not current:
+      return
+    turns.append(
+      _TurnRecord(
+        index=current["index"],
+        user_text="\n".join(current["user"]).strip(),
+        assistant_text="\n".join(current["assistant"]).strip(),
+        mcp_yaml="\n".join(current["mcp"]).strip() or None,
+      )
+    )
+    current = None
+
+  for line in text.splitlines():
+    stripped = line.strip()
+    if stripped.startswith("## Turn "):
+      finalize()
+      index_text = stripped[len("## Turn ") :].strip()
+      try:
+        idx = int(index_text)
+      except ValueError:
+        continue
+      current = {"index": idx, "user": [], "assistant": [], "mcp": []}
+      block = None
+      in_fence = False
+      continue
+
+    if current is None:
+      continue
+
+    if stripped.startswith("**User:**"):
+      block = "user"
+      continue
+    if stripped.startswith("**Assistant:**"):
+      block = "assistant"
+      continue
+    if stripped.startswith("### MCP References Injected"):
+      block = None
+      in_mcp_section = True
+      continue
+    if stripped.startswith("```mcp-yaml"):
+      block = "mcp"
+      in_fence = True
+      continue
+    if in_fence and stripped.startswith("```"):
+      in_fence = False
+      block = None
+      in_mcp_section = False
+      continue
+
+    if block == "mcp" and in_fence:
+      current["mcp"].append(line)
+      continue
+    if block == "user":
+      current["user"].append(line)
+      continue
+    if block == "assistant":
+      current["assistant"].append(line)
+      continue
+
+    if in_mcp_section:
+      continue
+
+  finalize()
+  return turns
+
+
+def _prepare_mcp_context(mcp_yaml: Optional[str]) -> Tuple[Optional[str], int]:
+  if not mcp_yaml:
+    return None, 0
+
+  raw = mcp_yaml.strip()
+  if not raw:
+    return None, 0
+
+  try:
+    payload = yaml.safe_load(raw)
+  except yaml.YAMLError:
+    return raw, 0
+
+  normalized = yaml.safe_dump(payload, sort_keys=False).strip()
+  ref_count = 0
+  if isinstance(payload, dict):
+    references = payload.get("references")
+    if isinstance(references, list):
+      ref_count = len(references)
+
+  context_text = (normalized or raw).strip()
+  if not context_text:
+    return None, ref_count
+  return context_text, ref_count
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)


thinking
**Adjusting MCP section state handling**
file update
M /var/home/rick/Development/llm_writer/src/simple_rag_writer/replay/reconstruct.py
@@ -97,2 +97,3 @@
       in_fence = False
+      in_mcp_section = False
       continue
@@ -108,3 +109,3 @@
       continue
-    if stripped.startswith("### MCP References Injected"):
+    if stripped == "### MCP References Injected":
       block = None
apply_patch(auto_approved=true) exited 0 in 6ms:
Success. Updated the following files:
M src/simple_rag_writer/replay/reconstruct.py
file update:
diff --git a/src/simple_rag_writer/replay/reconstruct.py b/src/simple_rag_writer/replay/reconstruct.py
index 544bfab7edf7ea5ed426c0c72c20ed533294c73c..d51ee022bf4568d6484a427a9b466bc248959087
--- a/src/simple_rag_writer/replay/reconstruct.py
+++ b/src/simple_rag_writer/replay/reconstruct.py
@@ -2,21 +2,163 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import Tuple
+from typing import List, Optional, Tuple
 
+import yaml
+
 from simple_rag_writer.llm.registry import ModelRegistry
+from simple_rag_writer.prompts.planning import DEFAULT_HISTORY_WINDOW, build_planning_prompt
 
 
 @dataclass
 class ReplayMeta:
   turn_index: int
+  user_text: str
+  history_turns: Tuple[int, ...]
+  mcp_reference_count: int = 0
 
 
+@dataclass
+class _TurnRecord:
+  index: int
+  user_text: str
+  assistant_text: str
+  mcp_yaml: Optional[str] = None
+
+
 def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
-  """Very rough placeholder: returns full log as prompt."""
-  text = log_path.read_text(encoding="utf-8")
-  return text, ReplayMeta(turn_index=turn_index)
+  if turn_index < 1:
+    raise ValueError("turn_index must be >= 1")
+
+  turns = _parse_turns(log_path.read_text(encoding="utf-8"))
+  if not turns:
+    raise ValueError("No turns found in log")
 
+  target = next((t for t in turns if t.index == turn_index), None)
+  if target is None:
+    raise ValueError(f"Turn {turn_index} not found in log")
 
+  prior_turns = [t for t in turns if t.index < turn_index]
+  history_slice = prior_turns[-DEFAULT_HISTORY_WINDOW:]
+  history_pairs = [(t.user_text, t.assistant_text) for t in history_slice]
+  mcp_context, reference_count = _prepare_mcp_context(target.mcp_yaml)
+
+  prompt = build_planning_prompt(
+    history_pairs,
+    target.user_text,
+    mcp_context,
+    history_window=DEFAULT_HISTORY_WINDOW,
+  )
+  meta = ReplayMeta(
+    turn_index=turn_index,
+    user_text=target.user_text,
+    history_turns=tuple(t.index for t in history_slice),
+    mcp_reference_count=reference_count,
+  )
+  return prompt, meta
+
+
 def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
   return registry.complete(prompt)
+
+
+def _parse_turns(text: str) -> List[_TurnRecord]:
+  turns: List[_TurnRecord] = []
+  current: Optional[dict] = None
+  block: Optional[str] = None
+  in_fence = False
+  in_mcp_section = False
+
+  def finalize() -> None:
+    nonlocal current
+    if not current:
+      return
+    turns.append(
+      _TurnRecord(
+        index=current["index"],
+        user_text="\n".join(current["user"]).strip(),
+        assistant_text="\n".join(current["assistant"]).strip(),
+        mcp_yaml="\n".join(current["mcp"]).strip() or None,
+      )
+    )
+    current = None
+
+  for line in text.splitlines():
+    stripped = line.strip()
+    if stripped.startswith("## Turn "):
+      finalize()
+      index_text = stripped[len("## Turn ") :].strip()
+      try:
+        idx = int(index_text)
+      except ValueError:
+        continue
+      current = {"index": idx, "user": [], "assistant": [], "mcp": []}
+      block = None
+      in_fence = False
+      in_mcp_section = False
+      continue
+
+    if current is None:
+      continue
+
+    if stripped.startswith("**User:**"):
+      block = "user"
+      continue
+    if stripped.startswith("**Assistant:**"):
+      block = "assistant"
+      continue
+    if stripped == "### MCP References Injected":
+      block = None
+      in_mcp_section = True
+      continue
+    if stripped.startswith("```mcp-yaml"):
+      block = "mcp"
+      in_fence = True
+      continue
+    if in_fence and stripped.startswith("```"):
+      in_fence = False
+      block = None
+      in_mcp_section = False
+      continue
+
+    if block == "mcp" and in_fence:
+      current["mcp"].append(line)
+      continue
+    if block == "user":
+      current["user"].append(line)
+      continue
+    if block == "assistant":
+      current["assistant"].append(line)
+      continue
+
+    if in_mcp_section:
+      continue
+
+  finalize()
+  return turns
+
+
+def _prepare_mcp_context(mcp_yaml: Optional[str]) -> Tuple[Optional[str], int]:
+  if not mcp_yaml:
+    return None, 0
+
+  raw = mcp_yaml.strip()
+  if not raw:
+    return None, 0
+
+  try:
+    payload = yaml.safe_load(raw)
+  except yaml.YAMLError:
+    return raw, 0
+
+  normalized = yaml.safe_dump(payload, sort_keys=False).strip()
+  ref_count = 0
+  if isinstance(payload, dict):
+    references = payload.get("references")
+    if isinstance(references, list):
+      ref_count = len(references)
+
+  context_text = (normalized or raw).strip()
+  if not context_text:
+    return None, ref_count
+  return context_text, ref_count
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)

file update:
diff --git a/src/simple_rag_writer/replay/reconstruct.py b/src/simple_rag_writer/replay/reconstruct.py
index 544bfab7edf7ea5ed426c0c72c20ed533294c73c..d51ee022bf4568d6484a427a9b466bc248959087
--- a/src/simple_rag_writer/replay/reconstruct.py
+++ b/src/simple_rag_writer/replay/reconstruct.py
@@ -2,21 +2,163 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import Tuple
+from typing import List, Optional, Tuple
 
+import yaml
+
 from simple_rag_writer.llm.registry import ModelRegistry
+from simple_rag_writer.prompts.planning import DEFAULT_HISTORY_WINDOW, build_planning_prompt
 
 
 @dataclass
 class ReplayMeta:
   turn_index: int
+  user_text: str
+  history_turns: Tuple[int, ...]
+  mcp_reference_count: int = 0
 
 
+@dataclass
+class _TurnRecord:
+  index: int
+  user_text: str
+  assistant_text: str
+  mcp_yaml: Optional[str] = None
+
+
 def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
-  """Very rough placeholder: returns full log as prompt."""
-  text = log_path.read_text(encoding="utf-8")
-  return text, ReplayMeta(turn_index=turn_index)
+  if turn_index < 1:
+    raise ValueError("turn_index must be >= 1")
+
+  turns = _parse_turns(log_path.read_text(encoding="utf-8"))
+  if not turns:
+    raise ValueError("No turns found in log")
 
+  target = next((t for t in turns if t.index == turn_index), None)
+  if target is None:
+    raise ValueError(f"Turn {turn_index} not found in log")
 
+  prior_turns = [t for t in turns if t.index < turn_index]
+  history_slice = prior_turns[-DEFAULT_HISTORY_WINDOW:]
+  history_pairs = [(t.user_text, t.assistant_text) for t in history_slice]
+  mcp_context, reference_count = _prepare_mcp_context(target.mcp_yaml)
+
+  prompt = build_planning_prompt(
+    history_pairs,
+    target.user_text,
+    mcp_context,
+    history_window=DEFAULT_HISTORY_WINDOW,
+  )
+  meta = ReplayMeta(
+    turn_index=turn_index,
+    user_text=target.user_text,
+    history_turns=tuple(t.index for t in history_slice),
+    mcp_reference_count=reference_count,
+  )
+  return prompt, meta
+
+
 def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
   return registry.complete(prompt)
+
+
+def _parse_turns(text: str) -> List[_TurnRecord]:
+  turns: List[_TurnRecord] = []
+  current: Optional[dict] = None
+  block: Optional[str] = None
+  in_fence = False
+  in_mcp_section = False
+
+  def finalize() -> None:
+    nonlocal current
+    if not current:
+      return
+    turns.append(
+      _TurnRecord(
+        index=current["index"],
+        user_text="\n".join(current["user"]).strip(),
+        assistant_text="\n".join(current["assistant"]).strip(),
+        mcp_yaml="\n".join(current["mcp"]).strip() or None,
+      )
+    )
+    current = None
+
+  for line in text.splitlines():
+    stripped = line.strip()
+    if stripped.startswith("## Turn "):
+      finalize()
+      index_text = stripped[len("## Turn ") :].strip()
+      try:
+        idx = int(index_text)
+      except ValueError:
+        continue
+      current = {"index": idx, "user": [], "assistant": [], "mcp": []}
+      block = None
+      in_fence = False
+      in_mcp_section = False
+      continue
+
+    if current is None:
+      continue
+
+    if stripped.startswith("**User:**"):
+      block = "user"
+      continue
+    if stripped.startswith("**Assistant:**"):
+      block = "assistant"
+      continue
+    if stripped == "### MCP References Injected":
+      block = None
+      in_mcp_section = True
+      continue
+    if stripped.startswith("```mcp-yaml"):
+      block = "mcp"
+      in_fence = True
+      continue
+    if in_fence and stripped.startswith("```"):
+      in_fence = False
+      block = None
+      in_mcp_section = False
+      continue
+
+    if block == "mcp" and in_fence:
+      current["mcp"].append(line)
+      continue
+    if block == "user":
+      current["user"].append(line)
+      continue
+    if block == "assistant":
+      current["assistant"].append(line)
+      continue
+
+    if in_mcp_section:
+      continue
+
+  finalize()
+  return turns
+
+
+def _prepare_mcp_context(mcp_yaml: Optional[str]) -> Tuple[Optional[str], int]:
+  if not mcp_yaml:
+    return None, 0
+
+  raw = mcp_yaml.strip()
+  if not raw:
+    return None, 0
+
+  try:
+    payload = yaml.safe_load(raw)
+  except yaml.YAMLError:
+    return raw, 0
+
+  normalized = yaml.safe_dump(payload, sort_keys=False).strip()
+  ref_count = 0
+  if isinstance(payload, dict):
+    references = payload.get("references")
+    if isinstance(references, list):
+      ref_count = len(references)
+
+  context_text = (normalized or raw).strip()
+  if not context_text:
+    return None, ref_count
+  return context_text, ref_count
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)


thinking
**Verifying parsing and import details**
exec
bash -lc 'pytest tests/test_replay_reconstruct.py' in /var/home/rick/Development/llm_writer succeeded in 4.65s:
============================= test session starts ==============================
platform linux -- Python 3.13.9, pytest-8.4.2, pluggy-1.6.0
rootdir: /var/home/rick/Development/llm_writer
configfile: pyproject.toml
plugins: Faker-37.8.0, xdist-3.8.0, mock-3.15.1, metadata-3.1.1, cov-7.0.0, asyncio-1.2.0, html-4.1.1, hypothesis-6.141.1, anyio-4.8.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collected 3 items

tests/test_replay_reconstruct.py ...                                     [100%]

============================== 3 passed in 3.81s ===============================
file update:
diff --git a/src/simple_rag_writer/replay/reconstruct.py b/src/simple_rag_writer/replay/reconstruct.py
index 544bfab7edf7ea5ed426c0c72c20ed533294c73c..d51ee022bf4568d6484a427a9b466bc248959087
--- a/src/simple_rag_writer/replay/reconstruct.py
+++ b/src/simple_rag_writer/replay/reconstruct.py
@@ -2,21 +2,163 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import Tuple
+from typing import List, Optional, Tuple
 
+import yaml
+
 from simple_rag_writer.llm.registry import ModelRegistry
+from simple_rag_writer.prompts.planning import DEFAULT_HISTORY_WINDOW, build_planning_prompt
 
 
 @dataclass
 class ReplayMeta:
   turn_index: int
+  user_text: str
+  history_turns: Tuple[int, ...]
+  mcp_reference_count: int = 0
 
 
+@dataclass
+class _TurnRecord:
+  index: int
+  user_text: str
+  assistant_text: str
+  mcp_yaml: Optional[str] = None
+
+
 def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
-  """Very rough placeholder: returns full log as prompt."""
-  text = log_path.read_text(encoding="utf-8")
-  return text, ReplayMeta(turn_index=turn_index)
+  if turn_index < 1:
+    raise ValueError("turn_index must be >= 1")
+
+  turns = _parse_turns(log_path.read_text(encoding="utf-8"))
+  if not turns:
+    raise ValueError("No turns found in log")
 
+  target = next((t for t in turns if t.index == turn_index), None)
+  if target is None:
+    raise ValueError(f"Turn {turn_index} not found in log")
 
+  prior_turns = [t for t in turns if t.index < turn_index]
+  history_slice = prior_turns[-DEFAULT_HISTORY_WINDOW:]
+  history_pairs = [(t.user_text, t.assistant_text) for t in history_slice]
+  mcp_context, reference_count = _prepare_mcp_context(target.mcp_yaml)
+
+  prompt = build_planning_prompt(
+    history_pairs,
+    target.user_text,
+    mcp_context,
+    history_window=DEFAULT_HISTORY_WINDOW,
+  )
+  meta = ReplayMeta(
+    turn_index=turn_index,
+    user_text=target.user_text,
+    history_turns=tuple(t.index for t in history_slice),
+    mcp_reference_count=reference_count,
+  )
+  return prompt, meta
+
+
 def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
   return registry.complete(prompt)
+
+
+def _parse_turns(text: str) -> List[_TurnRecord]:
+  turns: List[_TurnRecord] = []
+  current: Optional[dict] = None
+  block: Optional[str] = None
+  in_fence = False
+  in_mcp_section = False
+
+  def finalize() -> None:
+    nonlocal current
+    if not current:
+      return
+    turns.append(
+      _TurnRecord(
+        index=current["index"],
+        user_text="\n".join(current["user"]).strip(),
+        assistant_text="\n".join(current["assistant"]).strip(),
+        mcp_yaml="\n".join(current["mcp"]).strip() or None,
+      )
+    )
+    current = None
+
+  for line in text.splitlines():
+    stripped = line.strip()
+    if stripped.startswith("## Turn "):
+      finalize()
+      index_text = stripped[len("## Turn ") :].strip()
+      try:
+        idx = int(index_text)
+      except ValueError:
+        continue
+      current = {"index": idx, "user": [], "assistant": [], "mcp": []}
+      block = None
+      in_fence = False
+      in_mcp_section = False
+      continue
+
+    if current is None:
+      continue
+
+    if stripped.startswith("**User:**"):
+      block = "user"
+      continue
+    if stripped.startswith("**Assistant:**"):
+      block = "assistant"
+      continue
+    if stripped == "### MCP References Injected":
+      block = None
+      in_mcp_section = True
+      continue
+    if stripped.startswith("```mcp-yaml"):
+      block = "mcp"
+      in_fence = True
+      continue
+    if in_fence and stripped.startswith("```"):
+      in_fence = False
+      block = None
+      in_mcp_section = False
+      continue
+
+    if block == "mcp" and in_fence:
+      current["mcp"].append(line)
+      continue
+    if block == "user":
+      current["user"].append(line)
+      continue
+    if block == "assistant":
+      current["assistant"].append(line)
+      continue
+
+    if in_mcp_section:
+      continue
+
+  finalize()
+  return turns
+
+
+def _prepare_mcp_context(mcp_yaml: Optional[str]) -> Tuple[Optional[str], int]:
+  if not mcp_yaml:
+    return None, 0
+
+  raw = mcp_yaml.strip()
+  if not raw:
+    return None, 0
+
+  try:
+    payload = yaml.safe_load(raw)
+  except yaml.YAMLError:
+    return raw, 0
+
+  normalized = yaml.safe_dump(payload, sort_keys=False).strip()
+  ref_count = 0
+  if isinstance(payload, dict):
+    references = payload.get("references")
+    if isinstance(references, list):
+      ref_count = len(references)
+
+  context_text = (normalized or raw).strip()
+  if not context_text:
+    return None, ref_count
+  return context_text, ref_count
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)


thinking
**Running test suite to verify**
exec
bash -lc pytest in /var/home/rick/Development/llm_writer succeeded in 2.49s:
============================= test session starts ==============================
platform linux -- Python 3.13.9, pytest-8.4.2, pluggy-1.6.0
rootdir: /var/home/rick/Development/llm_writer
configfile: pyproject.toml
testpaths: tests
plugins: Faker-37.8.0, xdist-3.8.0, mock-3.15.1, metadata-3.1.1, cov-7.0.0, asyncio-1.2.0, html-4.1.1, hypothesis-6.141.1, anyio-4.8.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collected 31 items

tests/test_cli_parser.py ..                                              [  6%]
tests/test_config_loader.py ...                                          [ 16%]
tests/test_llm_registry.py ....                                          [ 29%]
tests/test_mcp_normalization.py .....                                    [ 45%]
tests/test_planning_log_writer.py ...                                    [ 54%]
tests/test_planning_repl.py ....                                         [ 67%]
tests/test_prompt_building.py ..                                         [ 74%]
tests/test_replay_reconstruct.py ...                                     [ 83%]
tests/test_runner_run_tasks.py ..                                        [ 90%]
tests/test_task_loading.py ...                                           [100%]

file update:
diff --git a/src/simple_rag_writer/replay/reconstruct.py b/src/simple_rag_writer/replay/reconstruct.py
index 544bfab7edf7ea5ed426c0c72c20ed533294c73c..d51ee022bf4568d6484a427a9b466bc248959087
--- a/src/simple_rag_writer/replay/reconstruct.py
+++ b/src/simple_rag_writer/replay/reconstruct.py
@@ -2,21 +2,163 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import Tuple
+from typing import List, Optional, Tuple
 
+import yaml
+
 from simple_rag_writer.llm.registry import ModelRegistry
+from simple_rag_writer.prompts.planning import DEFAULT_HISTORY_WINDOW, build_planning_prompt
 
 
 @dataclass
 class ReplayMeta:
   turn_index: int
+  user_text: str
+  history_turns: Tuple[int, ...]
+  mcp_reference_count: int = 0
 
 
+@dataclass
+class _TurnRecord:
+  index: int
+  user_text: str
+  assistant_text: str
+  mcp_yaml: Optional[str] = None
+
+
 def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
-  """Very rough placeholder: returns full log as prompt."""
-  text = log_path.read_text(encoding="utf-8")
-  return text, ReplayMeta(turn_index=turn_index)
+  if turn_index < 1:
+    raise ValueError("turn_index must be >= 1")
+
+  turns = _parse_turns(log_path.read_text(encoding="utf-8"))
+  if not turns:
+    raise ValueError("No turns found in log")
 
+  target = next((t for t in turns if t.index == turn_index), None)
+  if target is None:
+    raise ValueError(f"Turn {turn_index} not found in log")
 
+  prior_turns = [t for t in turns if t.index < turn_index]
+  history_slice = prior_turns[-DEFAULT_HISTORY_WINDOW:]
+  history_pairs = [(t.user_text, t.assistant_text) for t in history_slice]
+  mcp_context, reference_count = _prepare_mcp_context(target.mcp_yaml)
+
+  prompt = build_planning_prompt(
+    history_pairs,
+    target.user_text,
+    mcp_context,
+    history_window=DEFAULT_HISTORY_WINDOW,
+  )
+  meta = ReplayMeta(
+    turn_index=turn_index,
+    user_text=target.user_text,
+    history_turns=tuple(t.index for t in history_slice),
+    mcp_reference_count=reference_count,
+  )
+  return prompt, meta
+
+
 def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
   return registry.complete(prompt)
+
+
+def _parse_turns(text: str) -> List[_TurnRecord]:
+  turns: List[_TurnRecord] = []
+  current: Optional[dict] = None
+  block: Optional[str] = None
+  in_fence = False
+  in_mcp_section = False
+
+  def finalize() -> None:
+    nonlocal current
+    if not current:
+      return
+    turns.append(
+      _TurnRecord(
+        index=current["index"],
+        user_text="\n".join(current["user"]).strip(),
+        assistant_text="\n".join(current["assistant"]).strip(),
+        mcp_yaml="\n".join(current["mcp"]).strip() or None,
+      )
+    )
+    current = None
+
+  for line in text.splitlines():
+    stripped = line.strip()
+    if stripped.startswith("## Turn "):
+      finalize()
+      index_text = stripped[len("## Turn ") :].strip()
+      try:
+        idx = int(index_text)
+      except ValueError:
+        continue
+      current = {"index": idx, "user": [], "assistant": [], "mcp": []}
+      block = None
+      in_fence = False
+      in_mcp_section = False
+      continue
+
+    if current is None:
+      continue
+
+    if stripped.startswith("**User:**"):
+      block = "user"
+      continue
+    if stripped.startswith("**Assistant:**"):
+      block = "assistant"
+      continue
+    if stripped == "### MCP References Injected":
+      block = None
+      in_mcp_section = True
+      continue
+    if stripped.startswith("```mcp-yaml"):
+      block = "mcp"
+      in_fence = True
+      continue
+    if in_fence and stripped.startswith("```"):
+      in_fence = False
+      block = None
+      in_mcp_section = False
+      continue
+
+    if block == "mcp" and in_fence:
+      current["mcp"].append(line)
+      continue
+    if block == "user":
+      current["user"].append(line)
+      continue
+    if block == "assistant":
+      current["assistant"].append(line)
+      continue
+
+    if in_mcp_section:
+      continue
+
+  finalize()
+  return turns
+
+
+def _prepare_mcp_context(mcp_yaml: Optional[str]) -> Tuple[Optional[str], int]:
+  if not mcp_yaml:
+    return None, 0
+
+  raw = mcp_yaml.strip()
+  if not raw:
+    return None, 0
+
+  try:
+    payload = yaml.safe_load(raw)
+  except yaml.YAMLError:
+    return raw, 0
+
+  normalized = yaml.safe_dump(payload, sort_keys=False).strip()
+  ref_count = 0
+  if isinstance(payload, dict):
+    references = payload.get("references")
+    if isinstance(references, list):
+      ref_count = len(references)
+
+  context_text = (normalized or raw).strip()
+  if not context_text:
+    return None, ref_count
+  return context_text, ref_count
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)


thinking
**Completing the plan update**
Plan update
  ✓ Read task spec and inspect existing replay/log structures to understand required behavior.
  ✓ Add tests covering prompt reconstruction behavior for multi-turn logs.
  ✓ Implement replay reconstruction and model run logic to satisfy tests, then run pytest.
file update:
diff --git a/src/simple_rag_writer/replay/reconstruct.py b/src/simple_rag_writer/replay/reconstruct.py
index 544bfab7edf7ea5ed426c0c72c20ed533294c73c..d51ee022bf4568d6484a427a9b466bc248959087
--- a/src/simple_rag_writer/replay/reconstruct.py
+++ b/src/simple_rag_writer/replay/reconstruct.py
@@ -2,21 +2,163 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import Tuple
+from typing import List, Optional, Tuple
 
+import yaml
+
 from simple_rag_writer.llm.registry import ModelRegistry
+from simple_rag_writer.prompts.planning import DEFAULT_HISTORY_WINDOW, build_planning_prompt
 
 
 @dataclass
 class ReplayMeta:
   turn_index: int
+  user_text: str
+  history_turns: Tuple[int, ...]
+  mcp_reference_count: int = 0
 
 
+@dataclass
+class _TurnRecord:
+  index: int
+  user_text: str
+  assistant_text: str
+  mcp_yaml: Optional[str] = None
+
+
 def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
-  """Very rough placeholder: returns full log as prompt."""
-  text = log_path.read_text(encoding="utf-8")
-  return text, ReplayMeta(turn_index=turn_index)
+  if turn_index < 1:
+    raise ValueError("turn_index must be >= 1")
+
+  turns = _parse_turns(log_path.read_text(encoding="utf-8"))
+  if not turns:
+    raise ValueError("No turns found in log")
 
+  target = next((t for t in turns if t.index == turn_index), None)
+  if target is None:
+    raise ValueError(f"Turn {turn_index} not found in log")
 
+  prior_turns = [t for t in turns if t.index < turn_index]
+  history_slice = prior_turns[-DEFAULT_HISTORY_WINDOW:]
+  history_pairs = [(t.user_text, t.assistant_text) for t in history_slice]
+  mcp_context, reference_count = _prepare_mcp_context(target.mcp_yaml)
+
+  prompt = build_planning_prompt(
+    history_pairs,
+    target.user_text,
+    mcp_context,
+    history_window=DEFAULT_HISTORY_WINDOW,
+  )
+  meta = ReplayMeta(
+    turn_index=turn_index,
+    user_text=target.user_text,
+    history_turns=tuple(t.index for t in history_slice),
+    mcp_reference_count=reference_count,
+  )
+  return prompt, meta
+
+
 def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
   return registry.complete(prompt)
+
+
+def _parse_turns(text: str) -> List[_TurnRecord]:
+  turns: List[_TurnRecord] = []
+  current: Optional[dict] = None
+  block: Optional[str] = None
+  in_fence = False
+  in_mcp_section = False
+
+  def finalize() -> None:
+    nonlocal current
+    if not current:
+      return
+    turns.append(
+      _TurnRecord(
+        index=current["index"],
+        user_text="\n".join(current["user"]).strip(),
+        assistant_text="\n".join(current["assistant"]).strip(),
+        mcp_yaml="\n".join(current["mcp"]).strip() or None,
+      )
+    )
+    current = None
+
+  for line in text.splitlines():
+    stripped = line.strip()
+    if stripped.startswith("## Turn "):
+      finalize()
+      index_text = stripped[len("## Turn ") :].strip()
+      try:
+        idx = int(index_text)
+      except ValueError:
+        continue
+      current = {"index": idx, "user": [], "assistant": [], "mcp": []}
+      block = None
+      in_fence = False
+      in_mcp_section = False
+      continue
+
+    if current is None:
+      continue
+
+    if stripped.startswith("**User:**"):
+      block = "user"
+      continue
+    if stripped.startswith("**Assistant:**"):
+      block = "assistant"
+      continue
+    if stripped == "### MCP References Injected":
+      block = None
+      in_mcp_section = True
+      continue
+    if stripped.startswith("```mcp-yaml"):
+      block = "mcp"
+      in_fence = True
+      continue
+    if in_fence and stripped.startswith("```"):
+      in_fence = False
+      block = None
+      in_mcp_section = False
+      continue
+
+    if block == "mcp" and in_fence:
+      current["mcp"].append(line)
+      continue
+    if block == "user":
+      current["user"].append(line)
+      continue
+    if block == "assistant":
+      current["assistant"].append(line)
+      continue
+
+    if in_mcp_section:
+      continue
+
+  finalize()
+  return turns
+
+
+def _prepare_mcp_context(mcp_yaml: Optional[str]) -> Tuple[Optional[str], int]:
+  if not mcp_yaml:
+    return None, 0
+
+  raw = mcp_yaml.strip()
+  if not raw:
+    return None, 0
+
+  try:
+    payload = yaml.safe_load(raw)
+  except yaml.YAMLError:
+    return raw, 0
+
+  normalized = yaml.safe_dump(payload, sort_keys=False).strip()
+  ref_count = 0
+  if isinstance(payload, dict):
+    references = payload.get("references")
+    if isinstance(references, list):
+      ref_count = len(references)
+
+  context_text = (normalized or raw).strip()
+  if not context_text:
+    return None, ref_count
+  return context_text, ref_count
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)


thinking
**Checking git status for changes**
exec
bash -lc 'git status -sb' in /var/home/rick/Development/llm_writer succeeded in 3.88s:
## main
?? codex/LOGS/codex_run_2025-11-16_04-58-12.log
?? codex/LOGS/tasklog_01_bootstrap_project_and_cli_1763287092.log
?? codex/LOGS/tasklog_01_bootstrap_project_and_cli_1763287092.log.done
?? codex/LOGS/tasklog_02_implement_config_models_and_loader_1763287503.log
?? codex/LOGS/tasklog_02_implement_config_models_and_loader_1763287503.log.done
?? codex/LOGS/tasklog_03_implement_model_registry_and_litellm_integration_1763287725.log
?? codex/LOGS/tasklog_03_implement_model_registry_and_litellm_integration_1763287725.log.done
?? codex/LOGS/tasklog_04_define_task_spec_and_loader_1763287876.log
?? codex/LOGS/tasklog_04_define_task_spec_and_loader_1763287876.log.done
?? codex/LOGS/tasklog_05_implement_prompt_builders_1763288031.log
?? codex/LOGS/tasklog_05_implement_prompt_builders_1763288031.log.done
?? codex/LOGS/tasklog_06_implement_mcp_types_and_normalization_1763288389.log
?? codex/LOGS/tasklog_06_implement_mcp_types_and_normalization_1763288389.log.done
?? codex/LOGS/tasklog_07_implement_automated_task_runner_1763288534.log
?? codex/LOGS/tasklog_07_implement_automated_task_runner_1763288534.log.done
?? codex/LOGS/tasklog_08_implement_planning_log_writer_1763289052.log
?? codex/LOGS/tasklog_08_implement_planning_log_writer_1763289052.log.done
?? codex/LOGS/tasklog_09_implement_planning_repl_1763289341.log
?? codex/LOGS/tasklog_09_implement_planning_repl_1763289341.log.done
file update:
diff --git a/src/simple_rag_writer/replay/reconstruct.py b/src/simple_rag_writer/replay/reconstruct.py
index 544bfab7edf7ea5ed426c0c72c20ed533294c73c..d51ee022bf4568d6484a427a9b466bc248959087
--- a/src/simple_rag_writer/replay/reconstruct.py
+++ b/src/simple_rag_writer/replay/reconstruct.py
@@ -2,21 +2,163 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import Tuple
+from typing import List, Optional, Tuple
 
+import yaml
+
 from simple_rag_writer.llm.registry import ModelRegistry
+from simple_rag_writer.prompts.planning import DEFAULT_HISTORY_WINDOW, build_planning_prompt
 
 
 @dataclass
 class ReplayMeta:
   turn_index: int
+  user_text: str
+  history_turns: Tuple[int, ...]
+  mcp_reference_count: int = 0
 
 
+@dataclass
+class _TurnRecord:
+  index: int
+  user_text: str
+  assistant_text: str
+  mcp_yaml: Optional[str] = None
+
+
 def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
-  """Very rough placeholder: returns full log as prompt."""
-  text = log_path.read_text(encoding="utf-8")
-  return text, ReplayMeta(turn_index=turn_index)
+  if turn_index < 1:
+    raise ValueError("turn_index must be >= 1")
+
+  turns = _parse_turns(log_path.read_text(encoding="utf-8"))
+  if not turns:
+    raise ValueError("No turns found in log")
 
+  target = next((t for t in turns if t.index == turn_index), None)
+  if target is None:
+    raise ValueError(f"Turn {turn_index} not found in log")
 
+  prior_turns = [t for t in turns if t.index < turn_index]
+  history_slice = prior_turns[-DEFAULT_HISTORY_WINDOW:]
+  history_pairs = [(t.user_text, t.assistant_text) for t in history_slice]
+  mcp_context, reference_count = _prepare_mcp_context(target.mcp_yaml)
+
+  prompt = build_planning_prompt(
+    history_pairs,
+    target.user_text,
+    mcp_context,
+    history_window=DEFAULT_HISTORY_WINDOW,
+  )
+  meta = ReplayMeta(
+    turn_index=turn_index,
+    user_text=target.user_text,
+    history_turns=tuple(t.index for t in history_slice),
+    mcp_reference_count=reference_count,
+  )
+  return prompt, meta
+
+
 def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
   return registry.complete(prompt)
+
+
+def _parse_turns(text: str) -> List[_TurnRecord]:
+  turns: List[_TurnRecord] = []
+  current: Optional[dict] = None
+  block: Optional[str] = None
+  in_fence = False
+  in_mcp_section = False
+
+  def finalize() -> None:
+    nonlocal current
+    if not current:
+      return
+    turns.append(
+      _TurnRecord(
+        index=current["index"],
+        user_text="\n".join(current["user"]).strip(),
+        assistant_text="\n".join(current["assistant"]).strip(),
+        mcp_yaml="\n".join(current["mcp"]).strip() or None,
+      )
+    )
+    current = None
+
+  for line in text.splitlines():
+    stripped = line.strip()
+    if stripped.startswith("## Turn "):
+      finalize()
+      index_text = stripped[len("## Turn ") :].strip()
+      try:
+        idx = int(index_text)
+      except ValueError:
+        continue
+      current = {"index": idx, "user": [], "assistant": [], "mcp": []}
+      block = None
+      in_fence = False
+      in_mcp_section = False
+      continue
+
+    if current is None:
+      continue
+
+    if stripped.startswith("**User:**"):
+      block = "user"
+      continue
+    if stripped.startswith("**Assistant:**"):
+      block = "assistant"
+      continue
+    if stripped == "### MCP References Injected":
+      block = None
+      in_mcp_section = True
+      continue
+    if stripped.startswith("```mcp-yaml"):
+      block = "mcp"
+      in_fence = True
+      continue
+    if in_fence and stripped.startswith("```"):
+      in_fence = False
+      block = None
+      in_mcp_section = False
+      continue
+
+    if block == "mcp" and in_fence:
+      current["mcp"].append(line)
+      continue
+    if block == "user":
+      current["user"].append(line)
+      continue
+    if block == "assistant":
+      current["assistant"].append(line)
+      continue
+
+    if in_mcp_section:
+      continue
+
+  finalize()
+  return turns
+
+
+def _prepare_mcp_context(mcp_yaml: Optional[str]) -> Tuple[Optional[str], int]:
+  if not mcp_yaml:
+    return None, 0
+
+  raw = mcp_yaml.strip()
+  if not raw:
+    return None, 0
+
+  try:
+    payload = yaml.safe_load(raw)
+  except yaml.YAMLError:
+    return raw, 0
+
+  normalized = yaml.safe_dump(payload, sort_keys=False).strip()
+  ref_count = 0
+  if isinstance(payload, dict):
+    references = payload.get("references")
+    if isinstance(references, list):
+      ref_count = len(references)
+
+  context_text = (normalized or raw).strip()
+  if not context_text:
+    return None, ref_count
+  return context_text, ref_count
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)


thinking
**Preparing summary details with file line references**
exec
bash -lc 'nl -ba tests/test_replay_reconstruct.py' in /var/home/rick/Development/llm_writer succeeded in 41ms:
     1	from __future__ import annotations
     2	
     3	from pathlib import Path
     4	from textwrap import dedent
     5	
     6	import pytest
     7	
     8	from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
     9	
    10	
    11	def _write_log(tmp_path: Path, text: str) -> Path:
    12	  path = tmp_path / "plan-log.md"
    13	  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
    14	  return path
    15	
    16	
    17	def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
    18	  log_path = _write_log(
    19	    tmp_path,
    20	    """
file update:
diff --git a/src/simple_rag_writer/replay/reconstruct.py b/src/simple_rag_writer/replay/reconstruct.py
index 544bfab7edf7ea5ed426c0c72c20ed533294c73c..d51ee022bf4568d6484a427a9b466bc248959087
--- a/src/simple_rag_writer/replay/reconstruct.py
+++ b/src/simple_rag_writer/replay/reconstruct.py
@@ -2,21 +2,163 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import Tuple
+from typing import List, Optional, Tuple
 
+import yaml
+
 from simple_rag_writer.llm.registry import ModelRegistry
+from simple_rag_writer.prompts.planning import DEFAULT_HISTORY_WINDOW, build_planning_prompt
 
 
 @dataclass
 class ReplayMeta:
   turn_index: int
+  user_text: str
+  history_turns: Tuple[int, ...]
+  mcp_reference_count: int = 0
 
 
+@dataclass
+class _TurnRecord:
+  index: int
+  user_text: str
+  assistant_text: str
+  mcp_yaml: Optional[str] = None
+
+
 def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
-  """Very rough placeholder: returns full log as prompt."""
-  text = log_path.read_text(encoding="utf-8")
-  return text, ReplayMeta(turn_index=turn_index)
+  if turn_index < 1:
+    raise ValueError("turn_index must be >= 1")
+
+  turns = _parse_turns(log_path.read_text(encoding="utf-8"))
+  if not turns:
+    raise ValueError("No turns found in log")
 
+  target = next((t for t in turns if t.index == turn_index), None)
+  if target is None:
+    raise ValueError(f"Turn {turn_index} not found in log")
 
+  prior_turns = [t for t in turns if t.index < turn_index]
+  history_slice = prior_turns[-DEFAULT_HISTORY_WINDOW:]
+  history_pairs = [(t.user_text, t.assistant_text) for t in history_slice]
+  mcp_context, reference_count = _prepare_mcp_context(target.mcp_yaml)
+
+  prompt = build_planning_prompt(
+    history_pairs,
+    target.user_text,
+    mcp_context,
+    history_window=DEFAULT_HISTORY_WINDOW,
+  )
+  meta = ReplayMeta(
+    turn_index=turn_index,
+    user_text=target.user_text,
+    history_turns=tuple(t.index for t in history_slice),
+    mcp_reference_count=reference_count,
+  )
+  return prompt, meta
+
+
 def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
   return registry.complete(prompt)
+
+
+def _parse_turns(text: str) -> List[_TurnRecord]:
+  turns: List[_TurnRecord] = []
+  current: Optional[dict] = None
+  block: Optional[str] = None
+  in_fence = False
+  in_mcp_section = False
+
+  def finalize() -> None:
+    nonlocal current
+    if not current:
+      return
+    turns.append(
+      _TurnRecord(
+        index=current["index"],
+        user_text="\n".join(current["user"]).strip(),
+        assistant_text="\n".join(current["assistant"]).strip(),
+        mcp_yaml="\n".join(current["mcp"]).strip() or None,
+      )
+    )
+    current = None
+
+  for line in text.splitlines():
+    stripped = line.strip()
+    if stripped.startswith("## Turn "):
+      finalize()
+      index_text = stripped[len("## Turn ") :].strip()
+      try:
+        idx = int(index_text)
+      except ValueError:
+        continue
+      current = {"index": idx, "user": [], "assistant": [], "mcp": []}
+      block = None
+      in_fence = False
+      in_mcp_section = False
+      continue
+
+    if current is None:
+      continue
+
+    if stripped.startswith("**User:**"):
+      block = "user"
+      continue
+    if stripped.startswith("**Assistant:**"):
+      block = "assistant"
+      continue
+    if stripped == "### MCP References Injected":
+      block = None
+      in_mcp_section = True
+      continue
+    if stripped.startswith("```mcp-yaml"):
+      block = "mcp"
+      in_fence = True
+      continue
+    if in_fence and stripped.startswith("```"):
+      in_fence = False
+      block = None
+      in_mcp_section = False
+      continue
+
+    if block == "mcp" and in_fence:
+      current["mcp"].append(line)
+      continue
+    if block == "user":
+      current["user"].append(line)
+      continue
+    if block == "assistant":
+      current["assistant"].append(line)
+      continue
+
+    if in_mcp_section:
+      continue
+
+  finalize()
+  return turns
+
+
+def _prepare_mcp_context(mcp_yaml: Optional[str]) -> Tuple[Optional[str], int]:
+  if not mcp_yaml:
+    return None, 0
+
+  raw = mcp_yaml.strip()
+  if not raw:
+    return None, 0
+
+  try:
+    payload = yaml.safe_load(raw)
+  except yaml.YAMLError:
+    return raw, 0
+
+  normalized = yaml.safe_dump(payload, sort_keys=False).strip()
+  ref_count = 0
+  if isinstance(payload, dict):
+    references = payload.get("references")
+    if isinstance(references, list):
+      ref_count = len(references)
+
+  context_text = (normalized or raw).strip()
+  if not context_text:
+    return None, ref_count
+  return context_text, ref_count
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)


thinking
**Preparing to reference source lines**
exec
bash -lc 'nl -ba src/simple_rag_writer/replay/reconstruct.py' in /var/home/rick/Development/llm_writer succeeded in 40ms:
     1	from __future__ import annotations
     2	
     3	from dataclasses import dataclass
     4	from pathlib import Path
     5	from typing import List, Optional, Tuple
     6	
     7	import yaml
     8	
     9	from simple_rag_writer.llm.registry import ModelRegistry
    10	from simple_rag_writer.prompts.planning import DEFAULT_HISTORY_WINDOW, build_planning_prompt
    11	
    12	
    13	@dataclass
    14	class ReplayMeta:
    15	  turn_index: int
    16	  user_text: str
    17	  history_turns: Tuple[int, ...]
    18	  mcp_reference_count: int = 0
    19	
    20	
file update:
diff --git a/src/simple_rag_writer/replay/reconstruct.py b/src/simple_rag_writer/replay/reconstruct.py
index 544bfab7edf7ea5ed426c0c72c20ed533294c73c..d51ee022bf4568d6484a427a9b466bc248959087
--- a/src/simple_rag_writer/replay/reconstruct.py
+++ b/src/simple_rag_writer/replay/reconstruct.py
@@ -2,21 +2,163 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import Tuple
+from typing import List, Optional, Tuple
 
+import yaml
+
 from simple_rag_writer.llm.registry import ModelRegistry
+from simple_rag_writer.prompts.planning import DEFAULT_HISTORY_WINDOW, build_planning_prompt
 
 
 @dataclass
 class ReplayMeta:
   turn_index: int
+  user_text: str
+  history_turns: Tuple[int, ...]
+  mcp_reference_count: int = 0
 
 
+@dataclass
+class _TurnRecord:
+  index: int
+  user_text: str
+  assistant_text: str
+  mcp_yaml: Optional[str] = None
+
+
 def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
-  """Very rough placeholder: returns full log as prompt."""
-  text = log_path.read_text(encoding="utf-8")
-  return text, ReplayMeta(turn_index=turn_index)
+  if turn_index < 1:
+    raise ValueError("turn_index must be >= 1")
+
+  turns = _parse_turns(log_path.read_text(encoding="utf-8"))
+  if not turns:
+    raise ValueError("No turns found in log")
 
+  target = next((t for t in turns if t.index == turn_index), None)
+  if target is None:
+    raise ValueError(f"Turn {turn_index} not found in log")
 
+  prior_turns = [t for t in turns if t.index < turn_index]
+  history_slice = prior_turns[-DEFAULT_HISTORY_WINDOW:]
+  history_pairs = [(t.user_text, t.assistant_text) for t in history_slice]
+  mcp_context, reference_count = _prepare_mcp_context(target.mcp_yaml)
+
+  prompt = build_planning_prompt(
+    history_pairs,
+    target.user_text,
+    mcp_context,
+    history_window=DEFAULT_HISTORY_WINDOW,
+  )
+  meta = ReplayMeta(
+    turn_index=turn_index,
+    user_text=target.user_text,
+    history_turns=tuple(t.index for t in history_slice),
+    mcp_reference_count=reference_count,
+  )
+  return prompt, meta
+
+
 def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
   return registry.complete(prompt)
+
+
+def _parse_turns(text: str) -> List[_TurnRecord]:
+  turns: List[_TurnRecord] = []
+  current: Optional[dict] = None
+  block: Optional[str] = None
+  in_fence = False
+  in_mcp_section = False
+
+  def finalize() -> None:
+    nonlocal current
+    if not current:
+      return
+    turns.append(
+      _TurnRecord(
+        index=current["index"],
+        user_text="\n".join(current["user"]).strip(),
+        assistant_text="\n".join(current["assistant"]).strip(),
+        mcp_yaml="\n".join(current["mcp"]).strip() or None,
+      )
+    )
+    current = None
+
+  for line in text.splitlines():
+    stripped = line.strip()
+    if stripped.startswith("## Turn "):
+      finalize()
+      index_text = stripped[len("## Turn ") :].strip()
+      try:
+        idx = int(index_text)
+      except ValueError:
+        continue
+      current = {"index": idx, "user": [], "assistant": [], "mcp": []}
+      block = None
+      in_fence = False
+      in_mcp_section = False
+      continue
+
+    if current is None:
+      continue
+
+    if stripped.startswith("**User:**"):
+      block = "user"
+      continue
+    if stripped.startswith("**Assistant:**"):
+      block = "assistant"
+      continue
+    if stripped == "### MCP References Injected":
+      block = None
+      in_mcp_section = True
+      continue
+    if stripped.startswith("```mcp-yaml"):
+      block = "mcp"
+      in_fence = True
+      continue
+    if in_fence and stripped.startswith("```"):
+      in_fence = False
+      block = None
+      in_mcp_section = False
+      continue
+
+    if block == "mcp" and in_fence:
+      current["mcp"].append(line)
+      continue
+    if block == "user":
+      current["user"].append(line)
+      continue
+    if block == "assistant":
+      current["assistant"].append(line)
+      continue
+
+    if in_mcp_section:
+      continue
+
+  finalize()
+  return turns
+
+
+def _prepare_mcp_context(mcp_yaml: Optional[str]) -> Tuple[Optional[str], int]:
+  if not mcp_yaml:
+    return None, 0
+
+  raw = mcp_yaml.strip()
+  if not raw:
+    return None, 0
+
+  try:
+    payload = yaml.safe_load(raw)
+  except yaml.YAMLError:
+    return raw, 0
+
+  normalized = yaml.safe_dump(payload, sort_keys=False).strip()
+  ref_count = 0
+  if isinstance(payload, dict):
+    references = payload.get("references")
+    if isinstance(references, list):
+      ref_count = len(references)
+
+  context_text = (normalized or raw).strip()
+  if not context_text:
+    return None, ref_count
+  return context_text, ref_count
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)


thinking
**Summarizing replay support changes**

I'll organize the final summary into a neat bullet list highlighting key code changes in replay prompt reconstruction, helper functions for parsing and MCP context, details about new metadata tracking, and related tests with line references. I'll also include test commands for verification and keep it clear and concise under the header **Replay Support**.
codex
**Replay Support**
- Rebuilt `reconstruct_prompt_for_turn` to validate turn indices, parse planning logs into structured turns, reuse the planning prompt builder, and expose richer metadata (user text, history slice, MCP reference count) via `ReplayMeta` so replayed prompts reflect the original conversation context (`src/simple_rag_writer/replay/reconstruct.py:13-58`).
- Added `_parse_turns` and `_prepare_mcp_context` helpers that extract user/assistant text, isolate embedded MCP sections (including fenced YAML), normalize the stored payload, and count references for inclusion in the reconstructed prompt (`src/simple_rag_writer/replay/reconstruct.py:65-164`).
- Introduced targeted replay tests that generate sample logs, verify history and MCP context are preserved, and ensure missing-turn requests raise errors (`tests/test_replay_reconstruct.py:11-146`).

**Tests**
- `pytest tests/test_replay_reconstruct.py`
- `pytest`
file update:
diff --git a/src/simple_rag_writer/replay/reconstruct.py b/src/simple_rag_writer/replay/reconstruct.py
index 544bfab7edf7ea5ed426c0c72c20ed533294c73c..d51ee022bf4568d6484a427a9b466bc248959087
--- a/src/simple_rag_writer/replay/reconstruct.py
+++ b/src/simple_rag_writer/replay/reconstruct.py
@@ -2,21 +2,163 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import Tuple
+from typing import List, Optional, Tuple
 
+import yaml
+
 from simple_rag_writer.llm.registry import ModelRegistry
+from simple_rag_writer.prompts.planning import DEFAULT_HISTORY_WINDOW, build_planning_prompt
 
 
 @dataclass
 class ReplayMeta:
   turn_index: int
+  user_text: str
+  history_turns: Tuple[int, ...]
+  mcp_reference_count: int = 0
 
 
+@dataclass
+class _TurnRecord:
+  index: int
+  user_text: str
+  assistant_text: str
+  mcp_yaml: Optional[str] = None
+
+
 def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
-  """Very rough placeholder: returns full log as prompt."""
-  text = log_path.read_text(encoding="utf-8")
-  return text, ReplayMeta(turn_index=turn_index)
+  if turn_index < 1:
+    raise ValueError("turn_index must be >= 1")
+
+  turns = _parse_turns(log_path.read_text(encoding="utf-8"))
+  if not turns:
+    raise ValueError("No turns found in log")
 
+  target = next((t for t in turns if t.index == turn_index), None)
+  if target is None:
+    raise ValueError(f"Turn {turn_index} not found in log")
 
+  prior_turns = [t for t in turns if t.index < turn_index]
+  history_slice = prior_turns[-DEFAULT_HISTORY_WINDOW:]
+  history_pairs = [(t.user_text, t.assistant_text) for t in history_slice]
+  mcp_context, reference_count = _prepare_mcp_context(target.mcp_yaml)
+
+  prompt = build_planning_prompt(
+    history_pairs,
+    target.user_text,
+    mcp_context,
+    history_window=DEFAULT_HISTORY_WINDOW,
+  )
+  meta = ReplayMeta(
+    turn_index=turn_index,
+    user_text=target.user_text,
+    history_turns=tuple(t.index for t in history_slice),
+    mcp_reference_count=reference_count,
+  )
+  return prompt, meta
+
+
 def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
   return registry.complete(prompt)
+
+
+def _parse_turns(text: str) -> List[_TurnRecord]:
+  turns: List[_TurnRecord] = []
+  current: Optional[dict] = None
+  block: Optional[str] = None
+  in_fence = False
+  in_mcp_section = False
+
+  def finalize() -> None:
+    nonlocal current
+    if not current:
+      return
+    turns.append(
+      _TurnRecord(
+        index=current["index"],
+        user_text="\n".join(current["user"]).strip(),
+        assistant_text="\n".join(current["assistant"]).strip(),
+        mcp_yaml="\n".join(current["mcp"]).strip() or None,
+      )
+    )
+    current = None
+
+  for line in text.splitlines():
+    stripped = line.strip()
+    if stripped.startswith("## Turn "):
+      finalize()
+      index_text = stripped[len("## Turn ") :].strip()
+      try:
+        idx = int(index_text)
+      except ValueError:
+        continue
+      current = {"index": idx, "user": [], "assistant": [], "mcp": []}
+      block = None
+      in_fence = False
+      in_mcp_section = False
+      continue
+
+    if current is None:
+      continue
+
+    if stripped.startswith("**User:**"):
+      block = "user"
+      continue
+    if stripped.startswith("**Assistant:**"):
+      block = "assistant"
+      continue
+    if stripped == "### MCP References Injected":
+      block = None
+      in_mcp_section = True
+      continue
+    if stripped.startswith("```mcp-yaml"):
+      block = "mcp"
+      in_fence = True
+      continue
+    if in_fence and stripped.startswith("```"):
+      in_fence = False
+      block = None
+      in_mcp_section = False
+      continue
+
+    if block == "mcp" and in_fence:
+      current["mcp"].append(line)
+      continue
+    if block == "user":
+      current["user"].append(line)
+      continue
+    if block == "assistant":
+      current["assistant"].append(line)
+      continue
+
+    if in_mcp_section:
+      continue
+
+  finalize()
+  return turns
+
+
+def _prepare_mcp_context(mcp_yaml: Optional[str]) -> Tuple[Optional[str], int]:
+  if not mcp_yaml:
+    return None, 0
+
+  raw = mcp_yaml.strip()
+  if not raw:
+    return None, 0
+
+  try:
+    payload = yaml.safe_load(raw)
+  except yaml.YAMLError:
+    return raw, 0
+
+  normalized = yaml.safe_dump(payload, sort_keys=False).strip()
+  ref_count = 0
+  if isinstance(payload, dict):
+    references = payload.get("references")
+    if isinstance(references, list):
+      ref_count = len(references)
+
+  context_text = (normalized or raw).strip()
+  if not context_text:
+    return None, ref_count
+  return context_text, ref_count
diff --git a/tests/test_replay_reconstruct.py b/tests/test_replay_reconstruct.py
new file mode 100644
index 0000000000000000000000000000000000000000..dc3fb6a8a6c521d7391a171c54bb6cef1d928c8f
--- /dev/null
+++ b/tests/test_replay_reconstruct.py
@@ -0,0 +1,146 @@
+from __future__ import annotations
+
+from pathlib import Path
+from textwrap import dedent
+
+import pytest
+
+from simple_rag_writer.replay.reconstruct import reconstruct_prompt_for_turn
+
+
+def _write_log(tmp_path: Path, text: str) -> Path:
+  path = tmp_path / "plan-log.md"
+  path.write_text(dedent(text).lstrip("\n"), encoding="utf-8")
+  return path
+
+
+def test_reconstruct_prompt_includes_previous_turn_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Need help outlining the chapter.
+
+    **Assistant:**
+
+    Start by listing sections and transitions.
+
+    ## Turn 2
+
+    **User:**
+
+    Can you expand the outline with more details?
+
+    **Assistant:**
+
+    Let's add bullet points per section.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "You are a planning assistant" in prompt
+  assert "User: Need help outlining the chapter." in prompt
+  assert "Assistant: Start by listing sections and transitions." in prompt
+  assert prompt.strip().endswith("Can you expand the outline with more details?")
+  assert meta.turn_index == 2
+  assert meta.user_text == "Can you expand the outline with more details?"
+  assert meta.history_turns == (1,)
+
+
+def test_reconstruct_prompt_includes_mcp_yaml_context(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Summarize new notes.
+
+    **Assistant:**
+
+    Sure thing.
+
+    ## Turn 2
+
+    **User:**
+
+    Use the MCP references from earlier.
+
+    ### MCP References Injected
+
+    | idx | server | tool | label | normalized_id | title |
+    | --- | ------ | ---- | ----- | ------------- | ----- |
+    | 1 | notes | search | Spec | notes#1 | Outline draft |
+
+    ```mcp-yaml
+    references:
+      - idx: 1
+        server: notes
+        tool: search
+        label: Spec
+        normalized_id: notes#1
+        title: Outline draft
+        snippet: First few lines
+        body: Full body text
+      - idx: 2
+        server: notes
+        tool: search
+        label: Plan
+        normalized_id: notes#2
+        title: Planning memo
+        snippet: Another snippet
+        body: Another body text
+    ```
+
+    **Assistant:**
+
+    Injected the MCP references.
+    """,
+  )
+
+  prompt, meta = reconstruct_prompt_for_turn(log_path, 2)
+
+  assert "## Context from external sources" in prompt
+  assert "references:" in prompt
+  assert "title: Outline draft" in prompt
+  assert meta.mcp_reference_count == 2
+
+
+def test_reconstruct_prompt_errors_when_turn_missing(tmp_path: Path) -> None:
+  log_path = _write_log(
+    tmp_path,
+    """
+    # Planning Session — 2024-05-01
+    - Config: config.yaml
+    - Default model: writer
+    - Models used: writer
+
+    ## Turn 1
+
+    **User:**
+
+    Hello
+
+    **Assistant:**
+
+    Hi
+    """,
+  )
+
+  with pytest.raises(ValueError):
+    reconstruct_prompt_for_turn(log_path, 3)

tokens used
110,898
**Replay Support**
- Rebuilt `reconstruct_prompt_for_turn` to validate turn indices, parse planning logs into structured turns, reuse the planning prompt builder, and expose richer metadata (user text, history slice, MCP reference count) via `ReplayMeta` so replayed prompts reflect the original conversation context (`src/simple_rag_writer/replay/reconstruct.py:13-58`).
- Added `_parse_turns` and `_prepare_mcp_context` helpers that extract user/assistant text, isolate embedded MCP sections (including fenced YAML), normalize the stored payload, and count references for inclusion in the reconstructed prompt (`src/simple_rag_writer/replay/reconstruct.py:65-164`).
- Introduced targeted replay tests that generate sample logs, verify history and MCP context are preserved, and ensure missing-turn requests raise errors (`tests/test_replay_reconstruct.py:11-146`).

**Tests**
- `pytest tests/test_replay_reconstruct.py`
- `pytest`
