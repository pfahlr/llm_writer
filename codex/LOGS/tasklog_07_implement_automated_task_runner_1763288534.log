OpenAI Codex v0.57.0 (research preview)
--------
workdir: /var/home/rick/Development/llm_writer
model: gpt-5-codex
provider: openai
approval: never
sandbox: workspace-write [workdir, /tmp, $TMPDIR]
reasoning effort: high
reasoning summaries: auto
session id: 019a8c2f-cde3-73f0-8c7e-efc5075d2fbe
--------
user
Implement the functionality described in codex/TASKS/07_implement_automated_task_runner.yaml, then verify with any available tests.
ERROR: MCP client for `exa` failed to start: handshaking with MCP server failed: connection closed: initialize response
ERROR: MCP client for `context7-mcp` failed to start: handshaking with MCP server failed: connection closed: initialize response
ERROR: MCP client for `vibe-check-mcp-server` failed to start: handshaking with MCP server failed: connection closed: initialize response
ERROR: MCP client for `mcp` failed to start: handshaking with MCP server failed: connection closed: initialize response

thinking
**Assessing environment and planning**
exec
bash -lc ls in /var/home/rick/Development/llm_writer succeeded in 43ms:
AGENTS.md
codex
codex.toml
pyproject.toml
README.md
requirements.txt
src
tests
venv

thinking
**Reading task file**
exec
bash -lc 'ls codex/TASKS' in /var/home/rick/Development/llm_writer succeeded in 39ms:
01_bootstrap_project_and_cli.yaml
02_implement_config_models_and_loader.yaml
03_implement_model_registry_and_litellm_integration.yaml
04_define_task_spec_and_loader.yaml
05_implement_prompt_builders.yaml
06_implement_mcp_types_and_normalization.yaml
07_implement_automated_task_runner.yaml
08_implement_planning_log_writer.yaml
09_implement_planning_repl.yaml
10_implement_replay_support.yaml
11_implement_mcp_prompt_policy_modes.yaml
12_add_textual_source_browser_stub.yaml
CODEX_TODO.md
master_spec.yaml
work_list

thinking
**Searching for category 07 file**
exec
bash -lc 'cat codex/TASKS/07_implement_automated_task_runner.yaml' in /var/home/rick/Development/llm_writer succeeded in 38ms:
id: 07
filename: 07_implement_automated_task_runner.yaml
title: Implement automated task runner orchestration (MCP + URL references)
description: >
  Implement run_tasks_for_paths() to orchestrate loading TaskSpecs, resolving
  references via MCP and via direct URL fetching, building prompts, calling
  the ModelRegistry, and writing Markdown output files.

dependencies:
  - 03
  - 04
  - 05
  - 06

goals:
  - run_tasks_for_paths() expands globs, loads tasks, and runs them in order.
  - MCP references are resolved via McpClient and normalized into text blobs.
  - URL references are fetched over HTTP, converted to text, and normalized
    into text blobs, then passed through the same prompt policy layer.
  - Task output is written to the configured "output" path in TaskSpec.

thinking
**Preparing to implement run_tasks_for_paths**
exec
bash -lc 'rg --files src | head' in /var/home/rick/Development/llm_writer succeeded in 50ms:
src/simple_rag_writer/__pycache__/__init__.cpython-313.pyc
src/simple_rag_writer/__init__.py
src/simple_rag_writer/tasks/__pycache__/loader.cpython-313.pyc
src/simple_rag_writer/tasks/__pycache__/models.cpython-313.pyc
src/simple_rag_writer/tasks/__pycache__/__init__.cpython-313.pyc
src/simple_rag_writer/tasks/loader.py
src/simple_rag_writer/tasks/models.py
src/simple_rag_writer/tasks/__init__.py
src/simple_rag_writer/runner/__pycache__/run_tasks.cpython-313.pyc
src/simple_rag_writer/runner/__pycache__/__init__.cpython-313.pyc

thinking
**Checking for pycache and run_tasks**
exec
bash -lc "sed -n '1,200p' src/simple_rag_writer/runner/run_tasks.py" in /var/home/rick/Development/llm_writer succeeded in 44ms:
from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import List

from rich.console import Console

from simple_rag_writer.config.models import AppConfig
from simple_rag_writer.llm.registry import ModelRegistry
from simple_rag_writer.tasks.loader import load_task, expand_task_paths
from simple_rag_writer.mcp.client import McpClient
from simple_rag_writer.mcp.normalization import normalize_payload
from simple_rag_writer.prompts.task_prompt import build_task_prompt

console = Console()


@dataclass
class RunTasksResult:

thinking
**Preparing to add URL support and prompt normalization**
exec
bash -lc "sed -n '1,200p' src/simple_rag_writer/tasks/models.py" in /var/home/rick/Development/llm_writer succeeded in 39ms:
from __future__ import annotations

from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field


class ContextSpec(BaseModel):
  outline_path: Optional[str] = None
  outline_id: Optional[str] = None


class ReferenceCommon(BaseModel):
  type: str
  label: Optional[str] = None
  item_type: Optional[str] = None
  prompt_mode: Optional[str] = None
  max_items: Optional[int] = None
  max_chars: Optional[int] = None
  summary_max_tokens: Optional[int] = None

thinking
**Searching for prompt normalization modules**
exec
bash -lc 'ls src/simple_rag_writer' in /var/home/rick/Development/llm_writer succeeded in 39ms:
cli
config
__init__.py
llm
logging
mcp
planning
prompts
__pycache__
replay
runner
tasks

thinking
**Examining MCP normalization**
exec
bash -lc "sed -n '1,200p' src/simple_rag_writer/mcp/normalization.py" in /var/home/rick/Development/llm_writer succeeded in 38ms:
from __future__ import annotations

from typing import Any, Dict, List, Optional

from .types import NormalizedItem


def normalize_payload(
  payload: Any,
  item_type_hint: Optional[str] = None,
) -> List[NormalizedItem]:
  """Convert raw MCP payload into a list of NormalizedItem."""
  items: List[NormalizedItem] = []

  if isinstance(payload, str):
    items.append(NormalizedItem(body=payload, type=item_type_hint))
  elif isinstance(payload, list):
    for idx, entry in enumerate(payload):
      if isinstance(entry, str):
        items.append(NormalizedItem(id=str(idx), body=entry, type=item_type_hint))

thinking
**Identifying type requirement**
exec
bash -lc "sed -n '1,200p' src/simple_rag_writer/mcp/types.py" in /var/home/rick/Development/llm_writer succeeded in 44ms:
from __future__ import annotations

from typing import Any, Dict, Optional

from pydantic import BaseModel, Field


class McpToolResult(BaseModel):
  server_id: str
  tool_name: str
  payload: Any


class NormalizedItem(BaseModel):
  id: Optional[str] = None
  type: Optional[str] = None
  title: Optional[str] = None
  snippet: Optional[str] = None
  body: Optional[str] = None
  url: Optional[str] = None

thinking
**Considering mcp client usage**
exec
bash -lc "sed -n '1,200p' src/simple_rag_writer/mcp/client.py" in /var/home/rick/Development/llm_writer succeeded in 38ms:
from __future__ import annotations

from typing import Any, Dict

from .types import McpToolResult


class McpClient:
  """
  Placeholder for MCP client. Responsibilities:

  - Start/stop MCP servers (from AppConfig.mcp_servers).
  - Call tools on servers and return McpToolResult.
  """

  def __init__(self, config):
    self._config = config
    # TODO: process spawning / connection to MCP servers

  def call_tool(self, server_id: str, tool_name: str, params: Dict[str, Any]) -> McpToolResult:

thinking
**Checking prompt instructions**
exec
bash -lc 'ls src/simple_rag_writer/prompts' in /var/home/rick/Development/llm_writer succeeded in 38ms:
__init__.py
planning.py
__pycache__
task_prompt.py
exec
bash -lc "sed -n '1,200p' src/simple_rag_writer/prompts/task_prompt.py" in /var/home/rick/Development/llm_writer succeeded in 43ms:
from __future__ import annotations

from typing import List, Optional

from simple_rag_writer.tasks.models import TaskSpec


def build_task_prompt(
  task: TaskSpec,
  outline_context: Optional[str],
  reference_blobs: List[str],
) -> str:
  parts: List[str] = []
  parts.append(f"# Task: {task.title}\n")
  parts.append("## Description\n")
  parts.append(task.description)
  if task.style:
    parts.append(f"\n\nStyle: {task.style}")
  if outline_context:
    parts.append("\n\n## Outline context\n")

thinking
**Searching for prompt policy logic**
exec
bash -lc 'rg -n "prompt" -n src/simple_rag_writer -g"*prompt*"' in /var/home/rick/Development/llm_writer succeeded in 42ms:
src/simple_rag_writer/prompts/task_prompt.py:8:def build_task_prompt(

thinking
**Searching for prompt policy module**
exec
bash -lc 'rg -n "prompt_mode" -n' in /var/home/rick/Development/llm_writer succeeded in 174ms:
tests/test_task_loading.py:52:        prompt_mode: "summary"
tests/test_task_loading.py:71:  assert url_ref.prompt_mode == "summary"
src/simple_rag_writer/tasks/models.py:17:  prompt_mode: Optional[str] = None
codex/LOGS/tasklog_07_implement_automated_task_runner_1763288534.log:138:  prompt_mode: Optional[str] = None
codex/TASKS/master_spec.yaml:468:          prompt_mode:
codex/TASKS/master_spec.yaml:571:        prompt_mode: "summary"
codex/TASKS/master_spec.yaml:580:        prompt_mode: "raw_capped"
codex/TASKS/master_spec.yaml:820:                  - Determine mode (reference.prompt_mode or config.mcp_prompt_policy.default_mode).
codex/LOGS/tasklog_04_define_task_spec_and_loader_1763287876.log:124:  prompt_mode: Optional[str] = None
codex/LOGS/tasklog_04_define_task_spec_and_loader_1763287876.log:357:        prompt_mode: "summary"
codex/LOGS/tasklog_04_define_task_spec_and_loader_1763287876.log:376:  assert url_ref.prompt_mode == "summary"
codex/LOGS/tasklog_04_define_task_spec_and_loader_1763287876.log:480:+        prompt_mode: "summary"
codex/LOGS/tasklog_04_define_task_spec_and_loader_1763287876.log:499:+  assert url_ref.prompt_mode == "summary"
codex/LOGS/tasklog_04_define_task_spec_and_loader_1763287876.log:601:+        prompt_mode: "summary"
codex/LOGS/tasklog_04_define_task_spec_and_loader_1763287876.log:620:+  assert url_ref.prompt_mode == "summary"
codex/LOGS/tasklog_04_define_task_spec_and_loader_1763287876.log:733:+        prompt_mode: "summary"
codex/LOGS/tasklog_04_define_task_spec_and_loader_1763287876.log:752:+  assert url_ref.prompt_mode == "summary"
codex/LOGS/tasklog_04_define_task_spec_and_loader_1763287876.log:852:+        prompt_mode: "summary"
codex/LOGS/tasklog_04_define_task_spec_and_loader_1763287876.log:871:+  assert url_ref.prompt_mode == "summary"
codex/LOGS/tasklog_04_define_task_spec_and_loader_1763287876.log:996:+        prompt_mode: "summary"

thinking
**Searching for prompt policy modules**
exec
bash -lc 'rg -n "prompt" src/simple_rag_writer | head' in /var/home/rick/Development/llm_writer succeeded in 43ms:
src/simple_rag_writer/tasks/models.py:17:  prompt_mode: Optional[str] = None
src/simple_rag_writer/runner/run_tasks.py:14:from simple_rag_writer.prompts.task_prompt import build_task_prompt
src/simple_rag_writer/runner/run_tasks.py:63:      prompt = build_task_prompt(task, outline_context, reference_blobs)
src/simple_rag_writer/runner/run_tasks.py:66:      output_text = registry.complete(prompt, model_id=model_id, task_params=task.model_params)
src/simple_rag_writer/replay/reconstruct.py:15:def reconstruct_prompt_for_turn(log_path: Path, turn_index: int) -> Tuple[str, ReplayMeta]:
src/simple_rag_writer/replay/reconstruct.py:16:  """Very rough placeholder: returns full log as prompt."""
src/simple_rag_writer/replay/reconstruct.py:21:def run_replay_prompt(registry: ModelRegistry, prompt: str, meta: ReplayMeta) -> str:
src/simple_rag_writer/replay/reconstruct.py:22:  return registry.complete(prompt)
src/simple_rag_writer/prompts/task_prompt.py:8:def build_task_prompt(
src/simple_rag_writer/prompts/planning.py:8:def build_planning_prompt(

thinking
**Searching for prompt policy implementation**
exec
bash -lc 'rg -n "prompt policy" -n src -n tests' in /var/home/rick/Development/llm_writer exited 1 in 42ms:


thinking
**Checking for prompt policy implementation**
exec
bash -lc 'rg -n "Normalized" -n' in /var/home/rick/Development/llm_writer succeeded in 45ms:
codex/LOGS/tasklog_07_implement_automated_task_runner_1763288534.log:168:from .types import NormalizedItem
codex/LOGS/tasklog_07_implement_automated_task_runner_1763288534.log:174:) -> List[NormalizedItem]:
codex/LOGS/tasklog_07_implement_automated_task_runner_1763288534.log:175:  """Convert raw MCP payload into a list of NormalizedItem."""
codex/LOGS/tasklog_07_implement_automated_task_runner_1763288534.log:176:  items: List[NormalizedItem] = []
codex/LOGS/tasklog_07_implement_automated_task_runner_1763288534.log:179:    items.append(NormalizedItem(body=payload, type=item_type_hint))
codex/LOGS/tasklog_07_implement_automated_task_runner_1763288534.log:183:        items.append(NormalizedItem(id=str(idx), body=entry, type=item_type_hint))
codex/LOGS/tasklog_07_implement_automated_task_runner_1763288534.log:202:class NormalizedItem(BaseModel):
codex/LOGS/tasklog_07_implement_automated_task_runner_1763288534.log:321:bash -lc 'rg -n "Normalized" -n' in /var/home/rick/Development/llm_writer
codex/LOGS/tasklog_06_implement_mcp_types_and_normalization_1763288389.log:61:  Implement the core MCP types (McpToolResult, NormalizedItem) and the
codex/LOGS/tasklog_06_implement_mcp_types_and_normalization_1763288389.log:69:  - NormalizedItem supports id, type, title, snippet, body, url, metadata.
codex/LOGS/tasklog_06_implement_mcp_types_and_normalization_1763288389.log:129:class NormalizedItem(BaseModel):
codex/LOGS/tasklog_06_implement_mcp_types_and_normalization_1763288389.log:145:from .types import NormalizedItem
codex/LOGS/tasklog_06_implement_mcp_types_and_normalization_1763288389.log:151:) -> List[NormalizedItem]:
codex/LOGS/tasklog_06_implement_mcp_types_and_normalization_1763288389.log:152:  """Convert raw MCP payload into a list of NormalizedItem."""
codex/LOGS/tasklog_06_implement_mcp_types_and_normalization_1763288389.log:153:  items: List[NormalizedItem] = []
codex/LOGS/tasklog_06_implement_mcp_types_and_normalization_1763288389.log:156:    items.append(NormalizedItem(body=payload, type=item_type_hint))
codex/LOGS/tasklog_06_implement_mcp_types_and_normalization_1763288389.log:160:        items.append(NormalizedItem(id=str(idx), body=entry, type=item_type_hint))
codex/LOGS/tasklog_06_implement_mcp_types_and_normalization_1763288389.log:165:bash -lc 'rg -n "Normalized" -n src/simple_rag_writer -g"*.py"' in /var/home/rick/Development/llm_writer succeeded in 43ms:
codex/LOGS/tasklog_06_implement_mcp_types_and_normalization_1763288389.log:166:src/simple_rag_writer/mcp/normalization.py:5:from .types import NormalizedItem
codex/LOGS/tasklog_06_implement_mcp_types_and_normalization_1763288389.log:167:src/simple_rag_writer/mcp/normalization.py:11:) -> List[NormalizedItem]:

thinking
**Inspecting tests directory**
exec
bash -lc 'ls tests' in /var/home/rick/Development/llm_writer succeeded in 38ms:
conftest.py
__pycache__
test_cli_parser.py
test_config_loader.py
test_llm_registry.py
test_mcp_normalization.py
test_prompt_building.py
test_task_loading.py

thinking
**Reviewing test strategy and dependencies**
exec
bash -lc "sed -n '1,200p' src/simple_rag_writer/llm/registry.py" in /var/home/rick/Development/llm_writer succeeded in 38ms:
from __future__ import annotations

import os
from typing import Any, Dict, List, Optional

try:
  import litellm
except ImportError:  # pragma: no cover - only triggered when dependency missing
  litellm = None

from simple_rag_writer.config.models import AppConfig, ModelConfig, ProviderConfig
from .params import merge_generation_params


class ModelRegistry:
  def __init__(self, config: AppConfig):
    self._config = config
    self._models: Dict[str, ModelConfig] = {m.id: m for m in config.models}
    if config.default_model not in self._models:
      raise ValueError(f"default_model {config.default_model} not found in models")

thinking
**Searching for prompt policy implementation**
exec
bash -lc 'rg -n "policy" -n src/simple_rag_writer' in /var/home/rick/Development/llm_writer succeeded in 43ms:
src/simple_rag_writer/config/models.py:67:  mcp_prompt_policy: McpPromptPolicy = Field(default_factory=McpPromptPolicy)

thinking
**Checking config models**
exec
bash -lc "sed -n '1,200p' src/simple_rag_writer/config/models.py" in /var/home/rick/Development/llm_writer succeeded in 38ms:
from __future__ import annotations

from pathlib import Path
from typing import Any, Dict, List, Literal, Optional

from pydantic import BaseModel, Field


class ProviderConfig(BaseModel):
  type: str
  api_key_env: Optional[str] = None
  api_key: Optional[str] = None
  base_url: Optional[str] = None
  model_prefix: Optional[str] = None


class ModelConfig(BaseModel):
  id: str
  provider: str
  model_name: str

thinking
**Investigating prompt policy implementation**
exec
bash -lc 'rg -n "prompt_policy" -n codex/TASKS/master_spec.yaml' in /var/home/rick/Development/llm_writer succeeded in 41ms:
250:    mcp_prompt_policy:
388:    mcp_prompt_policy:
820:                  - Determine mode (reference.prompt_mode or config.mcp_prompt_policy.default_mode).

thinking
**Searching for behavior instructions near line 820**
exec
bash -lc "sed -n '760,860p' codex/TASKS/master_spec.yaml" in /var/home/rick/Development/llm_writer succeeded in 37ms:
      responsibility: >
        Task orchestration: resolve outline context, resolve MCP/url references,
        apply MCP prompt policy and mcp_error_mode, call model, write output.
    - path: "simple_rag_writer/planner.py"
      responsibility: >
        Interactive planning REPL using Rich; supports slash commands,
        model switching, MCP /sources and /use, and PlanningLogWriter for logs.
    - path: "simple_rag_writer/logging.py"
      responsibility: "Implementation of PlanningLogWriter and related helpers."
    - path: "simple_rag_writer/replay.py"
      responsibility: >
        Functions to parse a planning log, reconstruct the prompt for a given
        turn (including MCP context), and optionally re-run it via ModelRegistry.

  data_flow:
    planning_mode:
      steps:
        - Parse CLI args; load AppConfig.
        - Initialize ModelRegistry with config.
        - Create PlanningLogWriter via from_config().

thinking
**Reviewing specification and tests**
exec
bash -lc "sed -n '1,200p' tests/test_task_loading.py" in /var/home/rick/Development/llm_writer succeeded in 38ms:
from __future__ import annotations

from pathlib import Path
from textwrap import dedent

from simple_rag_writer.tasks.loader import expand_task_paths, load_task


def _write_task(tmp_path: Path, name: str, body: str) -> Path:
  path = tmp_path / name
  path.write_text(dedent(body), encoding="utf-8")
  return path


def test_load_minimal_task_spec(tmp_path: Path) -> None:
  task_path = _write_task(
    tmp_path,
    "task_minimal.yaml",
    """
    title: "Chapter Prelude"

thinking
**Planning new runner and prompt policy tests**
exec
bash -lc 'rg -n "prompt_policy" tests' in /var/home/rick/Development/llm_writer succeeded in 41ms:
tests/test_config_loader.py:35:    mcp_prompt_policy:
tests/test_config_loader.py:64:  assert cfg.mcp_prompt_policy.default_mode == "summary"
tests/test_config_loader.py:89:def test_load_config_rejects_invalid_prompt_policy_mode(tmp_path: Path) -> None:
tests/test_config_loader.py:100:    mcp_prompt_policy:
exec
bash -lc "sed -n '1,200p' tests/test_config_loader.py" in /var/home/rick/Development/llm_writer succeeded in 38ms:
from pathlib import Path
from textwrap import dedent

import pytest
from pydantic import ValidationError

from simple_rag_writer.config.loader import load_config


def test_load_config_round_trip(tmp_path: Path) -> None:
  cfg_text = dedent(
    """
    default_model: "openai:gpt-4.1-mini"
    providers:
      openai:
        type: "openai"
        api_key_env: "OPENAI_API_KEY"
      openrouter:
        type: "openrouter"
        api_key_env: "OPENROUTER_API_KEY"

thinking
**Searching for raw_capped references**
exec
bash -lc 'rg -n "raw_capped" -n' in /var/home/rick/Development/llm_writer succeeded in 42ms:
README.md:42:  default_mode: "raw_capped"
tests/test_config_loader.py:37:      raw_capped:
codex/LOGS/tasklog_07_implement_automated_task_runner_1763288534.log:282:codex/TASKS/master_spec.yaml:580:        prompt_mode: "raw_capped"
codex/LOGS/tasklog_07_implement_automated_task_runner_1763288534.log:502:**Searching for raw_capped references**
codex/LOGS/tasklog_07_implement_automated_task_runner_1763288534.log:504:bash -lc 'rg -n "raw_capped" -n' in /var/home/rick/Development/llm_writer
codex/LOGS/tasklog_02_implement_config_models_and_loader_1763287503.log:61:    - MCP prompt policy (raw_capped, summary).
codex/LOGS/tasklog_02_implement_config_models_and_loader_1763287503.log:376:+      raw_capped:
codex/LOGS/tasklog_02_implement_config_models_and_loader_1763287503.log:484:+      raw_capped:
codex/LOGS/tasklog_02_implement_config_models_and_loader_1763287503.log:591:+      raw_capped:
codex/LOGS/tasklog_02_implement_config_models_and_loader_1763287503.log:725:+      raw_capped:
codex/LOGS/tasklog_02_implement_config_models_and_loader_1763287503.log:857:+      raw_capped:
codex/LOGS/tasklog_02_implement_config_models_and_loader_1763287503.log:989:+      raw_capped:
codex/LOGS/tasklog_02_implement_config_models_and_loader_1763287503.log:1118:+      raw_capped:
codex/LOGS/tasklog_02_implement_config_models_and_loader_1763287503.log:1250:+      raw_capped:
codex/LOGS/tasklog_02_implement_config_models_and_loader_1763287503.log:1393:+      raw_capped:
codex/LOGS/tasklog_02_implement_config_models_and_loader_1763287503.log:1524:+      raw_capped:
codex/LOGS/tasklog_02_implement_config_models_and_loader_1763287503.log:1680:+      raw_capped:
codex/LOGS/tasklog_02_implement_config_models_and_loader_1763287503.log:1818:+      raw_capped:
codex/LOGS/tasklog_02_implement_config_models_and_loader_1763287503.log:1999:+      raw_capped:
codex/LOGS/tasklog_02_implement_config_models_and_loader_1763287503.log:2156:+      raw_capped:

thinking
**Searching for automated runner info**
exec
bash -lc 'rg -n "runner" -n README.md' in /var/home/rick/Development/llm_writer exited 1 in 41ms:


thinking
**Checking README for instructions**
exec
bash -lc "sed -n '1,200p' README.md" in /var/home/rick/Development/llm_writer succeeded in 38ms:
# Simple Rag Writer

Early scaffold for a slim writing assistant that:
- Uses multiple LLM providers (OpenAI, OpenRouter, Gemini) via `litellm`.
- Uses MCP servers as its only retrieval/knowledge layer.
- Supports interactive planning (`srw -c config.yaml plan`).
- Supports automated task execution from YAML (`srw -c config.yaml run tasks/*.yaml`).
- Supports replaying planning prompts from logs (`srw -c config.yaml replay --log ... --turn ...`).

This is an incomplete scaffold intended for test-driven development.
Many components are stubs with TODOs.

## Getting Started

```bash
python -m venv .venv
source .venv/bin/activate
pip install -e .
srw --help
srw -c config.yaml plan

thinking
**Inspecting CLI run command integration**
exec
bash -lc "sed -n '1,200p' src/simple_rag_writer/cli/run.py" in /var/home/rick/Development/llm_writer succeeded in 38ms:
from __future__ import annotations

from pathlib import Path
from typing import Iterable

from rich.console import Console

from simple_rag_writer.config.models import AppConfig
from simple_rag_writer.llm.registry import ModelRegistry
from simple_rag_writer.runner.run_tasks import run_tasks_for_paths

console = Console()


def run_automated_mode(config: AppConfig, task_paths: Iterable[str]) -> int:
  registry = ModelRegistry(config)
  task_paths_resolved = [Path(p) for p in task_paths]
  result = run_tasks_for_paths(config, registry, task_paths_resolved)
  if not result.ok:
    console.print("[red]Some tasks failed[/red]")

thinking
**Preparing to implement URL fetcher**

I’m getting ready to build the run_tasks logic and particularly the URL fetcher module, which will need integrated tests. Before diving in, I want to confirm dependencies like httpx and review the project structure, especially test directories, to understand how tasks integrate and ensure my approach fits well with TDD practices. Using a planning tool seems wise since this involves multi-step changes.
exec
bash -lc 'cat pyproject.toml' in /var/home/rick/Development/llm_writer succeeded in 37ms:
[build-system]
requires = ["setuptools>=61"]
build-backend = "setuptools.build_meta"

[project]
name = "simple-rag-writer"
version = "0.0.1"
description = "Simplified rag_writer-style tool with MCP and multi-provider LLMs"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
  "pydantic>=2.0",
  "PyYAML>=6.0",
  "rich>=13.0",
  "litellm>=1.0.0",
]

[project.optional-dependencies]
dev = [
  "pytest>=7.0",

thinking
**Evaluating HTTP fetching and HTML parsing strategies**

I'm weighing trade-offs between adding new dependencies like `httpx` and `beautifulsoup4` versus using Python's standard libraries like `urllib` and `html.parser` to keep things lightweight. I’m sketching out a plan to handle URL fetching that supports both `file://` and HTTP schemes, with a custom HTML-to-text converter using `HTMLParser` to cleanly extract text while skipping scripts and styles. I’m also thinking ahead about how this will fit with the prompt policy and summarization layers later on.
exec
bash -lc 'rg -n "summary" -n src/simple_rag_writer' in /var/home/rick/Development/llm_writer succeeded in 42ms:
src/simple_rag_writer/tasks/models.py:20:  summary_max_tokens: Optional[int] = None
src/simple_rag_writer/config/models.py:33:  summary_max_tokens: int = 512
src/simple_rag_writer/config/models.py:39:  default_mode: Literal["raw_capped", "summary"] = "raw_capped"
src/simple_rag_writer/config/models.py:41:  summary: SummaryPolicy = Field(default_factory=SummaryPolicy)

thinking
**Designing summary mode implementation**

I'm piecing together how run_tasks should handle summary mode by calling the ModelRegistry's summarizer model with type-specific or default prompts, capping output tokens, and ensuring registry access for summarization; I'll also consider adding tests to verify this behavior and explore prompt policies and per-type prompt configurations as specified.
exec
bash -lc 'rg -n "per_type_prompts" -n src tests codex/TASKS/master_spec.yaml' in /var/home/rick/Development/llm_writer succeeded in 42ms:
codex/TASKS/master_spec.yaml:295:                per_type_prompts:
codex/TASKS/master_spec.yaml:398:        per_type_prompts:
tests/test_config_loader.py:42:        per_type_prompts:
src/simple_rag_writer/config/models.py:34:  per_type_prompts: Dict[str, str] = Field(default_factory=dict)

thinking
**Checking spec snippet location**
exec
bash -lc "sed -n '280,360p' codex/TASKS/master_spec.yaml" in /var/home/rick/Development/llm_writer succeeded in 37ms:
              Settings for summary mode. In summary mode, the client passes
              full item bodies to the summarizer and relies on the LLM +
              summary_max_tokens to control length. No pre-truncation of
              bodies is performed.
            SummaryPolicy:
              fields:
                summarizer_model:
                  type: string
                  default: "openai:gpt-4.1-mini"
                max_items_per_reference:
                  type: int
                  default: 10
                summary_max_tokens:
                  type: int
                  default: 512
                per_type_prompts:
                  type: map<string, string>
                  required: false
                  description: >
                    Optional mapping from logical item type to a specialized

thinking
**Designing reference summarization and fetching**

I'll lay out how to implement default summarization prompts and handle reference items with modes like raw_capped and summary. I need to carefully manage per-reference overrides for limits and prompt modes, plus normalize various reference types (MCP calls, URLs, files) into NormalizedItems. I'll also plan to write a URL fetcher module with error handling and tests, likely using a multi-step plan to keep things clear and testable.
Plan update
Implementing automated task runner with URL support touches new tests, helper module, and run pipeline complexity, so laying out a plan will keep TDD steps clear.
  → Review existing runner behavior/spec and design tests for MCP+URL orchestration and error handling
  • Implement runner/url_fetcher helper plus prompt-policy processing in run_tasks
  • Run pytest and finalize changes

thinking
**Preparing to design new tests**
exec
bash -lc "sed -n '1,200p' tests/test_llm_registry.py" in /var/home/rick/Development/llm_writer succeeded in 37ms:
from types import SimpleNamespace

import pytest

from simple_rag_writer.config.models import AppConfig, ModelConfig, ProviderConfig
from simple_rag_writer.llm.registry import ModelRegistry


def test_model_registry_sets_and_switches_current_model():
  cfg = AppConfig(
    default_model="openai:gpt-4.1-mini",
    providers={
      "openai": ProviderConfig(type="openai", api_key="test-key"),
    },
    models=[
      ModelConfig(
        id="openai:gpt-4.1-mini",
        provider="openai",
        model_name="gpt-4.1-mini",
      ),

thinking
**Preparing test strategy for run_tasks**

I’m mapping out how to test `run_tasks` by faking dependencies like `McpClient`, `ModelRegistry`, and `normalize_payload`. I’ll patch these to control inputs and outputs, focusing on verifying that URL-fetched text is correctly included in prompts sent to a fake registry’s `complete` method. I plan to create minimal config objects and stub classes to avoid running real network or model calls. Let’s see how the tests fit together!
exec
bash -lc "sed -n '1,200p' tests/conftest.py" in /var/home/rick/Development/llm_writer succeeded in 38ms:
import sys
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
SRC = ROOT / "src"
if str(SRC) not in sys.path:
  sys.path.insert(0, str(SRC))


thinking
**Designing comprehensive run_tasks tests**

I'm working through detailed plans for testing the run_tasks function, focusing on instantiating AppConfig with custom prompt policies, patching key components like McpClient and fetch_url_text, and creating dummy registries to verify that summaries and raw modes behave as expected—including coverage for URL and MCP references, error handling, prompt composition, and ensuring correct model usage in summary calls. This approach carefully sets up test scenarios to check that prompts include relevant reference text and that warnings are logged appropriately.
thinking
**Planning run_tasks output and error handling tests**

I'm sorting out how to test writing final output file content and check it includes expected summary and MCP reference text, while also designing a second test to simulate URL fetch failure that logs a warning but still completes successfully. These tests will patch key components like McpClient and fetch_url_text, capture console output for warnings, and verify the correct sequence and content of registry completion calls along with file outputs.

thinking
**Retrying patch application**
file update
A /var/home/rick/Development/llm_writer/tests/test_runner_run_tasks.py
from __future__ import annotations

from io import StringIO
from pathlib import Path
from textwrap import dedent

from rich.console import Console

from simple_rag_writer.config.models import (
  AppConfig,
  McpPromptPolicy,
  ModelConfig,
  ProviderConfig,
  RawCappedPolicy,
  SummaryPolicy,
)
from simple_rag_writer.mcp.types import McpToolResult
from simple_rag_writer.runner.run_tasks import run_tasks_for_paths


class DummyRegistry:
  def __init__(self) -> None:
    self.calls = []

  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
    call = {
      "prompt": prompt,
      "model_id": model_id,
      "task_params": task_params,
    }
    self.calls.append(call)
    if model_id == "summary-model":
      return "URL SUMMARY"
    return "FINAL OUTPUT"


def _make_config() -> AppConfig:
  return AppConfig(
    default_model="writer-model",
    providers={
      "local": ProviderConfig(type="openai", api_key="dummy"),
    },
    models=[
      ModelConfig(id="writer-model", provider="local", model_name="writer"),
      ModelConfig(id="summary-model", provider="local", model_name="summary"),
    ],
    mcp_prompt_policy=McpPromptPolicy(
      default_mode="raw_capped",
      raw_capped=RawCappedPolicy(
        max_items_per_reference=5,
        max_chars_per_item=200,
        max_total_chars=2000,
      ),
      summary=SummaryPolicy(
        summarizer_model="summary-model",
        default_prompt="Summarize the material.",
        summary_max_tokens=128,
      ),
    ),
  )


def _write_task(tmp_path: Path, body: str) -> Path:
  path = tmp_path / "task.yaml"
  path.write_text(dedent(body), encoding="utf-8")
  return path


def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
  config = _make_config()
  registry = DummyRegistry()

  class FakeMcpClient:
    def __init__(self, _config):
      self.calls = []

    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
      self.calls.append((server, tool, params))
      return McpToolResult(
        server_id=server,
        tool_name=tool,
        payload=[
          {
            "title": "Notebook entry",
            "body": "Alpha body",
          }
        ],
      )

  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
  monkeypatch.setattr(
    "simple_rag_writer.runner.run_tasks.fetch_url_text",
    lambda url: "URL page text for " + url,
  )

  output_path = tmp_path / "drafts" / "chapter.md"
  task_path = _write_task(
    tmp_path,
    f"""
    title: "Chapter"
    id: "ch01"
    description: "Write the chapter"
    output: "{output_path}"
    references:
      - type: "mcp"
        label: "Notes"
        server: "notes"
        tool: "search"
      - type: "url"
        label: "Spec"
        url: "https://example.com/spec"
        prompt_mode: "summary"
    """,
  )

  result = run_tasks_for_paths(config, registry, [task_path])

  assert result.ok is True
  assert len(registry.calls) == 2
  summary_call, final_call = registry.calls
  assert summary_call["model_id"] == "summary-model"
  assert "URL page text" in summary_call["prompt"]
  assert final_call["model_id"] == "writer-model"
  assert "URL SUMMARY" in final_call["prompt"]
  assert "Notebook entry" in final_call["prompt"]
  assert output_path.exists()
  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"


def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
  config = _make_config()
  registry = DummyRegistry()

  class FakeMcpClient:
    def __init__(self, _config):
      pass

    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
      return McpToolResult(
        server_id=server,
        tool_name=tool,
        payload=[{"title": "Doc", "body": "Reference body"}],
      )

  console_output = StringIO()
  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
  monkeypatch.setattr(
    "simple_rag_writer.runner.run_tasks.fetch_url_text",
    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
  )
  monkeypatch.setattr(
    "simple_rag_writer.runner.run_tasks.console",
    Console(file=console_output, force_terminal=False, color_system=None),
  )

  output_path = tmp_path / "drafts" / "chapter.md"
  task_path = _write_task(
    tmp_path,
    f"""
    title: "Chapter"
    id: "ch01"
    description: "Write the chapter"
    output: "{output_path}"
    references:
      - type: "url"
        label: "Spec"
        url: "https://example.com/spec"
      - type: "mcp"
        label: "Notes"
        server: "notes"
        tool: "search"
    """,
  )

  result = run_tasks_for_paths(config, registry, [task_path])

  assert result.ok is True
  assert len(registry.calls) == 1
  assert "Reference body" in registry.calls[0]["prompt"]
  log_text = console_output.getvalue()
  assert "URL" in log_text and "failed" in log_text.lower()
  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
apply_patch(auto_approved=true) exited 0 in 5ms:
Success. Updated the following files:
A tests/test_runner_run_tasks.py
file update:
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"

file update:
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"


thinking
**Verifying test failures before implementation**
exec
bash -lc 'pytest tests/test_runner_run_tasks.py' in /var/home/rick/Development/llm_writer exited 1 in 1.59s:
============================= test session starts ==============================
platform linux -- Python 3.13.9, pytest-8.4.2, pluggy-1.6.0
rootdir: /var/home/rick/Development/llm_writer
configfile: pyproject.toml
plugins: Faker-37.8.0, xdist-3.8.0, mock-3.15.1, metadata-3.1.1, cov-7.0.0, asyncio-1.2.0, html-4.1.1, hypothesis-6.141.1, anyio-4.8.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collected 2 items

tests/test_runner_run_tasks.py FF                                        [100%]

=================================== FAILURES ===================================
__________________ test_run_tasks_includes_url_reference_text __________________

obj = <module 'simple_rag_writer.runner.run_tasks' from '/var/home/rick/Development/llm_writer/src/simple_rag_writer/runner/run_tasks.py'>
name = 'fetch_url_text', ann = 'simple_rag_writer.runner.run_tasks'

    def annotated_getattr(obj: object, name: str, ann: str) -> object:
        try:
>           obj = getattr(obj, name)
                  ^^^^^^^^^^^^^^^^^^
file update:
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"


thinking
**Implementing URL fetching and prompt policy logic**

I'm planning to create a new `url_fetcher.py` module to fetch text from URLs or local files, including HTML-to-text parsing. Then I'll enhance `run_tasks` to handle references by fetching URLs, converting data into normalized items, applying prompt policies for summary or raw rendering, and assembling reference blobs accordingly while managing errors and logging. This involves defining helper functions for policy application, formatting items, summarization prompts, and integrating everything with proper imports and type hints. I'll keep tests updated to patch the fetching functionality.
exec
bash -lc "sed -n '1,200p' src/simple_rag_writer/runner/__init__.py" in /var/home/rick/Development/llm_writer succeeded in 38ms:

file update:
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"


thinking
**Detailing run_tasks enhancements**

I'm working through a detailed plan to improve `run_tasks` by adding imports, helper functions, and reference-handling logic, including robust support for URL references and summary building using policies and normalized items. I’m carefully ensuring type annotations, error handling, and seamless integration with the existing MCP client and summary registry. There is a lot to coordinate, so I’m laying out each piece before coding.
Plan update
  ✓ Review existing runner behavior/spec and design tests for MCP+URL orchestration and error handling
  → Implement runner/url_fetcher helper plus prompt-policy processing in run_tasks
  • Run pytest and finalize changes
file update:
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"


thinking
**Implementing URL fetcher module**
file update
A /var/home/rick/Development/llm_writer/src/simple_rag_writer/runner/url_fetcher.py
from __future__ import annotations

from html.parser import HTMLParser
from pathlib import Path
from typing import Optional
from urllib.parse import unquote, urlparse
from urllib.request import Request, url2pathname, urlopen

DEFAULT_USER_AGENT = "simple-rag-writer/0.1"


class _HTMLToTextParser(HTMLParser):
  def __init__(self) -> None:
    super().__init__()
    self._parts: list[str] = []
    self._skip_depth = 0

  def handle_starttag(self, tag: str, attrs):  # type: ignore[override]
    lowered = tag.lower()
    if lowered in {"br", "p", "div", "section", "article", "li", "tr"}:
      self._parts.append("\n")
    if lowered in {"script", "style"}:
      self._skip_depth += 1

  def handle_endtag(self, tag: str):  # type: ignore[override]
    lowered = tag.lower()
    if lowered in {"script", "style"} and self._skip_depth:
      self._skip_depth -= 1
    elif lowered in {"p", "div", "section", "article", "li"}:
      self._parts.append("\n")

  def handle_data(self, data: str):  # type: ignore[override]
    if self._skip_depth:
      return
    if data.strip():
      self._parts.append(data)

  def get_text(self) -> str:
    raw = "".join(self._parts)
    lines = [line.strip() for line in raw.splitlines()]
    filtered = "\n".join(line for line in lines if line)
    return filtered.strip()


def _extract_file_path(url: str) -> Path:
  parsed = urlparse(url)
  path = unquote(parsed.path or "")
  if parsed.netloc:
    path = f"//{parsed.netloc}{path}"
  fs_path = Path(url2pathname(path))
  return fs_path


def _html_to_text(html: str) -> str:
  parser = _HTMLToTextParser()
  parser.feed(html)
  parser.close()
  text = parser.get_text()
  return text or html


def fetch_url_text(url: str, *, timeout: float = 15.0) -> str:
  parsed = urlparse(url)
  scheme = (parsed.scheme or "").lower()

  if scheme in {"", "file"}:
    path = _extract_file_path(url)
    return path.read_text(encoding="utf-8")

  if scheme not in {"http", "https"}:
    raise ValueError(f"Unsupported URL scheme: {parsed.scheme or 'unknown'}")

  request = Request(url, headers={"User-Agent": DEFAULT_USER_AGENT})
  with urlopen(request, timeout=timeout) as response:  # nosec: B310 in controlled use
    content_type = response.headers.get("Content-Type", "")
    charset: Optional[str] = None
    try:
      charset = response.headers.get_content_charset()  # type: ignore[attr-defined]
    except Exception:  # pragma: no cover - very old Python versions only
      charset = None
    data = response.read()

  encoding = charset or "utf-8"
  text = data.decode(encoding, errors="replace")
  if "html" in content_type.lower():
    return _html_to_text(text)
  return text


__all__ = ["fetch_url_text"]
apply_patch(auto_approved=true) exited 0 in 6ms:
Success. Updated the following files:
A src/simple_rag_writer/runner/url_fetcher.py
file update:
diff --git a/src/simple_rag_writer/runner/url_fetcher.py b/src/simple_rag_writer/runner/url_fetcher.py
new file mode 100644
index 0000000000000000000000000000000000000000..00abbf5049f05fcbcf0b5805378d5032ed50e20c
--- /dev/null
+++ b/src/simple_rag_writer/runner/url_fetcher.py
@@ -0,0 +1,90 @@
+from __future__ import annotations
+
+from html.parser import HTMLParser
+from pathlib import Path
+from typing import Optional
+from urllib.parse import unquote, urlparse
+from urllib.request import Request, url2pathname, urlopen
+
+DEFAULT_USER_AGENT = "simple-rag-writer/0.1"
+
+
+class _HTMLToTextParser(HTMLParser):
+  def __init__(self) -> None:
+    super().__init__()
+    self._parts: list[str] = []
+    self._skip_depth = 0
+
+  def handle_starttag(self, tag: str, attrs):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"br", "p", "div", "section", "article", "li", "tr"}:
+      self._parts.append("\n")
+    if lowered in {"script", "style"}:
+      self._skip_depth += 1
+
+  def handle_endtag(self, tag: str):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"script", "style"} and self._skip_depth:
+      self._skip_depth -= 1
+    elif lowered in {"p", "div", "section", "article", "li"}:
+      self._parts.append("\n")
+
+  def handle_data(self, data: str):  # type: ignore[override]
+    if self._skip_depth:
+      return
+    if data.strip():
+      self._parts.append(data)
+
+  def get_text(self) -> str:
+    raw = "".join(self._parts)
+    lines = [line.strip() for line in raw.splitlines()]
+    filtered = "\n".join(line for line in lines if line)
+    return filtered.strip()
+
+
+def _extract_file_path(url: str) -> Path:
+  parsed = urlparse(url)
+  path = unquote(parsed.path or "")
+  if parsed.netloc:
+    path = f"//{parsed.netloc}{path}"
+  fs_path = Path(url2pathname(path))
+  return fs_path
+
+
+def _html_to_text(html: str) -> str:
+  parser = _HTMLToTextParser()
+  parser.feed(html)
+  parser.close()
+  text = parser.get_text()
+  return text or html
+
+
+def fetch_url_text(url: str, *, timeout: float = 15.0) -> str:
+  parsed = urlparse(url)
+  scheme = (parsed.scheme or "").lower()
+
+  if scheme in {"", "file"}:
+    path = _extract_file_path(url)
+    return path.read_text(encoding="utf-8")
+
+  if scheme not in {"http", "https"}:
+    raise ValueError(f"Unsupported URL scheme: {parsed.scheme or 'unknown'}")
+
+  request = Request(url, headers={"User-Agent": DEFAULT_USER_AGENT})
+  with urlopen(request, timeout=timeout) as response:  # nosec: B310 in controlled use
+    content_type = response.headers.get("Content-Type", "")
+    charset: Optional[str] = None
+    try:
+      charset = response.headers.get_content_charset()  # type: ignore[attr-defined]
+    except Exception:  # pragma: no cover - very old Python versions only
+      charset = None
+    data = response.read()
+
+  encoding = charset or "utf-8"
+  text = data.decode(encoding, errors="replace")
+  if "html" in content_type.lower():
+    return _html_to_text(text)
+  return text
+
+
+__all__ = ["fetch_url_text"]
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"

file update:
diff --git a/src/simple_rag_writer/runner/url_fetcher.py b/src/simple_rag_writer/runner/url_fetcher.py
new file mode 100644
index 0000000000000000000000000000000000000000..00abbf5049f05fcbcf0b5805378d5032ed50e20c
--- /dev/null
+++ b/src/simple_rag_writer/runner/url_fetcher.py
@@ -0,0 +1,90 @@
+from __future__ import annotations
+
+from html.parser import HTMLParser
+from pathlib import Path
+from typing import Optional
+from urllib.parse import unquote, urlparse
+from urllib.request import Request, url2pathname, urlopen
+
+DEFAULT_USER_AGENT = "simple-rag-writer/0.1"
+
+
+class _HTMLToTextParser(HTMLParser):
+  def __init__(self) -> None:
+    super().__init__()
+    self._parts: list[str] = []
+    self._skip_depth = 0
+
+  def handle_starttag(self, tag: str, attrs):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"br", "p", "div", "section", "article", "li", "tr"}:
+      self._parts.append("\n")
+    if lowered in {"script", "style"}:
+      self._skip_depth += 1
+
+  def handle_endtag(self, tag: str):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"script", "style"} and self._skip_depth:
+      self._skip_depth -= 1
+    elif lowered in {"p", "div", "section", "article", "li"}:
+      self._parts.append("\n")
+
+  def handle_data(self, data: str):  # type: ignore[override]
+    if self._skip_depth:
+      return
+    if data.strip():
+      self._parts.append(data)
+
+  def get_text(self) -> str:
+    raw = "".join(self._parts)
+    lines = [line.strip() for line in raw.splitlines()]
+    filtered = "\n".join(line for line in lines if line)
+    return filtered.strip()
+
+
+def _extract_file_path(url: str) -> Path:
+  parsed = urlparse(url)
+  path = unquote(parsed.path or "")
+  if parsed.netloc:
+    path = f"//{parsed.netloc}{path}"
+  fs_path = Path(url2pathname(path))
+  return fs_path
+
+
+def _html_to_text(html: str) -> str:
+  parser = _HTMLToTextParser()
+  parser.feed(html)
+  parser.close()
+  text = parser.get_text()
+  return text or html
+
+
+def fetch_url_text(url: str, *, timeout: float = 15.0) -> str:
+  parsed = urlparse(url)
+  scheme = (parsed.scheme or "").lower()
+
+  if scheme in {"", "file"}:
+    path = _extract_file_path(url)
+    return path.read_text(encoding="utf-8")
+
+  if scheme not in {"http", "https"}:
+    raise ValueError(f"Unsupported URL scheme: {parsed.scheme or 'unknown'}")
+
+  request = Request(url, headers={"User-Agent": DEFAULT_USER_AGENT})
+  with urlopen(request, timeout=timeout) as response:  # nosec: B310 in controlled use
+    content_type = response.headers.get("Content-Type", "")
+    charset: Optional[str] = None
+    try:
+      charset = response.headers.get_content_charset()  # type: ignore[attr-defined]
+    except Exception:  # pragma: no cover - very old Python versions only
+      charset = None
+    data = response.read()
+
+  encoding = charset or "utf-8"
+  text = data.decode(encoding, errors="replace")
+  if "html" in content_type.lower():
+    return _html_to_text(text)
+  return text
+
+
+__all__ = ["fetch_url_text"]
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"


thinking
**Preparing for extensive file modification**
exec
bash -lc "sed -n '1,200p' src/simple_rag_writer/runner/run_tasks.py" in /var/home/rick/Development/llm_writer succeeded in 42ms:
from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import List

from rich.console import Console

from simple_rag_writer.config.models import AppConfig
from simple_rag_writer.llm.registry import ModelRegistry
from simple_rag_writer.tasks.loader import load_task, expand_task_paths
from simple_rag_writer.mcp.client import McpClient
from simple_rag_writer.mcp.normalization import normalize_payload
from simple_rag_writer.prompts.task_prompt import build_task_prompt

console = Console()


@dataclass
class RunTasksResult:
file update:
diff --git a/src/simple_rag_writer/runner/url_fetcher.py b/src/simple_rag_writer/runner/url_fetcher.py
new file mode 100644
index 0000000000000000000000000000000000000000..00abbf5049f05fcbcf0b5805378d5032ed50e20c
--- /dev/null
+++ b/src/simple_rag_writer/runner/url_fetcher.py
@@ -0,0 +1,90 @@
+from __future__ import annotations
+
+from html.parser import HTMLParser
+from pathlib import Path
+from typing import Optional
+from urllib.parse import unquote, urlparse
+from urllib.request import Request, url2pathname, urlopen
+
+DEFAULT_USER_AGENT = "simple-rag-writer/0.1"
+
+
+class _HTMLToTextParser(HTMLParser):
+  def __init__(self) -> None:
+    super().__init__()
+    self._parts: list[str] = []
+    self._skip_depth = 0
+
+  def handle_starttag(self, tag: str, attrs):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"br", "p", "div", "section", "article", "li", "tr"}:
+      self._parts.append("\n")
+    if lowered in {"script", "style"}:
+      self._skip_depth += 1
+
+  def handle_endtag(self, tag: str):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"script", "style"} and self._skip_depth:
+      self._skip_depth -= 1
+    elif lowered in {"p", "div", "section", "article", "li"}:
+      self._parts.append("\n")
+
+  def handle_data(self, data: str):  # type: ignore[override]
+    if self._skip_depth:
+      return
+    if data.strip():
+      self._parts.append(data)
+
+  def get_text(self) -> str:
+    raw = "".join(self._parts)
+    lines = [line.strip() for line in raw.splitlines()]
+    filtered = "\n".join(line for line in lines if line)
+    return filtered.strip()
+
+
+def _extract_file_path(url: str) -> Path:
+  parsed = urlparse(url)
+  path = unquote(parsed.path or "")
+  if parsed.netloc:
+    path = f"//{parsed.netloc}{path}"
+  fs_path = Path(url2pathname(path))
+  return fs_path
+
+
+def _html_to_text(html: str) -> str:
+  parser = _HTMLToTextParser()
+  parser.feed(html)
+  parser.close()
+  text = parser.get_text()
+  return text or html
+
+
+def fetch_url_text(url: str, *, timeout: float = 15.0) -> str:
+  parsed = urlparse(url)
+  scheme = (parsed.scheme or "").lower()
+
+  if scheme in {"", "file"}:
+    path = _extract_file_path(url)
+    return path.read_text(encoding="utf-8")
+
+  if scheme not in {"http", "https"}:
+    raise ValueError(f"Unsupported URL scheme: {parsed.scheme or 'unknown'}")
+
+  request = Request(url, headers={"User-Agent": DEFAULT_USER_AGENT})
+  with urlopen(request, timeout=timeout) as response:  # nosec: B310 in controlled use
+    content_type = response.headers.get("Content-Type", "")
+    charset: Optional[str] = None
+    try:
+      charset = response.headers.get_content_charset()  # type: ignore[attr-defined]
+    except Exception:  # pragma: no cover - very old Python versions only
+      charset = None
+    data = response.read()
+
+  encoding = charset or "utf-8"
+  text = data.decode(encoding, errors="replace")
+  if "html" in content_type.lower():
+    return _html_to_text(text)
+  return text
+
+
+__all__ = ["fetch_url_text"]
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"


thinking
**Preparing patch outline and imports**
file update
M /var/home/rick/Development/llm_writer/src/simple_rag_writer/runner/run_tasks.py
@@ -4,3 +4,3 @@
 from pathlib import Path
-from typing import List
+from typing import List, Optional
 
@@ -8,10 +8,17 @@
 
-from simple_rag_writer.config.models import AppConfig
+from simple_rag_writer.config.models import AppConfig, RawCappedPolicy, SummaryPolicy
 from simple_rag_writer.llm.registry import ModelRegistry
-from simple_rag_writer.tasks.loader import load_task, expand_task_paths
 from simple_rag_writer.mcp.client import McpClient
 from simple_rag_writer.mcp.normalization import normalize_payload
+from simple_rag_writer.mcp.types import NormalizedItem
 from simple_rag_writer.prompts.task_prompt import build_task_prompt
+from simple_rag_writer.runner.url_fetcher import fetch_url_text
+from simple_rag_writer.tasks.loader import expand_task_paths, load_task
+from simple_rag_writer.tasks.models import McpReference, ReferenceCommon, TaskSpec, UrlReference
 
 console = Console()
+DEFAULT_SUMMARY_PROMPT = (
+  "Summarize the following reference material into key bullet points, highlighting"
+  " actionable facts and important context."
+)
 
@@ -24,2 +31,118 @@
 
+def _format_item(item: NormalizedItem) -> str:
+  parts: List[str] = []
+  if item.title:
+    parts.append(f"Title: {item.title}")
+  if item.url:
+    parts.append(f"URL: {item.url}")
+  body = (item.body or item.snippet or "").strip()
+  if body:
+    parts.append(body)
+  elif item.metadata:
+    parts.append(str(item.metadata))
+  return "\n".join(parts).strip()
+
+
+def _render_raw_blob(reference: ReferenceCommon, items: List[NormalizedItem], policy: RawCappedPolicy) -> Optional[str]:
+  if not items:
+    return None
+  per_item_limit = reference.max_chars or policy.max_chars_per_item
+  total_limit = policy.max_total_chars
+  max_items = reference.max_items or policy.max_items_per_reference
+  chunks: List[str] = []
+  used = 0
+  for item in items[:max_items]:
+    formatted = _format_item(item)
+    if not formatted:
+      continue
+    snippet = formatted[:per_item_limit].strip()
+    if not snippet:
+      continue
+    if used + len(snippet) > total_limit:
+      remaining = total_limit - used
+      if remaining <= 0:
+        break
+      snippet = snippet[:remaining].rstrip()
+    chunks.append(snippet)
+    used += len(snippet)
+    if used >= total_limit:
+      break
+  if not chunks:
+    return None
+  return "\n\n".join(chunks)
+
+
+def _build_summary_prompt(reference: ReferenceCommon, items: List[NormalizedItem], policy: SummaryPolicy) -> str:
+  ref_type = reference.item_type or next((itm.type for itm in items if itm.type), None)
+  template = None
+  if ref_type:
+    template = policy.per_type_prompts.get(ref_type)
+  if not template:
+    template = policy.default_prompt or DEFAULT_SUMMARY_PROMPT
+  sections: List[str] = []
+  for idx, item in enumerate(items, start=1):
+    heading = item.title or f"Item {idx}"
+    body = (item.body or item.snippet or "").strip()
+    lines = [f"## {heading}"]
+    if body:
+      lines.append(body)
+    if item.url:
+      lines.append(f"Source: {item.url}")
+    sections.append("\n".join(lines).strip())
+  body_text = "\n\n".join(sections)
+  return f"{template.strip()}\n\n{body_text}".strip()
+
+
+def _render_summary_blob(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  policy: SummaryPolicy,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  if not items:
+    return None
+  max_items = reference.max_items or policy.max_items_per_reference
+  limited = items[:max_items]
+  prompt = _build_summary_prompt(reference, limited, policy)
+  max_tokens = reference.summary_max_tokens or policy.summary_max_tokens
+  summary = registry.complete(
+    prompt,
+    model_id=policy.summarizer_model,
+    task_params={"max_tokens": max_tokens},
+  )
+  return summary.strip() or None
+
+
+def _apply_prompt_policy(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  config: AppConfig,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  mode = reference.prompt_mode or config.mcp_prompt_policy.default_mode
+  if mode == "summary":
+    return _render_summary_blob(reference, items, config.mcp_prompt_policy.summary, registry)
+  return _render_raw_blob(reference, items, config.mcp_prompt_policy.raw_capped)
+
+
+def _wrap_reference_label(reference: ReferenceCommon, text: Optional[str]) -> Optional[str]:
+  if not text:
+    return None
+  if reference.label:
+    return f"{reference.label}\n{text}"
+  return text
+
+
+def _url_items(reference: UrlReference, text: str) -> List[NormalizedItem]:
+  return [
+    NormalizedItem(
+      id=reference.url,
+      type=reference.item_type or "url",
+      title=reference.label or reference.url,
+      body=text.strip(),
+      url=reference.url,
+    )
+  ]
+
+
 def run_tasks_for_paths(
@@ -43,3 +166,3 @@
       for ref in task.references:
-        if ref.type == "mcp":
+        if isinstance(ref, McpReference):
           try:
@@ -52,11 +175,22 @@
             continue
-
           items = normalize_payload(result.payload, item_type_hint=ref.item_type)
-          blob = "\n\n".join(
-            [
-              f"Title: {itm.title or ''}\n{itm.body or itm.snippet or ''}"
-              for itm in items
-            ]
-          )
-          reference_blobs.append(blob)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
+        elif isinstance(ref, UrlReference):
+          try:
+            fetched = fetch_url_text(ref.url)
+          except Exception as exc:  # noqa: BLE001
+            console.print(
+              f"[yellow]Failed to fetch URL {ref.url}: {exc}[/yellow]"
+            )
+            continue
+          if not fetched.strip():
+            continue
+          items = _url_items(ref, fetched)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
 
apply_patch(auto_approved=true) exited 0 in 15ms:
Success. Updated the following files:
M src/simple_rag_writer/runner/run_tasks.py
file update:
diff --git a/src/simple_rag_writer/runner/run_tasks.py b/src/simple_rag_writer/runner/run_tasks.py
index 0141e4ccf4ea65806dee82d72114784e6b1c8b7b..5d16d892c1d13dcb9cce15465047eb62ae63cb4b
--- a/src/simple_rag_writer/runner/run_tasks.py
+++ b/src/simple_rag_writer/runner/run_tasks.py
@@ -2,18 +2,25 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import List
+from typing import List, Optional
 
 from rich.console import Console
 
-from simple_rag_writer.config.models import AppConfig
+from simple_rag_writer.config.models import AppConfig, RawCappedPolicy, SummaryPolicy
 from simple_rag_writer.llm.registry import ModelRegistry
-from simple_rag_writer.tasks.loader import load_task, expand_task_paths
 from simple_rag_writer.mcp.client import McpClient
 from simple_rag_writer.mcp.normalization import normalize_payload
+from simple_rag_writer.mcp.types import NormalizedItem
 from simple_rag_writer.prompts.task_prompt import build_task_prompt
+from simple_rag_writer.runner.url_fetcher import fetch_url_text
+from simple_rag_writer.tasks.loader import expand_task_paths, load_task
+from simple_rag_writer.tasks.models import McpReference, ReferenceCommon, TaskSpec, UrlReference
 
 console = Console()
+DEFAULT_SUMMARY_PROMPT = (
+  "Summarize the following reference material into key bullet points, highlighting"
+  " actionable facts and important context."
+)
 
 
 @dataclass
@@ -22,6 +29,122 @@
   failed_tasks: List[str]
 
 
+def _format_item(item: NormalizedItem) -> str:
+  parts: List[str] = []
+  if item.title:
+    parts.append(f"Title: {item.title}")
+  if item.url:
+    parts.append(f"URL: {item.url}")
+  body = (item.body or item.snippet or "").strip()
+  if body:
+    parts.append(body)
+  elif item.metadata:
+    parts.append(str(item.metadata))
+  return "\n".join(parts).strip()
+
+
+def _render_raw_blob(reference: ReferenceCommon, items: List[NormalizedItem], policy: RawCappedPolicy) -> Optional[str]:
+  if not items:
+    return None
+  per_item_limit = reference.max_chars or policy.max_chars_per_item
+  total_limit = policy.max_total_chars
+  max_items = reference.max_items or policy.max_items_per_reference
+  chunks: List[str] = []
+  used = 0
+  for item in items[:max_items]:
+    formatted = _format_item(item)
+    if not formatted:
+      continue
+    snippet = formatted[:per_item_limit].strip()
+    if not snippet:
+      continue
+    if used + len(snippet) > total_limit:
+      remaining = total_limit - used
+      if remaining <= 0:
+        break
+      snippet = snippet[:remaining].rstrip()
+    chunks.append(snippet)
+    used += len(snippet)
+    if used >= total_limit:
+      break
+  if not chunks:
+    return None
+  return "\n\n".join(chunks)
+
+
+def _build_summary_prompt(reference: ReferenceCommon, items: List[NormalizedItem], policy: SummaryPolicy) -> str:
+  ref_type = reference.item_type or next((itm.type for itm in items if itm.type), None)
+  template = None
+  if ref_type:
+    template = policy.per_type_prompts.get(ref_type)
+  if not template:
+    template = policy.default_prompt or DEFAULT_SUMMARY_PROMPT
+  sections: List[str] = []
+  for idx, item in enumerate(items, start=1):
+    heading = item.title or f"Item {idx}"
+    body = (item.body or item.snippet or "").strip()
+    lines = [f"## {heading}"]
+    if body:
+      lines.append(body)
+    if item.url:
+      lines.append(f"Source: {item.url}")
+    sections.append("\n".join(lines).strip())
+  body_text = "\n\n".join(sections)
+  return f"{template.strip()}\n\n{body_text}".strip()
+
+
+def _render_summary_blob(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  policy: SummaryPolicy,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  if not items:
+    return None
+  max_items = reference.max_items or policy.max_items_per_reference
+  limited = items[:max_items]
+  prompt = _build_summary_prompt(reference, limited, policy)
+  max_tokens = reference.summary_max_tokens or policy.summary_max_tokens
+  summary = registry.complete(
+    prompt,
+    model_id=policy.summarizer_model,
+    task_params={"max_tokens": max_tokens},
+  )
+  return summary.strip() or None
+
+
+def _apply_prompt_policy(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  config: AppConfig,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  mode = reference.prompt_mode or config.mcp_prompt_policy.default_mode
+  if mode == "summary":
+    return _render_summary_blob(reference, items, config.mcp_prompt_policy.summary, registry)
+  return _render_raw_blob(reference, items, config.mcp_prompt_policy.raw_capped)
+
+
+def _wrap_reference_label(reference: ReferenceCommon, text: Optional[str]) -> Optional[str]:
+  if not text:
+    return None
+  if reference.label:
+    return f"{reference.label}\n{text}"
+  return text
+
+
+def _url_items(reference: UrlReference, text: str) -> List[NormalizedItem]:
+  return [
+    NormalizedItem(
+      id=reference.url,
+      type=reference.item_type or "url",
+      title=reference.label or reference.url,
+      body=text.strip(),
+      url=reference.url,
+    )
+  ]
+
+
 def run_tasks_for_paths(
   config: AppConfig,
   registry: ModelRegistry,
@@ -41,7 +164,7 @@
       outline_context = None  # TODO: outline loading
 
       for ref in task.references:
-        if ref.type == "mcp":
+        if isinstance(ref, McpReference):
           try:
             result = client.call_tool(ref.server, ref.tool, ref.params)
           except Exception as exc:  # noqa: BLE001
@@ -50,15 +173,26 @@
               raise
             console.print(f"[yellow]MCP error (skipping reference): {exc}[/yellow]")
             continue
-
           items = normalize_payload(result.payload, item_type_hint=ref.item_type)
-          blob = "\n\n".join(
-            [
-              f"Title: {itm.title or ''}\n{itm.body or itm.snippet or ''}"
-              for itm in items
-            ]
-          )
-          reference_blobs.append(blob)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
+        elif isinstance(ref, UrlReference):
+          try:
+            fetched = fetch_url_text(ref.url)
+          except Exception as exc:  # noqa: BLE001
+            console.print(
+              f"[yellow]Failed to fetch URL {ref.url}: {exc}[/yellow]"
+            )
+            continue
+          if not fetched.strip():
+            continue
+          items = _url_items(ref, fetched)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
 
       prompt = build_task_prompt(task, outline_context, reference_blobs)
 
diff --git a/src/simple_rag_writer/runner/url_fetcher.py b/src/simple_rag_writer/runner/url_fetcher.py
new file mode 100644
index 0000000000000000000000000000000000000000..00abbf5049f05fcbcf0b5805378d5032ed50e20c
--- /dev/null
+++ b/src/simple_rag_writer/runner/url_fetcher.py
@@ -0,0 +1,90 @@
+from __future__ import annotations
+
+from html.parser import HTMLParser
+from pathlib import Path
+from typing import Optional
+from urllib.parse import unquote, urlparse
+from urllib.request import Request, url2pathname, urlopen
+
+DEFAULT_USER_AGENT = "simple-rag-writer/0.1"
+
+
+class _HTMLToTextParser(HTMLParser):
+  def __init__(self) -> None:
+    super().__init__()
+    self._parts: list[str] = []
+    self._skip_depth = 0
+
+  def handle_starttag(self, tag: str, attrs):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"br", "p", "div", "section", "article", "li", "tr"}:
+      self._parts.append("\n")
+    if lowered in {"script", "style"}:
+      self._skip_depth += 1
+
+  def handle_endtag(self, tag: str):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"script", "style"} and self._skip_depth:
+      self._skip_depth -= 1
+    elif lowered in {"p", "div", "section", "article", "li"}:
+      self._parts.append("\n")
+
+  def handle_data(self, data: str):  # type: ignore[override]
+    if self._skip_depth:
+      return
+    if data.strip():
+      self._parts.append(data)
+
+  def get_text(self) -> str:
+    raw = "".join(self._parts)
+    lines = [line.strip() for line in raw.splitlines()]
+    filtered = "\n".join(line for line in lines if line)
+    return filtered.strip()
+
+
+def _extract_file_path(url: str) -> Path:
+  parsed = urlparse(url)
+  path = unquote(parsed.path or "")
+  if parsed.netloc:
+    path = f"//{parsed.netloc}{path}"
+  fs_path = Path(url2pathname(path))
+  return fs_path
+
+
+def _html_to_text(html: str) -> str:
+  parser = _HTMLToTextParser()
+  parser.feed(html)
+  parser.close()
+  text = parser.get_text()
+  return text or html
+
+
+def fetch_url_text(url: str, *, timeout: float = 15.0) -> str:
+  parsed = urlparse(url)
+  scheme = (parsed.scheme or "").lower()
+
+  if scheme in {"", "file"}:
+    path = _extract_file_path(url)
+    return path.read_text(encoding="utf-8")
+
+  if scheme not in {"http", "https"}:
+    raise ValueError(f"Unsupported URL scheme: {parsed.scheme or 'unknown'}")
+
+  request = Request(url, headers={"User-Agent": DEFAULT_USER_AGENT})
+  with urlopen(request, timeout=timeout) as response:  # nosec: B310 in controlled use
+    content_type = response.headers.get("Content-Type", "")
+    charset: Optional[str] = None
+    try:
+      charset = response.headers.get_content_charset()  # type: ignore[attr-defined]
+    except Exception:  # pragma: no cover - very old Python versions only
+      charset = None
+    data = response.read()
+
+  encoding = charset or "utf-8"
+  text = data.decode(encoding, errors="replace")
+  if "html" in content_type.lower():
+    return _html_to_text(text)
+  return text
+
+
+__all__ = ["fetch_url_text"]
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"

file update:
diff --git a/src/simple_rag_writer/runner/run_tasks.py b/src/simple_rag_writer/runner/run_tasks.py
index 0141e4ccf4ea65806dee82d72114784e6b1c8b7b..5d16d892c1d13dcb9cce15465047eb62ae63cb4b
--- a/src/simple_rag_writer/runner/run_tasks.py
+++ b/src/simple_rag_writer/runner/run_tasks.py
@@ -2,18 +2,25 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import List
+from typing import List, Optional
 
 from rich.console import Console
 
-from simple_rag_writer.config.models import AppConfig
+from simple_rag_writer.config.models import AppConfig, RawCappedPolicy, SummaryPolicy
 from simple_rag_writer.llm.registry import ModelRegistry
-from simple_rag_writer.tasks.loader import load_task, expand_task_paths
 from simple_rag_writer.mcp.client import McpClient
 from simple_rag_writer.mcp.normalization import normalize_payload
+from simple_rag_writer.mcp.types import NormalizedItem
 from simple_rag_writer.prompts.task_prompt import build_task_prompt
+from simple_rag_writer.runner.url_fetcher import fetch_url_text
+from simple_rag_writer.tasks.loader import expand_task_paths, load_task
+from simple_rag_writer.tasks.models import McpReference, ReferenceCommon, TaskSpec, UrlReference
 
 console = Console()
+DEFAULT_SUMMARY_PROMPT = (
+  "Summarize the following reference material into key bullet points, highlighting"
+  " actionable facts and important context."
+)
 
 
 @dataclass
@@ -22,6 +29,122 @@
   failed_tasks: List[str]
 
 
+def _format_item(item: NormalizedItem) -> str:
+  parts: List[str] = []
+  if item.title:
+    parts.append(f"Title: {item.title}")
+  if item.url:
+    parts.append(f"URL: {item.url}")
+  body = (item.body or item.snippet or "").strip()
+  if body:
+    parts.append(body)
+  elif item.metadata:
+    parts.append(str(item.metadata))
+  return "\n".join(parts).strip()
+
+
+def _render_raw_blob(reference: ReferenceCommon, items: List[NormalizedItem], policy: RawCappedPolicy) -> Optional[str]:
+  if not items:
+    return None
+  per_item_limit = reference.max_chars or policy.max_chars_per_item
+  total_limit = policy.max_total_chars
+  max_items = reference.max_items or policy.max_items_per_reference
+  chunks: List[str] = []
+  used = 0
+  for item in items[:max_items]:
+    formatted = _format_item(item)
+    if not formatted:
+      continue
+    snippet = formatted[:per_item_limit].strip()
+    if not snippet:
+      continue
+    if used + len(snippet) > total_limit:
+      remaining = total_limit - used
+      if remaining <= 0:
+        break
+      snippet = snippet[:remaining].rstrip()
+    chunks.append(snippet)
+    used += len(snippet)
+    if used >= total_limit:
+      break
+  if not chunks:
+    return None
+  return "\n\n".join(chunks)
+
+
+def _build_summary_prompt(reference: ReferenceCommon, items: List[NormalizedItem], policy: SummaryPolicy) -> str:
+  ref_type = reference.item_type or next((itm.type for itm in items if itm.type), None)
+  template = None
+  if ref_type:
+    template = policy.per_type_prompts.get(ref_type)
+  if not template:
+    template = policy.default_prompt or DEFAULT_SUMMARY_PROMPT
+  sections: List[str] = []
+  for idx, item in enumerate(items, start=1):
+    heading = item.title or f"Item {idx}"
+    body = (item.body or item.snippet or "").strip()
+    lines = [f"## {heading}"]
+    if body:
+      lines.append(body)
+    if item.url:
+      lines.append(f"Source: {item.url}")
+    sections.append("\n".join(lines).strip())
+  body_text = "\n\n".join(sections)
+  return f"{template.strip()}\n\n{body_text}".strip()
+
+
+def _render_summary_blob(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  policy: SummaryPolicy,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  if not items:
+    return None
+  max_items = reference.max_items or policy.max_items_per_reference
+  limited = items[:max_items]
+  prompt = _build_summary_prompt(reference, limited, policy)
+  max_tokens = reference.summary_max_tokens or policy.summary_max_tokens
+  summary = registry.complete(
+    prompt,
+    model_id=policy.summarizer_model,
+    task_params={"max_tokens": max_tokens},
+  )
+  return summary.strip() or None
+
+
+def _apply_prompt_policy(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  config: AppConfig,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  mode = reference.prompt_mode or config.mcp_prompt_policy.default_mode
+  if mode == "summary":
+    return _render_summary_blob(reference, items, config.mcp_prompt_policy.summary, registry)
+  return _render_raw_blob(reference, items, config.mcp_prompt_policy.raw_capped)
+
+
+def _wrap_reference_label(reference: ReferenceCommon, text: Optional[str]) -> Optional[str]:
+  if not text:
+    return None
+  if reference.label:
+    return f"{reference.label}\n{text}"
+  return text
+
+
+def _url_items(reference: UrlReference, text: str) -> List[NormalizedItem]:
+  return [
+    NormalizedItem(
+      id=reference.url,
+      type=reference.item_type or "url",
+      title=reference.label or reference.url,
+      body=text.strip(),
+      url=reference.url,
+    )
+  ]
+
+
 def run_tasks_for_paths(
   config: AppConfig,
   registry: ModelRegistry,
@@ -41,7 +164,7 @@
       outline_context = None  # TODO: outline loading
 
       for ref in task.references:
-        if ref.type == "mcp":
+        if isinstance(ref, McpReference):
           try:
             result = client.call_tool(ref.server, ref.tool, ref.params)
           except Exception as exc:  # noqa: BLE001
@@ -50,15 +173,26 @@
               raise
             console.print(f"[yellow]MCP error (skipping reference): {exc}[/yellow]")
             continue
-
           items = normalize_payload(result.payload, item_type_hint=ref.item_type)
-          blob = "\n\n".join(
-            [
-              f"Title: {itm.title or ''}\n{itm.body or itm.snippet or ''}"
-              for itm in items
-            ]
-          )
-          reference_blobs.append(blob)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
+        elif isinstance(ref, UrlReference):
+          try:
+            fetched = fetch_url_text(ref.url)
+          except Exception as exc:  # noqa: BLE001
+            console.print(
+              f"[yellow]Failed to fetch URL {ref.url}: {exc}[/yellow]"
+            )
+            continue
+          if not fetched.strip():
+            continue
+          items = _url_items(ref, fetched)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
 
       prompt = build_task_prompt(task, outline_context, reference_blobs)
 
diff --git a/src/simple_rag_writer/runner/url_fetcher.py b/src/simple_rag_writer/runner/url_fetcher.py
new file mode 100644
index 0000000000000000000000000000000000000000..00abbf5049f05fcbcf0b5805378d5032ed50e20c
--- /dev/null
+++ b/src/simple_rag_writer/runner/url_fetcher.py
@@ -0,0 +1,90 @@
+from __future__ import annotations
+
+from html.parser import HTMLParser
+from pathlib import Path
+from typing import Optional
+from urllib.parse import unquote, urlparse
+from urllib.request import Request, url2pathname, urlopen
+
+DEFAULT_USER_AGENT = "simple-rag-writer/0.1"
+
+
+class _HTMLToTextParser(HTMLParser):
+  def __init__(self) -> None:
+    super().__init__()
+    self._parts: list[str] = []
+    self._skip_depth = 0
+
+  def handle_starttag(self, tag: str, attrs):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"br", "p", "div", "section", "article", "li", "tr"}:
+      self._parts.append("\n")
+    if lowered in {"script", "style"}:
+      self._skip_depth += 1
+
+  def handle_endtag(self, tag: str):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"script", "style"} and self._skip_depth:
+      self._skip_depth -= 1
+    elif lowered in {"p", "div", "section", "article", "li"}:
+      self._parts.append("\n")
+
+  def handle_data(self, data: str):  # type: ignore[override]
+    if self._skip_depth:
+      return
+    if data.strip():
+      self._parts.append(data)
+
+  def get_text(self) -> str:
+    raw = "".join(self._parts)
+    lines = [line.strip() for line in raw.splitlines()]
+    filtered = "\n".join(line for line in lines if line)
+    return filtered.strip()
+
+
+def _extract_file_path(url: str) -> Path:
+  parsed = urlparse(url)
+  path = unquote(parsed.path or "")
+  if parsed.netloc:
+    path = f"//{parsed.netloc}{path}"
+  fs_path = Path(url2pathname(path))
+  return fs_path
+
+
+def _html_to_text(html: str) -> str:
+  parser = _HTMLToTextParser()
+  parser.feed(html)
+  parser.close()
+  text = parser.get_text()
+  return text or html
+
+
+def fetch_url_text(url: str, *, timeout: float = 15.0) -> str:
+  parsed = urlparse(url)
+  scheme = (parsed.scheme or "").lower()
+
+  if scheme in {"", "file"}:
+    path = _extract_file_path(url)
+    return path.read_text(encoding="utf-8")
+
+  if scheme not in {"http", "https"}:
+    raise ValueError(f"Unsupported URL scheme: {parsed.scheme or 'unknown'}")
+
+  request = Request(url, headers={"User-Agent": DEFAULT_USER_AGENT})
+  with urlopen(request, timeout=timeout) as response:  # nosec: B310 in controlled use
+    content_type = response.headers.get("Content-Type", "")
+    charset: Optional[str] = None
+    try:
+      charset = response.headers.get_content_charset()  # type: ignore[attr-defined]
+    except Exception:  # pragma: no cover - very old Python versions only
+      charset = None
+    data = response.read()
+
+  encoding = charset or "utf-8"
+  text = data.decode(encoding, errors="replace")
+  if "html" in content_type.lower():
+    return _html_to_text(text)
+  return text
+
+
+__all__ = ["fetch_url_text"]
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"


thinking
**Cleaning up unused imports**
file update
M /var/home/rick/Development/llm_writer/src/simple_rag_writer/runner/run_tasks.py
@@ -16,3 +16,3 @@
 from simple_rag_writer.tasks.loader import expand_task_paths, load_task
-from simple_rag_writer.tasks.models import McpReference, ReferenceCommon, TaskSpec, UrlReference
+from simple_rag_writer.tasks.models import McpReference, ReferenceCommon, UrlReference
 
apply_patch(auto_approved=true) exited 0 in 8ms:
Success. Updated the following files:
M src/simple_rag_writer/runner/run_tasks.py
file update:
diff --git a/src/simple_rag_writer/runner/run_tasks.py b/src/simple_rag_writer/runner/run_tasks.py
index 0141e4ccf4ea65806dee82d72114784e6b1c8b7b..d9fa29487a87ab4f79ef8dbcba52e97c779860b3
--- a/src/simple_rag_writer/runner/run_tasks.py
+++ b/src/simple_rag_writer/runner/run_tasks.py
@@ -2,18 +2,25 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import List
+from typing import List, Optional
 
 from rich.console import Console
 
-from simple_rag_writer.config.models import AppConfig
+from simple_rag_writer.config.models import AppConfig, RawCappedPolicy, SummaryPolicy
 from simple_rag_writer.llm.registry import ModelRegistry
-from simple_rag_writer.tasks.loader import load_task, expand_task_paths
 from simple_rag_writer.mcp.client import McpClient
 from simple_rag_writer.mcp.normalization import normalize_payload
+from simple_rag_writer.mcp.types import NormalizedItem
 from simple_rag_writer.prompts.task_prompt import build_task_prompt
+from simple_rag_writer.runner.url_fetcher import fetch_url_text
+from simple_rag_writer.tasks.loader import expand_task_paths, load_task
+from simple_rag_writer.tasks.models import McpReference, ReferenceCommon, UrlReference
 
 console = Console()
+DEFAULT_SUMMARY_PROMPT = (
+  "Summarize the following reference material into key bullet points, highlighting"
+  " actionable facts and important context."
+)
 
 
 @dataclass
@@ -22,6 +29,122 @@
   failed_tasks: List[str]
 
 
+def _format_item(item: NormalizedItem) -> str:
+  parts: List[str] = []
+  if item.title:
+    parts.append(f"Title: {item.title}")
+  if item.url:
+    parts.append(f"URL: {item.url}")
+  body = (item.body or item.snippet or "").strip()
+  if body:
+    parts.append(body)
+  elif item.metadata:
+    parts.append(str(item.metadata))
+  return "\n".join(parts).strip()
+
+
+def _render_raw_blob(reference: ReferenceCommon, items: List[NormalizedItem], policy: RawCappedPolicy) -> Optional[str]:
+  if not items:
+    return None
+  per_item_limit = reference.max_chars or policy.max_chars_per_item
+  total_limit = policy.max_total_chars
+  max_items = reference.max_items or policy.max_items_per_reference
+  chunks: List[str] = []
+  used = 0
+  for item in items[:max_items]:
+    formatted = _format_item(item)
+    if not formatted:
+      continue
+    snippet = formatted[:per_item_limit].strip()
+    if not snippet:
+      continue
+    if used + len(snippet) > total_limit:
+      remaining = total_limit - used
+      if remaining <= 0:
+        break
+      snippet = snippet[:remaining].rstrip()
+    chunks.append(snippet)
+    used += len(snippet)
+    if used >= total_limit:
+      break
+  if not chunks:
+    return None
+  return "\n\n".join(chunks)
+
+
+def _build_summary_prompt(reference: ReferenceCommon, items: List[NormalizedItem], policy: SummaryPolicy) -> str:
+  ref_type = reference.item_type or next((itm.type for itm in items if itm.type), None)
+  template = None
+  if ref_type:
+    template = policy.per_type_prompts.get(ref_type)
+  if not template:
+    template = policy.default_prompt or DEFAULT_SUMMARY_PROMPT
+  sections: List[str] = []
+  for idx, item in enumerate(items, start=1):
+    heading = item.title or f"Item {idx}"
+    body = (item.body or item.snippet or "").strip()
+    lines = [f"## {heading}"]
+    if body:
+      lines.append(body)
+    if item.url:
+      lines.append(f"Source: {item.url}")
+    sections.append("\n".join(lines).strip())
+  body_text = "\n\n".join(sections)
+  return f"{template.strip()}\n\n{body_text}".strip()
+
+
+def _render_summary_blob(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  policy: SummaryPolicy,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  if not items:
+    return None
+  max_items = reference.max_items or policy.max_items_per_reference
+  limited = items[:max_items]
+  prompt = _build_summary_prompt(reference, limited, policy)
+  max_tokens = reference.summary_max_tokens or policy.summary_max_tokens
+  summary = registry.complete(
+    prompt,
+    model_id=policy.summarizer_model,
+    task_params={"max_tokens": max_tokens},
+  )
+  return summary.strip() or None
+
+
+def _apply_prompt_policy(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  config: AppConfig,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  mode = reference.prompt_mode or config.mcp_prompt_policy.default_mode
+  if mode == "summary":
+    return _render_summary_blob(reference, items, config.mcp_prompt_policy.summary, registry)
+  return _render_raw_blob(reference, items, config.mcp_prompt_policy.raw_capped)
+
+
+def _wrap_reference_label(reference: ReferenceCommon, text: Optional[str]) -> Optional[str]:
+  if not text:
+    return None
+  if reference.label:
+    return f"{reference.label}\n{text}"
+  return text
+
+
+def _url_items(reference: UrlReference, text: str) -> List[NormalizedItem]:
+  return [
+    NormalizedItem(
+      id=reference.url,
+      type=reference.item_type or "url",
+      title=reference.label or reference.url,
+      body=text.strip(),
+      url=reference.url,
+    )
+  ]
+
+
 def run_tasks_for_paths(
   config: AppConfig,
   registry: ModelRegistry,
@@ -41,7 +164,7 @@
       outline_context = None  # TODO: outline loading
 
       for ref in task.references:
-        if ref.type == "mcp":
+        if isinstance(ref, McpReference):
           try:
             result = client.call_tool(ref.server, ref.tool, ref.params)
           except Exception as exc:  # noqa: BLE001
@@ -50,15 +173,26 @@
               raise
             console.print(f"[yellow]MCP error (skipping reference): {exc}[/yellow]")
             continue
-
           items = normalize_payload(result.payload, item_type_hint=ref.item_type)
-          blob = "\n\n".join(
-            [
-              f"Title: {itm.title or ''}\n{itm.body or itm.snippet or ''}"
-              for itm in items
-            ]
-          )
-          reference_blobs.append(blob)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
+        elif isinstance(ref, UrlReference):
+          try:
+            fetched = fetch_url_text(ref.url)
+          except Exception as exc:  # noqa: BLE001
+            console.print(
+              f"[yellow]Failed to fetch URL {ref.url}: {exc}[/yellow]"
+            )
+            continue
+          if not fetched.strip():
+            continue
+          items = _url_items(ref, fetched)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
 
       prompt = build_task_prompt(task, outline_context, reference_blobs)
 
diff --git a/src/simple_rag_writer/runner/url_fetcher.py b/src/simple_rag_writer/runner/url_fetcher.py
new file mode 100644
index 0000000000000000000000000000000000000000..00abbf5049f05fcbcf0b5805378d5032ed50e20c
--- /dev/null
+++ b/src/simple_rag_writer/runner/url_fetcher.py
@@ -0,0 +1,90 @@
+from __future__ import annotations
+
+from html.parser import HTMLParser
+from pathlib import Path
+from typing import Optional
+from urllib.parse import unquote, urlparse
+from urllib.request import Request, url2pathname, urlopen
+
+DEFAULT_USER_AGENT = "simple-rag-writer/0.1"
+
+
+class _HTMLToTextParser(HTMLParser):
+  def __init__(self) -> None:
+    super().__init__()
+    self._parts: list[str] = []
+    self._skip_depth = 0
+
+  def handle_starttag(self, tag: str, attrs):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"br", "p", "div", "section", "article", "li", "tr"}:
+      self._parts.append("\n")
+    if lowered in {"script", "style"}:
+      self._skip_depth += 1
+
+  def handle_endtag(self, tag: str):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"script", "style"} and self._skip_depth:
+      self._skip_depth -= 1
+    elif lowered in {"p", "div", "section", "article", "li"}:
+      self._parts.append("\n")
+
+  def handle_data(self, data: str):  # type: ignore[override]
+    if self._skip_depth:
+      return
+    if data.strip():
+      self._parts.append(data)
+
+  def get_text(self) -> str:
+    raw = "".join(self._parts)
+    lines = [line.strip() for line in raw.splitlines()]
+    filtered = "\n".join(line for line in lines if line)
+    return filtered.strip()
+
+
+def _extract_file_path(url: str) -> Path:
+  parsed = urlparse(url)
+  path = unquote(parsed.path or "")
+  if parsed.netloc:
+    path = f"//{parsed.netloc}{path}"
+  fs_path = Path(url2pathname(path))
+  return fs_path
+
+
+def _html_to_text(html: str) -> str:
+  parser = _HTMLToTextParser()
+  parser.feed(html)
+  parser.close()
+  text = parser.get_text()
+  return text or html
+
+
+def fetch_url_text(url: str, *, timeout: float = 15.0) -> str:
+  parsed = urlparse(url)
+  scheme = (parsed.scheme or "").lower()
+
+  if scheme in {"", "file"}:
+    path = _extract_file_path(url)
+    return path.read_text(encoding="utf-8")
+
+  if scheme not in {"http", "https"}:
+    raise ValueError(f"Unsupported URL scheme: {parsed.scheme or 'unknown'}")
+
+  request = Request(url, headers={"User-Agent": DEFAULT_USER_AGENT})
+  with urlopen(request, timeout=timeout) as response:  # nosec: B310 in controlled use
+    content_type = response.headers.get("Content-Type", "")
+    charset: Optional[str] = None
+    try:
+      charset = response.headers.get_content_charset()  # type: ignore[attr-defined]
+    except Exception:  # pragma: no cover - very old Python versions only
+      charset = None
+    data = response.read()
+
+  encoding = charset or "utf-8"
+  text = data.decode(encoding, errors="replace")
+  if "html" in content_type.lower():
+    return _html_to_text(text)
+  return text
+
+
+__all__ = ["fetch_url_text"]
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"

file update:
diff --git a/src/simple_rag_writer/runner/run_tasks.py b/src/simple_rag_writer/runner/run_tasks.py
index 0141e4ccf4ea65806dee82d72114784e6b1c8b7b..d9fa29487a87ab4f79ef8dbcba52e97c779860b3
--- a/src/simple_rag_writer/runner/run_tasks.py
+++ b/src/simple_rag_writer/runner/run_tasks.py
@@ -2,18 +2,25 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import List
+from typing import List, Optional
 
 from rich.console import Console
 
-from simple_rag_writer.config.models import AppConfig
+from simple_rag_writer.config.models import AppConfig, RawCappedPolicy, SummaryPolicy
 from simple_rag_writer.llm.registry import ModelRegistry
-from simple_rag_writer.tasks.loader import load_task, expand_task_paths
 from simple_rag_writer.mcp.client import McpClient
 from simple_rag_writer.mcp.normalization import normalize_payload
+from simple_rag_writer.mcp.types import NormalizedItem
 from simple_rag_writer.prompts.task_prompt import build_task_prompt
+from simple_rag_writer.runner.url_fetcher import fetch_url_text
+from simple_rag_writer.tasks.loader import expand_task_paths, load_task
+from simple_rag_writer.tasks.models import McpReference, ReferenceCommon, UrlReference
 
 console = Console()
+DEFAULT_SUMMARY_PROMPT = (
+  "Summarize the following reference material into key bullet points, highlighting"
+  " actionable facts and important context."
+)
 
 
 @dataclass
@@ -22,6 +29,122 @@
   failed_tasks: List[str]
 
 
+def _format_item(item: NormalizedItem) -> str:
+  parts: List[str] = []
+  if item.title:
+    parts.append(f"Title: {item.title}")
+  if item.url:
+    parts.append(f"URL: {item.url}")
+  body = (item.body or item.snippet or "").strip()
+  if body:
+    parts.append(body)
+  elif item.metadata:
+    parts.append(str(item.metadata))
+  return "\n".join(parts).strip()
+
+
+def _render_raw_blob(reference: ReferenceCommon, items: List[NormalizedItem], policy: RawCappedPolicy) -> Optional[str]:
+  if not items:
+    return None
+  per_item_limit = reference.max_chars or policy.max_chars_per_item
+  total_limit = policy.max_total_chars
+  max_items = reference.max_items or policy.max_items_per_reference
+  chunks: List[str] = []
+  used = 0
+  for item in items[:max_items]:
+    formatted = _format_item(item)
+    if not formatted:
+      continue
+    snippet = formatted[:per_item_limit].strip()
+    if not snippet:
+      continue
+    if used + len(snippet) > total_limit:
+      remaining = total_limit - used
+      if remaining <= 0:
+        break
+      snippet = snippet[:remaining].rstrip()
+    chunks.append(snippet)
+    used += len(snippet)
+    if used >= total_limit:
+      break
+  if not chunks:
+    return None
+  return "\n\n".join(chunks)
+
+
+def _build_summary_prompt(reference: ReferenceCommon, items: List[NormalizedItem], policy: SummaryPolicy) -> str:
+  ref_type = reference.item_type or next((itm.type for itm in items if itm.type), None)
+  template = None
+  if ref_type:
+    template = policy.per_type_prompts.get(ref_type)
+  if not template:
+    template = policy.default_prompt or DEFAULT_SUMMARY_PROMPT
+  sections: List[str] = []
+  for idx, item in enumerate(items, start=1):
+    heading = item.title or f"Item {idx}"
+    body = (item.body or item.snippet or "").strip()
+    lines = [f"## {heading}"]
+    if body:
+      lines.append(body)
+    if item.url:
+      lines.append(f"Source: {item.url}")
+    sections.append("\n".join(lines).strip())
+  body_text = "\n\n".join(sections)
+  return f"{template.strip()}\n\n{body_text}".strip()
+
+
+def _render_summary_blob(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  policy: SummaryPolicy,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  if not items:
+    return None
+  max_items = reference.max_items or policy.max_items_per_reference
+  limited = items[:max_items]
+  prompt = _build_summary_prompt(reference, limited, policy)
+  max_tokens = reference.summary_max_tokens or policy.summary_max_tokens
+  summary = registry.complete(
+    prompt,
+    model_id=policy.summarizer_model,
+    task_params={"max_tokens": max_tokens},
+  )
+  return summary.strip() or None
+
+
+def _apply_prompt_policy(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  config: AppConfig,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  mode = reference.prompt_mode or config.mcp_prompt_policy.default_mode
+  if mode == "summary":
+    return _render_summary_blob(reference, items, config.mcp_prompt_policy.summary, registry)
+  return _render_raw_blob(reference, items, config.mcp_prompt_policy.raw_capped)
+
+
+def _wrap_reference_label(reference: ReferenceCommon, text: Optional[str]) -> Optional[str]:
+  if not text:
+    return None
+  if reference.label:
+    return f"{reference.label}\n{text}"
+  return text
+
+
+def _url_items(reference: UrlReference, text: str) -> List[NormalizedItem]:
+  return [
+    NormalizedItem(
+      id=reference.url,
+      type=reference.item_type or "url",
+      title=reference.label or reference.url,
+      body=text.strip(),
+      url=reference.url,
+    )
+  ]
+
+
 def run_tasks_for_paths(
   config: AppConfig,
   registry: ModelRegistry,
@@ -41,7 +164,7 @@
       outline_context = None  # TODO: outline loading
 
       for ref in task.references:
-        if ref.type == "mcp":
+        if isinstance(ref, McpReference):
           try:
             result = client.call_tool(ref.server, ref.tool, ref.params)
           except Exception as exc:  # noqa: BLE001
@@ -50,15 +173,26 @@
               raise
             console.print(f"[yellow]MCP error (skipping reference): {exc}[/yellow]")
             continue
-
           items = normalize_payload(result.payload, item_type_hint=ref.item_type)
-          blob = "\n\n".join(
-            [
-              f"Title: {itm.title or ''}\n{itm.body or itm.snippet or ''}"
-              for itm in items
-            ]
-          )
-          reference_blobs.append(blob)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
+        elif isinstance(ref, UrlReference):
+          try:
+            fetched = fetch_url_text(ref.url)
+          except Exception as exc:  # noqa: BLE001
+            console.print(
+              f"[yellow]Failed to fetch URL {ref.url}: {exc}[/yellow]"
+            )
+            continue
+          if not fetched.strip():
+            continue
+          items = _url_items(ref, fetched)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
 
       prompt = build_task_prompt(task, outline_context, reference_blobs)
 
diff --git a/src/simple_rag_writer/runner/url_fetcher.py b/src/simple_rag_writer/runner/url_fetcher.py
new file mode 100644
index 0000000000000000000000000000000000000000..00abbf5049f05fcbcf0b5805378d5032ed50e20c
--- /dev/null
+++ b/src/simple_rag_writer/runner/url_fetcher.py
@@ -0,0 +1,90 @@
+from __future__ import annotations
+
+from html.parser import HTMLParser
+from pathlib import Path
+from typing import Optional
+from urllib.parse import unquote, urlparse
+from urllib.request import Request, url2pathname, urlopen
+
+DEFAULT_USER_AGENT = "simple-rag-writer/0.1"
+
+
+class _HTMLToTextParser(HTMLParser):
+  def __init__(self) -> None:
+    super().__init__()
+    self._parts: list[str] = []
+    self._skip_depth = 0
+
+  def handle_starttag(self, tag: str, attrs):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"br", "p", "div", "section", "article", "li", "tr"}:
+      self._parts.append("\n")
+    if lowered in {"script", "style"}:
+      self._skip_depth += 1
+
+  def handle_endtag(self, tag: str):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"script", "style"} and self._skip_depth:
+      self._skip_depth -= 1
+    elif lowered in {"p", "div", "section", "article", "li"}:
+      self._parts.append("\n")
+
+  def handle_data(self, data: str):  # type: ignore[override]
+    if self._skip_depth:
+      return
+    if data.strip():
+      self._parts.append(data)
+
+  def get_text(self) -> str:
+    raw = "".join(self._parts)
+    lines = [line.strip() for line in raw.splitlines()]
+    filtered = "\n".join(line for line in lines if line)
+    return filtered.strip()
+
+
+def _extract_file_path(url: str) -> Path:
+  parsed = urlparse(url)
+  path = unquote(parsed.path or "")
+  if parsed.netloc:
+    path = f"//{parsed.netloc}{path}"
+  fs_path = Path(url2pathname(path))
+  return fs_path
+
+
+def _html_to_text(html: str) -> str:
+  parser = _HTMLToTextParser()
+  parser.feed(html)
+  parser.close()
+  text = parser.get_text()
+  return text or html
+
+
+def fetch_url_text(url: str, *, timeout: float = 15.0) -> str:
+  parsed = urlparse(url)
+  scheme = (parsed.scheme or "").lower()
+
+  if scheme in {"", "file"}:
+    path = _extract_file_path(url)
+    return path.read_text(encoding="utf-8")
+
+  if scheme not in {"http", "https"}:
+    raise ValueError(f"Unsupported URL scheme: {parsed.scheme or 'unknown'}")
+
+  request = Request(url, headers={"User-Agent": DEFAULT_USER_AGENT})
+  with urlopen(request, timeout=timeout) as response:  # nosec: B310 in controlled use
+    content_type = response.headers.get("Content-Type", "")
+    charset: Optional[str] = None
+    try:
+      charset = response.headers.get_content_charset()  # type: ignore[attr-defined]
+    except Exception:  # pragma: no cover - very old Python versions only
+      charset = None
+    data = response.read()
+
+  encoding = charset or "utf-8"
+  text = data.decode(encoding, errors="replace")
+  if "html" in content_type.lower():
+    return _html_to_text(text)
+  return text
+
+
+__all__ = ["fetch_url_text"]
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"


thinking
**Verifying comprehensive code consistency**
exec
bash -lc 'pytest tests/test_runner_run_tasks.py' in /var/home/rick/Development/llm_writer succeeded in 1.72s:
============================= test session starts ==============================
platform linux -- Python 3.13.9, pytest-8.4.2, pluggy-1.6.0
rootdir: /var/home/rick/Development/llm_writer
configfile: pyproject.toml
plugins: Faker-37.8.0, xdist-3.8.0, mock-3.15.1, metadata-3.1.1, cov-7.0.0, asyncio-1.2.0, html-4.1.1, hypothesis-6.141.1, anyio-4.8.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collected 2 items

tests/test_runner_run_tasks.py ..                                        [100%]

============================== 2 passed in 0.75s ===============================
file update:
diff --git a/src/simple_rag_writer/runner/run_tasks.py b/src/simple_rag_writer/runner/run_tasks.py
index 0141e4ccf4ea65806dee82d72114784e6b1c8b7b..d9fa29487a87ab4f79ef8dbcba52e97c779860b3
--- a/src/simple_rag_writer/runner/run_tasks.py
+++ b/src/simple_rag_writer/runner/run_tasks.py
@@ -2,18 +2,25 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import List
+from typing import List, Optional
 
 from rich.console import Console
 
-from simple_rag_writer.config.models import AppConfig
+from simple_rag_writer.config.models import AppConfig, RawCappedPolicy, SummaryPolicy
 from simple_rag_writer.llm.registry import ModelRegistry
-from simple_rag_writer.tasks.loader import load_task, expand_task_paths
 from simple_rag_writer.mcp.client import McpClient
 from simple_rag_writer.mcp.normalization import normalize_payload
+from simple_rag_writer.mcp.types import NormalizedItem
 from simple_rag_writer.prompts.task_prompt import build_task_prompt
+from simple_rag_writer.runner.url_fetcher import fetch_url_text
+from simple_rag_writer.tasks.loader import expand_task_paths, load_task
+from simple_rag_writer.tasks.models import McpReference, ReferenceCommon, UrlReference
 
 console = Console()
+DEFAULT_SUMMARY_PROMPT = (
+  "Summarize the following reference material into key bullet points, highlighting"
+  " actionable facts and important context."
+)
 
 
 @dataclass
@@ -22,6 +29,122 @@
   failed_tasks: List[str]
 
 
+def _format_item(item: NormalizedItem) -> str:
+  parts: List[str] = []
+  if item.title:
+    parts.append(f"Title: {item.title}")
+  if item.url:
+    parts.append(f"URL: {item.url}")
+  body = (item.body or item.snippet or "").strip()
+  if body:
+    parts.append(body)
+  elif item.metadata:
+    parts.append(str(item.metadata))
+  return "\n".join(parts).strip()
+
+
+def _render_raw_blob(reference: ReferenceCommon, items: List[NormalizedItem], policy: RawCappedPolicy) -> Optional[str]:
+  if not items:
+    return None
+  per_item_limit = reference.max_chars or policy.max_chars_per_item
+  total_limit = policy.max_total_chars
+  max_items = reference.max_items or policy.max_items_per_reference
+  chunks: List[str] = []
+  used = 0
+  for item in items[:max_items]:
+    formatted = _format_item(item)
+    if not formatted:
+      continue
+    snippet = formatted[:per_item_limit].strip()
+    if not snippet:
+      continue
+    if used + len(snippet) > total_limit:
+      remaining = total_limit - used
+      if remaining <= 0:
+        break
+      snippet = snippet[:remaining].rstrip()
+    chunks.append(snippet)
+    used += len(snippet)
+    if used >= total_limit:
+      break
+  if not chunks:
+    return None
+  return "\n\n".join(chunks)
+
+
+def _build_summary_prompt(reference: ReferenceCommon, items: List[NormalizedItem], policy: SummaryPolicy) -> str:
+  ref_type = reference.item_type or next((itm.type for itm in items if itm.type), None)
+  template = None
+  if ref_type:
+    template = policy.per_type_prompts.get(ref_type)
+  if not template:
+    template = policy.default_prompt or DEFAULT_SUMMARY_PROMPT
+  sections: List[str] = []
+  for idx, item in enumerate(items, start=1):
+    heading = item.title or f"Item {idx}"
+    body = (item.body or item.snippet or "").strip()
+    lines = [f"## {heading}"]
+    if body:
+      lines.append(body)
+    if item.url:
+      lines.append(f"Source: {item.url}")
+    sections.append("\n".join(lines).strip())
+  body_text = "\n\n".join(sections)
+  return f"{template.strip()}\n\n{body_text}".strip()
+
+
+def _render_summary_blob(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  policy: SummaryPolicy,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  if not items:
+    return None
+  max_items = reference.max_items or policy.max_items_per_reference
+  limited = items[:max_items]
+  prompt = _build_summary_prompt(reference, limited, policy)
+  max_tokens = reference.summary_max_tokens or policy.summary_max_tokens
+  summary = registry.complete(
+    prompt,
+    model_id=policy.summarizer_model,
+    task_params={"max_tokens": max_tokens},
+  )
+  return summary.strip() or None
+
+
+def _apply_prompt_policy(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  config: AppConfig,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  mode = reference.prompt_mode or config.mcp_prompt_policy.default_mode
+  if mode == "summary":
+    return _render_summary_blob(reference, items, config.mcp_prompt_policy.summary, registry)
+  return _render_raw_blob(reference, items, config.mcp_prompt_policy.raw_capped)
+
+
+def _wrap_reference_label(reference: ReferenceCommon, text: Optional[str]) -> Optional[str]:
+  if not text:
+    return None
+  if reference.label:
+    return f"{reference.label}\n{text}"
+  return text
+
+
+def _url_items(reference: UrlReference, text: str) -> List[NormalizedItem]:
+  return [
+    NormalizedItem(
+      id=reference.url,
+      type=reference.item_type or "url",
+      title=reference.label or reference.url,
+      body=text.strip(),
+      url=reference.url,
+    )
+  ]
+
+
 def run_tasks_for_paths(
   config: AppConfig,
   registry: ModelRegistry,
@@ -41,7 +164,7 @@
       outline_context = None  # TODO: outline loading
 
       for ref in task.references:
-        if ref.type == "mcp":
+        if isinstance(ref, McpReference):
           try:
             result = client.call_tool(ref.server, ref.tool, ref.params)
           except Exception as exc:  # noqa: BLE001
@@ -50,15 +173,26 @@
               raise
             console.print(f"[yellow]MCP error (skipping reference): {exc}[/yellow]")
             continue
-
           items = normalize_payload(result.payload, item_type_hint=ref.item_type)
-          blob = "\n\n".join(
-            [
-              f"Title: {itm.title or ''}\n{itm.body or itm.snippet or ''}"
-              for itm in items
-            ]
-          )
-          reference_blobs.append(blob)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
+        elif isinstance(ref, UrlReference):
+          try:
+            fetched = fetch_url_text(ref.url)
+          except Exception as exc:  # noqa: BLE001
+            console.print(
+              f"[yellow]Failed to fetch URL {ref.url}: {exc}[/yellow]"
+            )
+            continue
+          if not fetched.strip():
+            continue
+          items = _url_items(ref, fetched)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
 
       prompt = build_task_prompt(task, outline_context, reference_blobs)
 
diff --git a/src/simple_rag_writer/runner/url_fetcher.py b/src/simple_rag_writer/runner/url_fetcher.py
new file mode 100644
index 0000000000000000000000000000000000000000..00abbf5049f05fcbcf0b5805378d5032ed50e20c
--- /dev/null
+++ b/src/simple_rag_writer/runner/url_fetcher.py
@@ -0,0 +1,90 @@
+from __future__ import annotations
+
+from html.parser import HTMLParser
+from pathlib import Path
+from typing import Optional
+from urllib.parse import unquote, urlparse
+from urllib.request import Request, url2pathname, urlopen
+
+DEFAULT_USER_AGENT = "simple-rag-writer/0.1"
+
+
+class _HTMLToTextParser(HTMLParser):
+  def __init__(self) -> None:
+    super().__init__()
+    self._parts: list[str] = []
+    self._skip_depth = 0
+
+  def handle_starttag(self, tag: str, attrs):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"br", "p", "div", "section", "article", "li", "tr"}:
+      self._parts.append("\n")
+    if lowered in {"script", "style"}:
+      self._skip_depth += 1
+
+  def handle_endtag(self, tag: str):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"script", "style"} and self._skip_depth:
+      self._skip_depth -= 1
+    elif lowered in {"p", "div", "section", "article", "li"}:
+      self._parts.append("\n")
+
+  def handle_data(self, data: str):  # type: ignore[override]
+    if self._skip_depth:
+      return
+    if data.strip():
+      self._parts.append(data)
+
+  def get_text(self) -> str:
+    raw = "".join(self._parts)
+    lines = [line.strip() for line in raw.splitlines()]
+    filtered = "\n".join(line for line in lines if line)
+    return filtered.strip()
+
+
+def _extract_file_path(url: str) -> Path:
+  parsed = urlparse(url)
+  path = unquote(parsed.path or "")
+  if parsed.netloc:
+    path = f"//{parsed.netloc}{path}"
+  fs_path = Path(url2pathname(path))
+  return fs_path
+
+
+def _html_to_text(html: str) -> str:
+  parser = _HTMLToTextParser()
+  parser.feed(html)
+  parser.close()
+  text = parser.get_text()
+  return text or html
+
+
+def fetch_url_text(url: str, *, timeout: float = 15.0) -> str:
+  parsed = urlparse(url)
+  scheme = (parsed.scheme or "").lower()
+
+  if scheme in {"", "file"}:
+    path = _extract_file_path(url)
+    return path.read_text(encoding="utf-8")
+
+  if scheme not in {"http", "https"}:
+    raise ValueError(f"Unsupported URL scheme: {parsed.scheme or 'unknown'}")
+
+  request = Request(url, headers={"User-Agent": DEFAULT_USER_AGENT})
+  with urlopen(request, timeout=timeout) as response:  # nosec: B310 in controlled use
+    content_type = response.headers.get("Content-Type", "")
+    charset: Optional[str] = None
+    try:
+      charset = response.headers.get_content_charset()  # type: ignore[attr-defined]
+    except Exception:  # pragma: no cover - very old Python versions only
+      charset = None
+    data = response.read()
+
+  encoding = charset or "utf-8"
+  text = data.decode(encoding, errors="replace")
+  if "html" in content_type.lower():
+    return _html_to_text(text)
+  return text
+
+
+__all__ = ["fetch_url_text"]
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"


thinking
**Running full pytest suite**
exec
bash -lc pytest in /var/home/rick/Development/llm_writer succeeded in 1.63s:
============================= test session starts ==============================
platform linux -- Python 3.13.9, pytest-8.4.2, pluggy-1.6.0
rootdir: /var/home/rick/Development/llm_writer
configfile: pyproject.toml
testpaths: tests
plugins: Faker-37.8.0, xdist-3.8.0, mock-3.15.1, metadata-3.1.1, cov-7.0.0, asyncio-1.2.0, html-4.1.1, hypothesis-6.141.1, anyio-4.8.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collected 21 items

tests/test_cli_parser.py ..                                              [  9%]
tests/test_config_loader.py ...                                          [ 23%]
tests/test_llm_registry.py ....                                          [ 42%]
tests/test_mcp_normalization.py .....                                    [ 66%]
tests/test_prompt_building.py ..                                         [ 76%]
tests/test_runner_run_tasks.py ..                                        [ 85%]
tests/test_task_loading.py ...                                           [100%]

============================== 21 passed in 0.71s ==============================
file update:
diff --git a/src/simple_rag_writer/runner/run_tasks.py b/src/simple_rag_writer/runner/run_tasks.py
index 0141e4ccf4ea65806dee82d72114784e6b1c8b7b..d9fa29487a87ab4f79ef8dbcba52e97c779860b3
--- a/src/simple_rag_writer/runner/run_tasks.py
+++ b/src/simple_rag_writer/runner/run_tasks.py
@@ -2,18 +2,25 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import List
+from typing import List, Optional
 
 from rich.console import Console
 
-from simple_rag_writer.config.models import AppConfig
+from simple_rag_writer.config.models import AppConfig, RawCappedPolicy, SummaryPolicy
 from simple_rag_writer.llm.registry import ModelRegistry
-from simple_rag_writer.tasks.loader import load_task, expand_task_paths
 from simple_rag_writer.mcp.client import McpClient
 from simple_rag_writer.mcp.normalization import normalize_payload
+from simple_rag_writer.mcp.types import NormalizedItem
 from simple_rag_writer.prompts.task_prompt import build_task_prompt
+from simple_rag_writer.runner.url_fetcher import fetch_url_text
+from simple_rag_writer.tasks.loader import expand_task_paths, load_task
+from simple_rag_writer.tasks.models import McpReference, ReferenceCommon, UrlReference
 
 console = Console()
+DEFAULT_SUMMARY_PROMPT = (
+  "Summarize the following reference material into key bullet points, highlighting"
+  " actionable facts and important context."
+)
 
 
 @dataclass
@@ -22,6 +29,122 @@
   failed_tasks: List[str]
 
 
+def _format_item(item: NormalizedItem) -> str:
+  parts: List[str] = []
+  if item.title:
+    parts.append(f"Title: {item.title}")
+  if item.url:
+    parts.append(f"URL: {item.url}")
+  body = (item.body or item.snippet or "").strip()
+  if body:
+    parts.append(body)
+  elif item.metadata:
+    parts.append(str(item.metadata))
+  return "\n".join(parts).strip()
+
+
+def _render_raw_blob(reference: ReferenceCommon, items: List[NormalizedItem], policy: RawCappedPolicy) -> Optional[str]:
+  if not items:
+    return None
+  per_item_limit = reference.max_chars or policy.max_chars_per_item
+  total_limit = policy.max_total_chars
+  max_items = reference.max_items or policy.max_items_per_reference
+  chunks: List[str] = []
+  used = 0
+  for item in items[:max_items]:
+    formatted = _format_item(item)
+    if not formatted:
+      continue
+    snippet = formatted[:per_item_limit].strip()
+    if not snippet:
+      continue
+    if used + len(snippet) > total_limit:
+      remaining = total_limit - used
+      if remaining <= 0:
+        break
+      snippet = snippet[:remaining].rstrip()
+    chunks.append(snippet)
+    used += len(snippet)
+    if used >= total_limit:
+      break
+  if not chunks:
+    return None
+  return "\n\n".join(chunks)
+
+
+def _build_summary_prompt(reference: ReferenceCommon, items: List[NormalizedItem], policy: SummaryPolicy) -> str:
+  ref_type = reference.item_type or next((itm.type for itm in items if itm.type), None)
+  template = None
+  if ref_type:
+    template = policy.per_type_prompts.get(ref_type)
+  if not template:
+    template = policy.default_prompt or DEFAULT_SUMMARY_PROMPT
+  sections: List[str] = []
+  for idx, item in enumerate(items, start=1):
+    heading = item.title or f"Item {idx}"
+    body = (item.body or item.snippet or "").strip()
+    lines = [f"## {heading}"]
+    if body:
+      lines.append(body)
+    if item.url:
+      lines.append(f"Source: {item.url}")
+    sections.append("\n".join(lines).strip())
+  body_text = "\n\n".join(sections)
+  return f"{template.strip()}\n\n{body_text}".strip()
+
+
+def _render_summary_blob(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  policy: SummaryPolicy,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  if not items:
+    return None
+  max_items = reference.max_items or policy.max_items_per_reference
+  limited = items[:max_items]
+  prompt = _build_summary_prompt(reference, limited, policy)
+  max_tokens = reference.summary_max_tokens or policy.summary_max_tokens
+  summary = registry.complete(
+    prompt,
+    model_id=policy.summarizer_model,
+    task_params={"max_tokens": max_tokens},
+  )
+  return summary.strip() or None
+
+
+def _apply_prompt_policy(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  config: AppConfig,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  mode = reference.prompt_mode or config.mcp_prompt_policy.default_mode
+  if mode == "summary":
+    return _render_summary_blob(reference, items, config.mcp_prompt_policy.summary, registry)
+  return _render_raw_blob(reference, items, config.mcp_prompt_policy.raw_capped)
+
+
+def _wrap_reference_label(reference: ReferenceCommon, text: Optional[str]) -> Optional[str]:
+  if not text:
+    return None
+  if reference.label:
+    return f"{reference.label}\n{text}"
+  return text
+
+
+def _url_items(reference: UrlReference, text: str) -> List[NormalizedItem]:
+  return [
+    NormalizedItem(
+      id=reference.url,
+      type=reference.item_type or "url",
+      title=reference.label or reference.url,
+      body=text.strip(),
+      url=reference.url,
+    )
+  ]
+
+
 def run_tasks_for_paths(
   config: AppConfig,
   registry: ModelRegistry,
@@ -41,7 +164,7 @@
       outline_context = None  # TODO: outline loading
 
       for ref in task.references:
-        if ref.type == "mcp":
+        if isinstance(ref, McpReference):
           try:
             result = client.call_tool(ref.server, ref.tool, ref.params)
           except Exception as exc:  # noqa: BLE001
@@ -50,15 +173,26 @@
               raise
             console.print(f"[yellow]MCP error (skipping reference): {exc}[/yellow]")
             continue
-
           items = normalize_payload(result.payload, item_type_hint=ref.item_type)
-          blob = "\n\n".join(
-            [
-              f"Title: {itm.title or ''}\n{itm.body or itm.snippet or ''}"
-              for itm in items
-            ]
-          )
-          reference_blobs.append(blob)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
+        elif isinstance(ref, UrlReference):
+          try:
+            fetched = fetch_url_text(ref.url)
+          except Exception as exc:  # noqa: BLE001
+            console.print(
+              f"[yellow]Failed to fetch URL {ref.url}: {exc}[/yellow]"
+            )
+            continue
+          if not fetched.strip():
+            continue
+          items = _url_items(ref, fetched)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
 
       prompt = build_task_prompt(task, outline_context, reference_blobs)
 
diff --git a/src/simple_rag_writer/runner/url_fetcher.py b/src/simple_rag_writer/runner/url_fetcher.py
new file mode 100644
index 0000000000000000000000000000000000000000..00abbf5049f05fcbcf0b5805378d5032ed50e20c
--- /dev/null
+++ b/src/simple_rag_writer/runner/url_fetcher.py
@@ -0,0 +1,90 @@
+from __future__ import annotations
+
+from html.parser import HTMLParser
+from pathlib import Path
+from typing import Optional
+from urllib.parse import unquote, urlparse
+from urllib.request import Request, url2pathname, urlopen
+
+DEFAULT_USER_AGENT = "simple-rag-writer/0.1"
+
+
+class _HTMLToTextParser(HTMLParser):
+  def __init__(self) -> None:
+    super().__init__()
+    self._parts: list[str] = []
+    self._skip_depth = 0
+
+  def handle_starttag(self, tag: str, attrs):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"br", "p", "div", "section", "article", "li", "tr"}:
+      self._parts.append("\n")
+    if lowered in {"script", "style"}:
+      self._skip_depth += 1
+
+  def handle_endtag(self, tag: str):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"script", "style"} and self._skip_depth:
+      self._skip_depth -= 1
+    elif lowered in {"p", "div", "section", "article", "li"}:
+      self._parts.append("\n")
+
+  def handle_data(self, data: str):  # type: ignore[override]
+    if self._skip_depth:
+      return
+    if data.strip():
+      self._parts.append(data)
+
+  def get_text(self) -> str:
+    raw = "".join(self._parts)
+    lines = [line.strip() for line in raw.splitlines()]
+    filtered = "\n".join(line for line in lines if line)
+    return filtered.strip()
+
+
+def _extract_file_path(url: str) -> Path:
+  parsed = urlparse(url)
+  path = unquote(parsed.path or "")
+  if parsed.netloc:
+    path = f"//{parsed.netloc}{path}"
+  fs_path = Path(url2pathname(path))
+  return fs_path
+
+
+def _html_to_text(html: str) -> str:
+  parser = _HTMLToTextParser()
+  parser.feed(html)
+  parser.close()
+  text = parser.get_text()
+  return text or html
+
+
+def fetch_url_text(url: str, *, timeout: float = 15.0) -> str:
+  parsed = urlparse(url)
+  scheme = (parsed.scheme or "").lower()
+
+  if scheme in {"", "file"}:
+    path = _extract_file_path(url)
+    return path.read_text(encoding="utf-8")
+
+  if scheme not in {"http", "https"}:
+    raise ValueError(f"Unsupported URL scheme: {parsed.scheme or 'unknown'}")
+
+  request = Request(url, headers={"User-Agent": DEFAULT_USER_AGENT})
+  with urlopen(request, timeout=timeout) as response:  # nosec: B310 in controlled use
+    content_type = response.headers.get("Content-Type", "")
+    charset: Optional[str] = None
+    try:
+      charset = response.headers.get_content_charset()  # type: ignore[attr-defined]
+    except Exception:  # pragma: no cover - very old Python versions only
+      charset = None
+    data = response.read()
+
+  encoding = charset or "utf-8"
+  text = data.decode(encoding, errors="replace")
+  if "html" in content_type.lower():
+    return _html_to_text(text)
+  return text
+
+
+__all__ = ["fetch_url_text"]
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"


thinking
**Updating plan statuses**
Plan update
  ✓ Review existing runner behavior/spec and design tests for MCP+URL orchestration and error handling
  ✓ Implement runner/url_fetcher helper plus prompt-policy processing in run_tasks
  ✓ Run pytest and finalize changes
file update:
diff --git a/src/simple_rag_writer/runner/run_tasks.py b/src/simple_rag_writer/runner/run_tasks.py
index 0141e4ccf4ea65806dee82d72114784e6b1c8b7b..d9fa29487a87ab4f79ef8dbcba52e97c779860b3
--- a/src/simple_rag_writer/runner/run_tasks.py
+++ b/src/simple_rag_writer/runner/run_tasks.py
@@ -2,18 +2,25 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import List
+from typing import List, Optional
 
 from rich.console import Console
 
-from simple_rag_writer.config.models import AppConfig
+from simple_rag_writer.config.models import AppConfig, RawCappedPolicy, SummaryPolicy
 from simple_rag_writer.llm.registry import ModelRegistry
-from simple_rag_writer.tasks.loader import load_task, expand_task_paths
 from simple_rag_writer.mcp.client import McpClient
 from simple_rag_writer.mcp.normalization import normalize_payload
+from simple_rag_writer.mcp.types import NormalizedItem
 from simple_rag_writer.prompts.task_prompt import build_task_prompt
+from simple_rag_writer.runner.url_fetcher import fetch_url_text
+from simple_rag_writer.tasks.loader import expand_task_paths, load_task
+from simple_rag_writer.tasks.models import McpReference, ReferenceCommon, UrlReference
 
 console = Console()
+DEFAULT_SUMMARY_PROMPT = (
+  "Summarize the following reference material into key bullet points, highlighting"
+  " actionable facts and important context."
+)
 
 
 @dataclass
@@ -22,6 +29,122 @@
   failed_tasks: List[str]
 
 
+def _format_item(item: NormalizedItem) -> str:
+  parts: List[str] = []
+  if item.title:
+    parts.append(f"Title: {item.title}")
+  if item.url:
+    parts.append(f"URL: {item.url}")
+  body = (item.body or item.snippet or "").strip()
+  if body:
+    parts.append(body)
+  elif item.metadata:
+    parts.append(str(item.metadata))
+  return "\n".join(parts).strip()
+
+
+def _render_raw_blob(reference: ReferenceCommon, items: List[NormalizedItem], policy: RawCappedPolicy) -> Optional[str]:
+  if not items:
+    return None
+  per_item_limit = reference.max_chars or policy.max_chars_per_item
+  total_limit = policy.max_total_chars
+  max_items = reference.max_items or policy.max_items_per_reference
+  chunks: List[str] = []
+  used = 0
+  for item in items[:max_items]:
+    formatted = _format_item(item)
+    if not formatted:
+      continue
+    snippet = formatted[:per_item_limit].strip()
+    if not snippet:
+      continue
+    if used + len(snippet) > total_limit:
+      remaining = total_limit - used
+      if remaining <= 0:
+        break
+      snippet = snippet[:remaining].rstrip()
+    chunks.append(snippet)
+    used += len(snippet)
+    if used >= total_limit:
+      break
+  if not chunks:
+    return None
+  return "\n\n".join(chunks)
+
+
+def _build_summary_prompt(reference: ReferenceCommon, items: List[NormalizedItem], policy: SummaryPolicy) -> str:
+  ref_type = reference.item_type or next((itm.type for itm in items if itm.type), None)
+  template = None
+  if ref_type:
+    template = policy.per_type_prompts.get(ref_type)
+  if not template:
+    template = policy.default_prompt or DEFAULT_SUMMARY_PROMPT
+  sections: List[str] = []
+  for idx, item in enumerate(items, start=1):
+    heading = item.title or f"Item {idx}"
+    body = (item.body or item.snippet or "").strip()
+    lines = [f"## {heading}"]
+    if body:
+      lines.append(body)
+    if item.url:
+      lines.append(f"Source: {item.url}")
+    sections.append("\n".join(lines).strip())
+  body_text = "\n\n".join(sections)
+  return f"{template.strip()}\n\n{body_text}".strip()
+
+
+def _render_summary_blob(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  policy: SummaryPolicy,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  if not items:
+    return None
+  max_items = reference.max_items or policy.max_items_per_reference
+  limited = items[:max_items]
+  prompt = _build_summary_prompt(reference, limited, policy)
+  max_tokens = reference.summary_max_tokens or policy.summary_max_tokens
+  summary = registry.complete(
+    prompt,
+    model_id=policy.summarizer_model,
+    task_params={"max_tokens": max_tokens},
+  )
+  return summary.strip() or None
+
+
+def _apply_prompt_policy(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  config: AppConfig,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  mode = reference.prompt_mode or config.mcp_prompt_policy.default_mode
+  if mode == "summary":
+    return _render_summary_blob(reference, items, config.mcp_prompt_policy.summary, registry)
+  return _render_raw_blob(reference, items, config.mcp_prompt_policy.raw_capped)
+
+
+def _wrap_reference_label(reference: ReferenceCommon, text: Optional[str]) -> Optional[str]:
+  if not text:
+    return None
+  if reference.label:
+    return f"{reference.label}\n{text}"
+  return text
+
+
+def _url_items(reference: UrlReference, text: str) -> List[NormalizedItem]:
+  return [
+    NormalizedItem(
+      id=reference.url,
+      type=reference.item_type or "url",
+      title=reference.label or reference.url,
+      body=text.strip(),
+      url=reference.url,
+    )
+  ]
+
+
 def run_tasks_for_paths(
   config: AppConfig,
   registry: ModelRegistry,
@@ -41,7 +164,7 @@
       outline_context = None  # TODO: outline loading
 
       for ref in task.references:
-        if ref.type == "mcp":
+        if isinstance(ref, McpReference):
           try:
             result = client.call_tool(ref.server, ref.tool, ref.params)
           except Exception as exc:  # noqa: BLE001
@@ -50,15 +173,26 @@
               raise
             console.print(f"[yellow]MCP error (skipping reference): {exc}[/yellow]")
             continue
-
           items = normalize_payload(result.payload, item_type_hint=ref.item_type)
-          blob = "\n\n".join(
-            [
-              f"Title: {itm.title or ''}\n{itm.body or itm.snippet or ''}"
-              for itm in items
-            ]
-          )
-          reference_blobs.append(blob)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
+        elif isinstance(ref, UrlReference):
+          try:
+            fetched = fetch_url_text(ref.url)
+          except Exception as exc:  # noqa: BLE001
+            console.print(
+              f"[yellow]Failed to fetch URL {ref.url}: {exc}[/yellow]"
+            )
+            continue
+          if not fetched.strip():
+            continue
+          items = _url_items(ref, fetched)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
 
       prompt = build_task_prompt(task, outline_context, reference_blobs)
 
diff --git a/src/simple_rag_writer/runner/url_fetcher.py b/src/simple_rag_writer/runner/url_fetcher.py
new file mode 100644
index 0000000000000000000000000000000000000000..00abbf5049f05fcbcf0b5805378d5032ed50e20c
--- /dev/null
+++ b/src/simple_rag_writer/runner/url_fetcher.py
@@ -0,0 +1,90 @@
+from __future__ import annotations
+
+from html.parser import HTMLParser
+from pathlib import Path
+from typing import Optional
+from urllib.parse import unquote, urlparse
+from urllib.request import Request, url2pathname, urlopen
+
+DEFAULT_USER_AGENT = "simple-rag-writer/0.1"
+
+
+class _HTMLToTextParser(HTMLParser):
+  def __init__(self) -> None:
+    super().__init__()
+    self._parts: list[str] = []
+    self._skip_depth = 0
+
+  def handle_starttag(self, tag: str, attrs):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"br", "p", "div", "section", "article", "li", "tr"}:
+      self._parts.append("\n")
+    if lowered in {"script", "style"}:
+      self._skip_depth += 1
+
+  def handle_endtag(self, tag: str):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"script", "style"} and self._skip_depth:
+      self._skip_depth -= 1
+    elif lowered in {"p", "div", "section", "article", "li"}:
+      self._parts.append("\n")
+
+  def handle_data(self, data: str):  # type: ignore[override]
+    if self._skip_depth:
+      return
+    if data.strip():
+      self._parts.append(data)
+
+  def get_text(self) -> str:
+    raw = "".join(self._parts)
+    lines = [line.strip() for line in raw.splitlines()]
+    filtered = "\n".join(line for line in lines if line)
+    return filtered.strip()
+
+
+def _extract_file_path(url: str) -> Path:
+  parsed = urlparse(url)
+  path = unquote(parsed.path or "")
+  if parsed.netloc:
+    path = f"//{parsed.netloc}{path}"
+  fs_path = Path(url2pathname(path))
+  return fs_path
+
+
+def _html_to_text(html: str) -> str:
+  parser = _HTMLToTextParser()
+  parser.feed(html)
+  parser.close()
+  text = parser.get_text()
+  return text or html
+
+
+def fetch_url_text(url: str, *, timeout: float = 15.0) -> str:
+  parsed = urlparse(url)
+  scheme = (parsed.scheme or "").lower()
+
+  if scheme in {"", "file"}:
+    path = _extract_file_path(url)
+    return path.read_text(encoding="utf-8")
+
+  if scheme not in {"http", "https"}:
+    raise ValueError(f"Unsupported URL scheme: {parsed.scheme or 'unknown'}")
+
+  request = Request(url, headers={"User-Agent": DEFAULT_USER_AGENT})
+  with urlopen(request, timeout=timeout) as response:  # nosec: B310 in controlled use
+    content_type = response.headers.get("Content-Type", "")
+    charset: Optional[str] = None
+    try:
+      charset = response.headers.get_content_charset()  # type: ignore[attr-defined]
+    except Exception:  # pragma: no cover - very old Python versions only
+      charset = None
+    data = response.read()
+
+  encoding = charset or "utf-8"
+  text = data.decode(encoding, errors="replace")
+  if "html" in content_type.lower():
+    return _html_to_text(text)
+  return text
+
+
+__all__ = ["fetch_url_text"]
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"


thinking
**Checking git status**
exec
bash -lc 'git status -sb' in /var/home/rick/Development/llm_writer succeeded in 186ms:
## main
?? codex/LOGS/codex_run_2025-11-16_04-58-12.log
?? codex/LOGS/tasklog_01_bootstrap_project_and_cli_1763287092.log
?? codex/LOGS/tasklog_01_bootstrap_project_and_cli_1763287092.log.done
?? codex/LOGS/tasklog_02_implement_config_models_and_loader_1763287503.log
?? codex/LOGS/tasklog_02_implement_config_models_and_loader_1763287503.log.done
?? codex/LOGS/tasklog_03_implement_model_registry_and_litellm_integration_1763287725.log
?? codex/LOGS/tasklog_03_implement_model_registry_and_litellm_integration_1763287725.log.done
?? codex/LOGS/tasklog_04_define_task_spec_and_loader_1763287876.log
?? codex/LOGS/tasklog_04_define_task_spec_and_loader_1763287876.log.done
?? codex/LOGS/tasklog_05_implement_prompt_builders_1763288031.log
?? codex/LOGS/tasklog_05_implement_prompt_builders_1763288031.log.done
?? codex/LOGS/tasklog_06_implement_mcp_types_and_normalization_1763288389.log
?? codex/LOGS/tasklog_06_implement_mcp_types_and_normalization_1763288389.log.done
?? codex/LOGS/tasklog_07_implement_automated_task_runner_1763288534.log
?? src/simple_rag_writer/__init__.py
?? src/simple_rag_writer/__pycache__/
?? src/simple_rag_writer/cli/
?? src/simple_rag_writer/config/
?? src/simple_rag_writer/llm/
file update:
diff --git a/src/simple_rag_writer/runner/run_tasks.py b/src/simple_rag_writer/runner/run_tasks.py
index 0141e4ccf4ea65806dee82d72114784e6b1c8b7b..d9fa29487a87ab4f79ef8dbcba52e97c779860b3
--- a/src/simple_rag_writer/runner/run_tasks.py
+++ b/src/simple_rag_writer/runner/run_tasks.py
@@ -2,18 +2,25 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import List
+from typing import List, Optional
 
 from rich.console import Console
 
-from simple_rag_writer.config.models import AppConfig
+from simple_rag_writer.config.models import AppConfig, RawCappedPolicy, SummaryPolicy
 from simple_rag_writer.llm.registry import ModelRegistry
-from simple_rag_writer.tasks.loader import load_task, expand_task_paths
 from simple_rag_writer.mcp.client import McpClient
 from simple_rag_writer.mcp.normalization import normalize_payload
+from simple_rag_writer.mcp.types import NormalizedItem
 from simple_rag_writer.prompts.task_prompt import build_task_prompt
+from simple_rag_writer.runner.url_fetcher import fetch_url_text
+from simple_rag_writer.tasks.loader import expand_task_paths, load_task
+from simple_rag_writer.tasks.models import McpReference, ReferenceCommon, UrlReference
 
 console = Console()
+DEFAULT_SUMMARY_PROMPT = (
+  "Summarize the following reference material into key bullet points, highlighting"
+  " actionable facts and important context."
+)
 
 
 @dataclass
@@ -22,6 +29,122 @@
   failed_tasks: List[str]
 
 
+def _format_item(item: NormalizedItem) -> str:
+  parts: List[str] = []
+  if item.title:
+    parts.append(f"Title: {item.title}")
+  if item.url:
+    parts.append(f"URL: {item.url}")
+  body = (item.body or item.snippet or "").strip()
+  if body:
+    parts.append(body)
+  elif item.metadata:
+    parts.append(str(item.metadata))
+  return "\n".join(parts).strip()
+
+
+def _render_raw_blob(reference: ReferenceCommon, items: List[NormalizedItem], policy: RawCappedPolicy) -> Optional[str]:
+  if not items:
+    return None
+  per_item_limit = reference.max_chars or policy.max_chars_per_item
+  total_limit = policy.max_total_chars
+  max_items = reference.max_items or policy.max_items_per_reference
+  chunks: List[str] = []
+  used = 0
+  for item in items[:max_items]:
+    formatted = _format_item(item)
+    if not formatted:
+      continue
+    snippet = formatted[:per_item_limit].strip()
+    if not snippet:
+      continue
+    if used + len(snippet) > total_limit:
+      remaining = total_limit - used
+      if remaining <= 0:
+        break
+      snippet = snippet[:remaining].rstrip()
+    chunks.append(snippet)
+    used += len(snippet)
+    if used >= total_limit:
+      break
+  if not chunks:
+    return None
+  return "\n\n".join(chunks)
+
+
+def _build_summary_prompt(reference: ReferenceCommon, items: List[NormalizedItem], policy: SummaryPolicy) -> str:
+  ref_type = reference.item_type or next((itm.type for itm in items if itm.type), None)
+  template = None
+  if ref_type:
+    template = policy.per_type_prompts.get(ref_type)
+  if not template:
+    template = policy.default_prompt or DEFAULT_SUMMARY_PROMPT
+  sections: List[str] = []
+  for idx, item in enumerate(items, start=1):
+    heading = item.title or f"Item {idx}"
+    body = (item.body or item.snippet or "").strip()
+    lines = [f"## {heading}"]
+    if body:
+      lines.append(body)
+    if item.url:
+      lines.append(f"Source: {item.url}")
+    sections.append("\n".join(lines).strip())
+  body_text = "\n\n".join(sections)
+  return f"{template.strip()}\n\n{body_text}".strip()
+
+
+def _render_summary_blob(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  policy: SummaryPolicy,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  if not items:
+    return None
+  max_items = reference.max_items or policy.max_items_per_reference
+  limited = items[:max_items]
+  prompt = _build_summary_prompt(reference, limited, policy)
+  max_tokens = reference.summary_max_tokens or policy.summary_max_tokens
+  summary = registry.complete(
+    prompt,
+    model_id=policy.summarizer_model,
+    task_params={"max_tokens": max_tokens},
+  )
+  return summary.strip() or None
+
+
+def _apply_prompt_policy(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  config: AppConfig,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  mode = reference.prompt_mode or config.mcp_prompt_policy.default_mode
+  if mode == "summary":
+    return _render_summary_blob(reference, items, config.mcp_prompt_policy.summary, registry)
+  return _render_raw_blob(reference, items, config.mcp_prompt_policy.raw_capped)
+
+
+def _wrap_reference_label(reference: ReferenceCommon, text: Optional[str]) -> Optional[str]:
+  if not text:
+    return None
+  if reference.label:
+    return f"{reference.label}\n{text}"
+  return text
+
+
+def _url_items(reference: UrlReference, text: str) -> List[NormalizedItem]:
+  return [
+    NormalizedItem(
+      id=reference.url,
+      type=reference.item_type or "url",
+      title=reference.label or reference.url,
+      body=text.strip(),
+      url=reference.url,
+    )
+  ]
+
+
 def run_tasks_for_paths(
   config: AppConfig,
   registry: ModelRegistry,
@@ -41,7 +164,7 @@
       outline_context = None  # TODO: outline loading
 
       for ref in task.references:
-        if ref.type == "mcp":
+        if isinstance(ref, McpReference):
           try:
             result = client.call_tool(ref.server, ref.tool, ref.params)
           except Exception as exc:  # noqa: BLE001
@@ -50,15 +173,26 @@
               raise
             console.print(f"[yellow]MCP error (skipping reference): {exc}[/yellow]")
             continue
-
           items = normalize_payload(result.payload, item_type_hint=ref.item_type)
-          blob = "\n\n".join(
-            [
-              f"Title: {itm.title or ''}\n{itm.body or itm.snippet or ''}"
-              for itm in items
-            ]
-          )
-          reference_blobs.append(blob)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
+        elif isinstance(ref, UrlReference):
+          try:
+            fetched = fetch_url_text(ref.url)
+          except Exception as exc:  # noqa: BLE001
+            console.print(
+              f"[yellow]Failed to fetch URL {ref.url}: {exc}[/yellow]"
+            )
+            continue
+          if not fetched.strip():
+            continue
+          items = _url_items(ref, fetched)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
 
       prompt = build_task_prompt(task, outline_context, reference_blobs)
 
diff --git a/src/simple_rag_writer/runner/url_fetcher.py b/src/simple_rag_writer/runner/url_fetcher.py
new file mode 100644
index 0000000000000000000000000000000000000000..00abbf5049f05fcbcf0b5805378d5032ed50e20c
--- /dev/null
+++ b/src/simple_rag_writer/runner/url_fetcher.py
@@ -0,0 +1,90 @@
+from __future__ import annotations
+
+from html.parser import HTMLParser
+from pathlib import Path
+from typing import Optional
+from urllib.parse import unquote, urlparse
+from urllib.request import Request, url2pathname, urlopen
+
+DEFAULT_USER_AGENT = "simple-rag-writer/0.1"
+
+
+class _HTMLToTextParser(HTMLParser):
+  def __init__(self) -> None:
+    super().__init__()
+    self._parts: list[str] = []
+    self._skip_depth = 0
+
+  def handle_starttag(self, tag: str, attrs):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"br", "p", "div", "section", "article", "li", "tr"}:
+      self._parts.append("\n")
+    if lowered in {"script", "style"}:
+      self._skip_depth += 1
+
+  def handle_endtag(self, tag: str):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"script", "style"} and self._skip_depth:
+      self._skip_depth -= 1
+    elif lowered in {"p", "div", "section", "article", "li"}:
+      self._parts.append("\n")
+
+  def handle_data(self, data: str):  # type: ignore[override]
+    if self._skip_depth:
+      return
+    if data.strip():
+      self._parts.append(data)
+
+  def get_text(self) -> str:
+    raw = "".join(self._parts)
+    lines = [line.strip() for line in raw.splitlines()]
+    filtered = "\n".join(line for line in lines if line)
+    return filtered.strip()
+
+
+def _extract_file_path(url: str) -> Path:
+  parsed = urlparse(url)
+  path = unquote(parsed.path or "")
+  if parsed.netloc:
+    path = f"//{parsed.netloc}{path}"
+  fs_path = Path(url2pathname(path))
+  return fs_path
+
+
+def _html_to_text(html: str) -> str:
+  parser = _HTMLToTextParser()
+  parser.feed(html)
+  parser.close()
+  text = parser.get_text()
+  return text or html
+
+
+def fetch_url_text(url: str, *, timeout: float = 15.0) -> str:
+  parsed = urlparse(url)
+  scheme = (parsed.scheme or "").lower()
+
+  if scheme in {"", "file"}:
+    path = _extract_file_path(url)
+    return path.read_text(encoding="utf-8")
+
+  if scheme not in {"http", "https"}:
+    raise ValueError(f"Unsupported URL scheme: {parsed.scheme or 'unknown'}")
+
+  request = Request(url, headers={"User-Agent": DEFAULT_USER_AGENT})
+  with urlopen(request, timeout=timeout) as response:  # nosec: B310 in controlled use
+    content_type = response.headers.get("Content-Type", "")
+    charset: Optional[str] = None
+    try:
+      charset = response.headers.get_content_charset()  # type: ignore[attr-defined]
+    except Exception:  # pragma: no cover - very old Python versions only
+      charset = None
+    data = response.read()
+
+  encoding = charset or "utf-8"
+  text = data.decode(encoding, errors="replace")
+  if "html" in content_type.lower():
+    return _html_to_text(text)
+  return text
+
+
+__all__ = ["fetch_url_text"]
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"


thinking
**Analyzing untracked repository state**
exec
bash -lc 'nl -ba src/simple_rag_writer/runner/run_tasks.py' in /var/home/rick/Development/llm_writer succeeded in 44ms:
     1	from __future__ import annotations
     2	
     3	from dataclasses import dataclass
     4	from pathlib import Path
     5	from typing import List, Optional
     6	
     7	from rich.console import Console
     8	
     9	from simple_rag_writer.config.models import AppConfig, RawCappedPolicy, SummaryPolicy
    10	from simple_rag_writer.llm.registry import ModelRegistry
    11	from simple_rag_writer.mcp.client import McpClient
    12	from simple_rag_writer.mcp.normalization import normalize_payload
    13	from simple_rag_writer.mcp.types import NormalizedItem
    14	from simple_rag_writer.prompts.task_prompt import build_task_prompt
    15	from simple_rag_writer.runner.url_fetcher import fetch_url_text
    16	from simple_rag_writer.tasks.loader import expand_task_paths, load_task
    17	from simple_rag_writer.tasks.models import McpReference, ReferenceCommon, UrlReference
    18	
    19	console = Console()
    20	DEFAULT_SUMMARY_PROMPT = (
file update:
diff --git a/src/simple_rag_writer/runner/run_tasks.py b/src/simple_rag_writer/runner/run_tasks.py
index 0141e4ccf4ea65806dee82d72114784e6b1c8b7b..d9fa29487a87ab4f79ef8dbcba52e97c779860b3
--- a/src/simple_rag_writer/runner/run_tasks.py
+++ b/src/simple_rag_writer/runner/run_tasks.py
@@ -2,18 +2,25 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import List
+from typing import List, Optional
 
 from rich.console import Console
 
-from simple_rag_writer.config.models import AppConfig
+from simple_rag_writer.config.models import AppConfig, RawCappedPolicy, SummaryPolicy
 from simple_rag_writer.llm.registry import ModelRegistry
-from simple_rag_writer.tasks.loader import load_task, expand_task_paths
 from simple_rag_writer.mcp.client import McpClient
 from simple_rag_writer.mcp.normalization import normalize_payload
+from simple_rag_writer.mcp.types import NormalizedItem
 from simple_rag_writer.prompts.task_prompt import build_task_prompt
+from simple_rag_writer.runner.url_fetcher import fetch_url_text
+from simple_rag_writer.tasks.loader import expand_task_paths, load_task
+from simple_rag_writer.tasks.models import McpReference, ReferenceCommon, UrlReference
 
 console = Console()
+DEFAULT_SUMMARY_PROMPT = (
+  "Summarize the following reference material into key bullet points, highlighting"
+  " actionable facts and important context."
+)
 
 
 @dataclass
@@ -22,6 +29,122 @@
   failed_tasks: List[str]
 
 
+def _format_item(item: NormalizedItem) -> str:
+  parts: List[str] = []
+  if item.title:
+    parts.append(f"Title: {item.title}")
+  if item.url:
+    parts.append(f"URL: {item.url}")
+  body = (item.body or item.snippet or "").strip()
+  if body:
+    parts.append(body)
+  elif item.metadata:
+    parts.append(str(item.metadata))
+  return "\n".join(parts).strip()
+
+
+def _render_raw_blob(reference: ReferenceCommon, items: List[NormalizedItem], policy: RawCappedPolicy) -> Optional[str]:
+  if not items:
+    return None
+  per_item_limit = reference.max_chars or policy.max_chars_per_item
+  total_limit = policy.max_total_chars
+  max_items = reference.max_items or policy.max_items_per_reference
+  chunks: List[str] = []
+  used = 0
+  for item in items[:max_items]:
+    formatted = _format_item(item)
+    if not formatted:
+      continue
+    snippet = formatted[:per_item_limit].strip()
+    if not snippet:
+      continue
+    if used + len(snippet) > total_limit:
+      remaining = total_limit - used
+      if remaining <= 0:
+        break
+      snippet = snippet[:remaining].rstrip()
+    chunks.append(snippet)
+    used += len(snippet)
+    if used >= total_limit:
+      break
+  if not chunks:
+    return None
+  return "\n\n".join(chunks)
+
+
+def _build_summary_prompt(reference: ReferenceCommon, items: List[NormalizedItem], policy: SummaryPolicy) -> str:
+  ref_type = reference.item_type or next((itm.type for itm in items if itm.type), None)
+  template = None
+  if ref_type:
+    template = policy.per_type_prompts.get(ref_type)
+  if not template:
+    template = policy.default_prompt or DEFAULT_SUMMARY_PROMPT
+  sections: List[str] = []
+  for idx, item in enumerate(items, start=1):
+    heading = item.title or f"Item {idx}"
+    body = (item.body or item.snippet or "").strip()
+    lines = [f"## {heading}"]
+    if body:
+      lines.append(body)
+    if item.url:
+      lines.append(f"Source: {item.url}")
+    sections.append("\n".join(lines).strip())
+  body_text = "\n\n".join(sections)
+  return f"{template.strip()}\n\n{body_text}".strip()
+
+
+def _render_summary_blob(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  policy: SummaryPolicy,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  if not items:
+    return None
+  max_items = reference.max_items or policy.max_items_per_reference
+  limited = items[:max_items]
+  prompt = _build_summary_prompt(reference, limited, policy)
+  max_tokens = reference.summary_max_tokens or policy.summary_max_tokens
+  summary = registry.complete(
+    prompt,
+    model_id=policy.summarizer_model,
+    task_params={"max_tokens": max_tokens},
+  )
+  return summary.strip() or None
+
+
+def _apply_prompt_policy(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  config: AppConfig,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  mode = reference.prompt_mode or config.mcp_prompt_policy.default_mode
+  if mode == "summary":
+    return _render_summary_blob(reference, items, config.mcp_prompt_policy.summary, registry)
+  return _render_raw_blob(reference, items, config.mcp_prompt_policy.raw_capped)
+
+
+def _wrap_reference_label(reference: ReferenceCommon, text: Optional[str]) -> Optional[str]:
+  if not text:
+    return None
+  if reference.label:
+    return f"{reference.label}\n{text}"
+  return text
+
+
+def _url_items(reference: UrlReference, text: str) -> List[NormalizedItem]:
+  return [
+    NormalizedItem(
+      id=reference.url,
+      type=reference.item_type or "url",
+      title=reference.label or reference.url,
+      body=text.strip(),
+      url=reference.url,
+    )
+  ]
+
+
 def run_tasks_for_paths(
   config: AppConfig,
   registry: ModelRegistry,
@@ -41,7 +164,7 @@
       outline_context = None  # TODO: outline loading
 
       for ref in task.references:
-        if ref.type == "mcp":
+        if isinstance(ref, McpReference):
           try:
             result = client.call_tool(ref.server, ref.tool, ref.params)
           except Exception as exc:  # noqa: BLE001
@@ -50,15 +173,26 @@
               raise
             console.print(f"[yellow]MCP error (skipping reference): {exc}[/yellow]")
             continue
-
           items = normalize_payload(result.payload, item_type_hint=ref.item_type)
-          blob = "\n\n".join(
-            [
-              f"Title: {itm.title or ''}\n{itm.body or itm.snippet or ''}"
-              for itm in items
-            ]
-          )
-          reference_blobs.append(blob)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
+        elif isinstance(ref, UrlReference):
+          try:
+            fetched = fetch_url_text(ref.url)
+          except Exception as exc:  # noqa: BLE001
+            console.print(
+              f"[yellow]Failed to fetch URL {ref.url}: {exc}[/yellow]"
+            )
+            continue
+          if not fetched.strip():
+            continue
+          items = _url_items(ref, fetched)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
 
       prompt = build_task_prompt(task, outline_context, reference_blobs)
 
diff --git a/src/simple_rag_writer/runner/url_fetcher.py b/src/simple_rag_writer/runner/url_fetcher.py
new file mode 100644
index 0000000000000000000000000000000000000000..00abbf5049f05fcbcf0b5805378d5032ed50e20c
--- /dev/null
+++ b/src/simple_rag_writer/runner/url_fetcher.py
@@ -0,0 +1,90 @@
+from __future__ import annotations
+
+from html.parser import HTMLParser
+from pathlib import Path
+from typing import Optional
+from urllib.parse import unquote, urlparse
+from urllib.request import Request, url2pathname, urlopen
+
+DEFAULT_USER_AGENT = "simple-rag-writer/0.1"
+
+
+class _HTMLToTextParser(HTMLParser):
+  def __init__(self) -> None:
+    super().__init__()
+    self._parts: list[str] = []
+    self._skip_depth = 0
+
+  def handle_starttag(self, tag: str, attrs):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"br", "p", "div", "section", "article", "li", "tr"}:
+      self._parts.append("\n")
+    if lowered in {"script", "style"}:
+      self._skip_depth += 1
+
+  def handle_endtag(self, tag: str):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"script", "style"} and self._skip_depth:
+      self._skip_depth -= 1
+    elif lowered in {"p", "div", "section", "article", "li"}:
+      self._parts.append("\n")
+
+  def handle_data(self, data: str):  # type: ignore[override]
+    if self._skip_depth:
+      return
+    if data.strip():
+      self._parts.append(data)
+
+  def get_text(self) -> str:
+    raw = "".join(self._parts)
+    lines = [line.strip() for line in raw.splitlines()]
+    filtered = "\n".join(line for line in lines if line)
+    return filtered.strip()
+
+
+def _extract_file_path(url: str) -> Path:
+  parsed = urlparse(url)
+  path = unquote(parsed.path or "")
+  if parsed.netloc:
+    path = f"//{parsed.netloc}{path}"
+  fs_path = Path(url2pathname(path))
+  return fs_path
+
+
+def _html_to_text(html: str) -> str:
+  parser = _HTMLToTextParser()
+  parser.feed(html)
+  parser.close()
+  text = parser.get_text()
+  return text or html
+
+
+def fetch_url_text(url: str, *, timeout: float = 15.0) -> str:
+  parsed = urlparse(url)
+  scheme = (parsed.scheme or "").lower()
+
+  if scheme in {"", "file"}:
+    path = _extract_file_path(url)
+    return path.read_text(encoding="utf-8")
+
+  if scheme not in {"http", "https"}:
+    raise ValueError(f"Unsupported URL scheme: {parsed.scheme or 'unknown'}")
+
+  request = Request(url, headers={"User-Agent": DEFAULT_USER_AGENT})
+  with urlopen(request, timeout=timeout) as response:  # nosec: B310 in controlled use
+    content_type = response.headers.get("Content-Type", "")
+    charset: Optional[str] = None
+    try:
+      charset = response.headers.get_content_charset()  # type: ignore[attr-defined]
+    except Exception:  # pragma: no cover - very old Python versions only
+      charset = None
+    data = response.read()
+
+  encoding = charset or "utf-8"
+  text = data.decode(encoding, errors="replace")
+  if "html" in content_type.lower():
+    return _html_to_text(text)
+  return text
+
+
+__all__ = ["fetch_url_text"]
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"


thinking
**Preparing to extract code snippet with line numbers**
exec
bash -lc 'nl -ba src/simple_rag_writer/runner/url_fetcher.py' in /var/home/rick/Development/llm_writer succeeded in 38ms:
     1	from __future__ import annotations
     2	
     3	from html.parser import HTMLParser
     4	from pathlib import Path
     5	from typing import Optional
     6	from urllib.parse import unquote, urlparse
     7	from urllib.request import Request, url2pathname, urlopen
     8	
     9	DEFAULT_USER_AGENT = "simple-rag-writer/0.1"
    10	
    11	
    12	class _HTMLToTextParser(HTMLParser):
    13	  def __init__(self) -> None:
    14	    super().__init__()
    15	    self._parts: list[str] = []
    16	    self._skip_depth = 0
    17	
    18	  def handle_starttag(self, tag: str, attrs):  # type: ignore[override]
    19	    lowered = tag.lower()
    20	    if lowered in {"br", "p", "div", "section", "article", "li", "tr"}:
file update:
diff --git a/src/simple_rag_writer/runner/run_tasks.py b/src/simple_rag_writer/runner/run_tasks.py
index 0141e4ccf4ea65806dee82d72114784e6b1c8b7b..d9fa29487a87ab4f79ef8dbcba52e97c779860b3
--- a/src/simple_rag_writer/runner/run_tasks.py
+++ b/src/simple_rag_writer/runner/run_tasks.py
@@ -2,18 +2,25 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import List
+from typing import List, Optional
 
 from rich.console import Console
 
-from simple_rag_writer.config.models import AppConfig
+from simple_rag_writer.config.models import AppConfig, RawCappedPolicy, SummaryPolicy
 from simple_rag_writer.llm.registry import ModelRegistry
-from simple_rag_writer.tasks.loader import load_task, expand_task_paths
 from simple_rag_writer.mcp.client import McpClient
 from simple_rag_writer.mcp.normalization import normalize_payload
+from simple_rag_writer.mcp.types import NormalizedItem
 from simple_rag_writer.prompts.task_prompt import build_task_prompt
+from simple_rag_writer.runner.url_fetcher import fetch_url_text
+from simple_rag_writer.tasks.loader import expand_task_paths, load_task
+from simple_rag_writer.tasks.models import McpReference, ReferenceCommon, UrlReference
 
 console = Console()
+DEFAULT_SUMMARY_PROMPT = (
+  "Summarize the following reference material into key bullet points, highlighting"
+  " actionable facts and important context."
+)
 
 
 @dataclass
@@ -22,6 +29,122 @@
   failed_tasks: List[str]
 
 
+def _format_item(item: NormalizedItem) -> str:
+  parts: List[str] = []
+  if item.title:
+    parts.append(f"Title: {item.title}")
+  if item.url:
+    parts.append(f"URL: {item.url}")
+  body = (item.body or item.snippet or "").strip()
+  if body:
+    parts.append(body)
+  elif item.metadata:
+    parts.append(str(item.metadata))
+  return "\n".join(parts).strip()
+
+
+def _render_raw_blob(reference: ReferenceCommon, items: List[NormalizedItem], policy: RawCappedPolicy) -> Optional[str]:
+  if not items:
+    return None
+  per_item_limit = reference.max_chars or policy.max_chars_per_item
+  total_limit = policy.max_total_chars
+  max_items = reference.max_items or policy.max_items_per_reference
+  chunks: List[str] = []
+  used = 0
+  for item in items[:max_items]:
+    formatted = _format_item(item)
+    if not formatted:
+      continue
+    snippet = formatted[:per_item_limit].strip()
+    if not snippet:
+      continue
+    if used + len(snippet) > total_limit:
+      remaining = total_limit - used
+      if remaining <= 0:
+        break
+      snippet = snippet[:remaining].rstrip()
+    chunks.append(snippet)
+    used += len(snippet)
+    if used >= total_limit:
+      break
+  if not chunks:
+    return None
+  return "\n\n".join(chunks)
+
+
+def _build_summary_prompt(reference: ReferenceCommon, items: List[NormalizedItem], policy: SummaryPolicy) -> str:
+  ref_type = reference.item_type or next((itm.type for itm in items if itm.type), None)
+  template = None
+  if ref_type:
+    template = policy.per_type_prompts.get(ref_type)
+  if not template:
+    template = policy.default_prompt or DEFAULT_SUMMARY_PROMPT
+  sections: List[str] = []
+  for idx, item in enumerate(items, start=1):
+    heading = item.title or f"Item {idx}"
+    body = (item.body or item.snippet or "").strip()
+    lines = [f"## {heading}"]
+    if body:
+      lines.append(body)
+    if item.url:
+      lines.append(f"Source: {item.url}")
+    sections.append("\n".join(lines).strip())
+  body_text = "\n\n".join(sections)
+  return f"{template.strip()}\n\n{body_text}".strip()
+
+
+def _render_summary_blob(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  policy: SummaryPolicy,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  if not items:
+    return None
+  max_items = reference.max_items or policy.max_items_per_reference
+  limited = items[:max_items]
+  prompt = _build_summary_prompt(reference, limited, policy)
+  max_tokens = reference.summary_max_tokens or policy.summary_max_tokens
+  summary = registry.complete(
+    prompt,
+    model_id=policy.summarizer_model,
+    task_params={"max_tokens": max_tokens},
+  )
+  return summary.strip() or None
+
+
+def _apply_prompt_policy(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  config: AppConfig,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  mode = reference.prompt_mode or config.mcp_prompt_policy.default_mode
+  if mode == "summary":
+    return _render_summary_blob(reference, items, config.mcp_prompt_policy.summary, registry)
+  return _render_raw_blob(reference, items, config.mcp_prompt_policy.raw_capped)
+
+
+def _wrap_reference_label(reference: ReferenceCommon, text: Optional[str]) -> Optional[str]:
+  if not text:
+    return None
+  if reference.label:
+    return f"{reference.label}\n{text}"
+  return text
+
+
+def _url_items(reference: UrlReference, text: str) -> List[NormalizedItem]:
+  return [
+    NormalizedItem(
+      id=reference.url,
+      type=reference.item_type or "url",
+      title=reference.label or reference.url,
+      body=text.strip(),
+      url=reference.url,
+    )
+  ]
+
+
 def run_tasks_for_paths(
   config: AppConfig,
   registry: ModelRegistry,
@@ -41,7 +164,7 @@
       outline_context = None  # TODO: outline loading
 
       for ref in task.references:
-        if ref.type == "mcp":
+        if isinstance(ref, McpReference):
           try:
             result = client.call_tool(ref.server, ref.tool, ref.params)
           except Exception as exc:  # noqa: BLE001
@@ -50,15 +173,26 @@
               raise
             console.print(f"[yellow]MCP error (skipping reference): {exc}[/yellow]")
             continue
-
           items = normalize_payload(result.payload, item_type_hint=ref.item_type)
-          blob = "\n\n".join(
-            [
-              f"Title: {itm.title or ''}\n{itm.body or itm.snippet or ''}"
-              for itm in items
-            ]
-          )
-          reference_blobs.append(blob)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
+        elif isinstance(ref, UrlReference):
+          try:
+            fetched = fetch_url_text(ref.url)
+          except Exception as exc:  # noqa: BLE001
+            console.print(
+              f"[yellow]Failed to fetch URL {ref.url}: {exc}[/yellow]"
+            )
+            continue
+          if not fetched.strip():
+            continue
+          items = _url_items(ref, fetched)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
 
       prompt = build_task_prompt(task, outline_context, reference_blobs)
 
diff --git a/src/simple_rag_writer/runner/url_fetcher.py b/src/simple_rag_writer/runner/url_fetcher.py
new file mode 100644
index 0000000000000000000000000000000000000000..00abbf5049f05fcbcf0b5805378d5032ed50e20c
--- /dev/null
+++ b/src/simple_rag_writer/runner/url_fetcher.py
@@ -0,0 +1,90 @@
+from __future__ import annotations
+
+from html.parser import HTMLParser
+from pathlib import Path
+from typing import Optional
+from urllib.parse import unquote, urlparse
+from urllib.request import Request, url2pathname, urlopen
+
+DEFAULT_USER_AGENT = "simple-rag-writer/0.1"
+
+
+class _HTMLToTextParser(HTMLParser):
+  def __init__(self) -> None:
+    super().__init__()
+    self._parts: list[str] = []
+    self._skip_depth = 0
+
+  def handle_starttag(self, tag: str, attrs):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"br", "p", "div", "section", "article", "li", "tr"}:
+      self._parts.append("\n")
+    if lowered in {"script", "style"}:
+      self._skip_depth += 1
+
+  def handle_endtag(self, tag: str):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"script", "style"} and self._skip_depth:
+      self._skip_depth -= 1
+    elif lowered in {"p", "div", "section", "article", "li"}:
+      self._parts.append("\n")
+
+  def handle_data(self, data: str):  # type: ignore[override]
+    if self._skip_depth:
+      return
+    if data.strip():
+      self._parts.append(data)
+
+  def get_text(self) -> str:
+    raw = "".join(self._parts)
+    lines = [line.strip() for line in raw.splitlines()]
+    filtered = "\n".join(line for line in lines if line)
+    return filtered.strip()
+
+
+def _extract_file_path(url: str) -> Path:
+  parsed = urlparse(url)
+  path = unquote(parsed.path or "")
+  if parsed.netloc:
+    path = f"//{parsed.netloc}{path}"
+  fs_path = Path(url2pathname(path))
+  return fs_path
+
+
+def _html_to_text(html: str) -> str:
+  parser = _HTMLToTextParser()
+  parser.feed(html)
+  parser.close()
+  text = parser.get_text()
+  return text or html
+
+
+def fetch_url_text(url: str, *, timeout: float = 15.0) -> str:
+  parsed = urlparse(url)
+  scheme = (parsed.scheme or "").lower()
+
+  if scheme in {"", "file"}:
+    path = _extract_file_path(url)
+    return path.read_text(encoding="utf-8")
+
+  if scheme not in {"http", "https"}:
+    raise ValueError(f"Unsupported URL scheme: {parsed.scheme or 'unknown'}")
+
+  request = Request(url, headers={"User-Agent": DEFAULT_USER_AGENT})
+  with urlopen(request, timeout=timeout) as response:  # nosec: B310 in controlled use
+    content_type = response.headers.get("Content-Type", "")
+    charset: Optional[str] = None
+    try:
+      charset = response.headers.get_content_charset()  # type: ignore[attr-defined]
+    except Exception:  # pragma: no cover - very old Python versions only
+      charset = None
+    data = response.read()
+
+  encoding = charset or "utf-8"
+  text = data.decode(encoding, errors="replace")
+  if "html" in content_type.lower():
+    return _html_to_text(text)
+  return text
+
+
+__all__ = ["fetch_url_text"]
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"


thinking
**Checking test file line numbers**
exec
bash -lc 'nl -ba tests/test_runner_run_tasks.py' in /var/home/rick/Development/llm_writer succeeded in 37ms:
     1	from __future__ import annotations
     2	
     3	from io import StringIO
     4	from pathlib import Path
     5	from textwrap import dedent
     6	
     7	from rich.console import Console
     8	
     9	from simple_rag_writer.config.models import (
    10	  AppConfig,
    11	  McpPromptPolicy,
    12	  ModelConfig,
    13	  ProviderConfig,
    14	  RawCappedPolicy,
    15	  SummaryPolicy,
    16	)
    17	from simple_rag_writer.mcp.types import McpToolResult
    18	from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
    19	
    20	
file update:
diff --git a/src/simple_rag_writer/runner/run_tasks.py b/src/simple_rag_writer/runner/run_tasks.py
index 0141e4ccf4ea65806dee82d72114784e6b1c8b7b..d9fa29487a87ab4f79ef8dbcba52e97c779860b3
--- a/src/simple_rag_writer/runner/run_tasks.py
+++ b/src/simple_rag_writer/runner/run_tasks.py
@@ -2,18 +2,25 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import List
+from typing import List, Optional
 
 from rich.console import Console
 
-from simple_rag_writer.config.models import AppConfig
+from simple_rag_writer.config.models import AppConfig, RawCappedPolicy, SummaryPolicy
 from simple_rag_writer.llm.registry import ModelRegistry
-from simple_rag_writer.tasks.loader import load_task, expand_task_paths
 from simple_rag_writer.mcp.client import McpClient
 from simple_rag_writer.mcp.normalization import normalize_payload
+from simple_rag_writer.mcp.types import NormalizedItem
 from simple_rag_writer.prompts.task_prompt import build_task_prompt
+from simple_rag_writer.runner.url_fetcher import fetch_url_text
+from simple_rag_writer.tasks.loader import expand_task_paths, load_task
+from simple_rag_writer.tasks.models import McpReference, ReferenceCommon, UrlReference
 
 console = Console()
+DEFAULT_SUMMARY_PROMPT = (
+  "Summarize the following reference material into key bullet points, highlighting"
+  " actionable facts and important context."
+)
 
 
 @dataclass
@@ -22,6 +29,122 @@
   failed_tasks: List[str]
 
 
+def _format_item(item: NormalizedItem) -> str:
+  parts: List[str] = []
+  if item.title:
+    parts.append(f"Title: {item.title}")
+  if item.url:
+    parts.append(f"URL: {item.url}")
+  body = (item.body or item.snippet or "").strip()
+  if body:
+    parts.append(body)
+  elif item.metadata:
+    parts.append(str(item.metadata))
+  return "\n".join(parts).strip()
+
+
+def _render_raw_blob(reference: ReferenceCommon, items: List[NormalizedItem], policy: RawCappedPolicy) -> Optional[str]:
+  if not items:
+    return None
+  per_item_limit = reference.max_chars or policy.max_chars_per_item
+  total_limit = policy.max_total_chars
+  max_items = reference.max_items or policy.max_items_per_reference
+  chunks: List[str] = []
+  used = 0
+  for item in items[:max_items]:
+    formatted = _format_item(item)
+    if not formatted:
+      continue
+    snippet = formatted[:per_item_limit].strip()
+    if not snippet:
+      continue
+    if used + len(snippet) > total_limit:
+      remaining = total_limit - used
+      if remaining <= 0:
+        break
+      snippet = snippet[:remaining].rstrip()
+    chunks.append(snippet)
+    used += len(snippet)
+    if used >= total_limit:
+      break
+  if not chunks:
+    return None
+  return "\n\n".join(chunks)
+
+
+def _build_summary_prompt(reference: ReferenceCommon, items: List[NormalizedItem], policy: SummaryPolicy) -> str:
+  ref_type = reference.item_type or next((itm.type for itm in items if itm.type), None)
+  template = None
+  if ref_type:
+    template = policy.per_type_prompts.get(ref_type)
+  if not template:
+    template = policy.default_prompt or DEFAULT_SUMMARY_PROMPT
+  sections: List[str] = []
+  for idx, item in enumerate(items, start=1):
+    heading = item.title or f"Item {idx}"
+    body = (item.body or item.snippet or "").strip()
+    lines = [f"## {heading}"]
+    if body:
+      lines.append(body)
+    if item.url:
+      lines.append(f"Source: {item.url}")
+    sections.append("\n".join(lines).strip())
+  body_text = "\n\n".join(sections)
+  return f"{template.strip()}\n\n{body_text}".strip()
+
+
+def _render_summary_blob(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  policy: SummaryPolicy,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  if not items:
+    return None
+  max_items = reference.max_items or policy.max_items_per_reference
+  limited = items[:max_items]
+  prompt = _build_summary_prompt(reference, limited, policy)
+  max_tokens = reference.summary_max_tokens or policy.summary_max_tokens
+  summary = registry.complete(
+    prompt,
+    model_id=policy.summarizer_model,
+    task_params={"max_tokens": max_tokens},
+  )
+  return summary.strip() or None
+
+
+def _apply_prompt_policy(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  config: AppConfig,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  mode = reference.prompt_mode or config.mcp_prompt_policy.default_mode
+  if mode == "summary":
+    return _render_summary_blob(reference, items, config.mcp_prompt_policy.summary, registry)
+  return _render_raw_blob(reference, items, config.mcp_prompt_policy.raw_capped)
+
+
+def _wrap_reference_label(reference: ReferenceCommon, text: Optional[str]) -> Optional[str]:
+  if not text:
+    return None
+  if reference.label:
+    return f"{reference.label}\n{text}"
+  return text
+
+
+def _url_items(reference: UrlReference, text: str) -> List[NormalizedItem]:
+  return [
+    NormalizedItem(
+      id=reference.url,
+      type=reference.item_type or "url",
+      title=reference.label or reference.url,
+      body=text.strip(),
+      url=reference.url,
+    )
+  ]
+
+
 def run_tasks_for_paths(
   config: AppConfig,
   registry: ModelRegistry,
@@ -41,7 +164,7 @@
       outline_context = None  # TODO: outline loading
 
       for ref in task.references:
-        if ref.type == "mcp":
+        if isinstance(ref, McpReference):
           try:
             result = client.call_tool(ref.server, ref.tool, ref.params)
           except Exception as exc:  # noqa: BLE001
@@ -50,15 +173,26 @@
               raise
             console.print(f"[yellow]MCP error (skipping reference): {exc}[/yellow]")
             continue
-
           items = normalize_payload(result.payload, item_type_hint=ref.item_type)
-          blob = "\n\n".join(
-            [
-              f"Title: {itm.title or ''}\n{itm.body or itm.snippet or ''}"
-              for itm in items
-            ]
-          )
-          reference_blobs.append(blob)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
+        elif isinstance(ref, UrlReference):
+          try:
+            fetched = fetch_url_text(ref.url)
+          except Exception as exc:  # noqa: BLE001
+            console.print(
+              f"[yellow]Failed to fetch URL {ref.url}: {exc}[/yellow]"
+            )
+            continue
+          if not fetched.strip():
+            continue
+          items = _url_items(ref, fetched)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
 
       prompt = build_task_prompt(task, outline_context, reference_blobs)
 
diff --git a/src/simple_rag_writer/runner/url_fetcher.py b/src/simple_rag_writer/runner/url_fetcher.py
new file mode 100644
index 0000000000000000000000000000000000000000..00abbf5049f05fcbcf0b5805378d5032ed50e20c
--- /dev/null
+++ b/src/simple_rag_writer/runner/url_fetcher.py
@@ -0,0 +1,90 @@
+from __future__ import annotations
+
+from html.parser import HTMLParser
+from pathlib import Path
+from typing import Optional
+from urllib.parse import unquote, urlparse
+from urllib.request import Request, url2pathname, urlopen
+
+DEFAULT_USER_AGENT = "simple-rag-writer/0.1"
+
+
+class _HTMLToTextParser(HTMLParser):
+  def __init__(self) -> None:
+    super().__init__()
+    self._parts: list[str] = []
+    self._skip_depth = 0
+
+  def handle_starttag(self, tag: str, attrs):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"br", "p", "div", "section", "article", "li", "tr"}:
+      self._parts.append("\n")
+    if lowered in {"script", "style"}:
+      self._skip_depth += 1
+
+  def handle_endtag(self, tag: str):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"script", "style"} and self._skip_depth:
+      self._skip_depth -= 1
+    elif lowered in {"p", "div", "section", "article", "li"}:
+      self._parts.append("\n")
+
+  def handle_data(self, data: str):  # type: ignore[override]
+    if self._skip_depth:
+      return
+    if data.strip():
+      self._parts.append(data)
+
+  def get_text(self) -> str:
+    raw = "".join(self._parts)
+    lines = [line.strip() for line in raw.splitlines()]
+    filtered = "\n".join(line for line in lines if line)
+    return filtered.strip()
+
+
+def _extract_file_path(url: str) -> Path:
+  parsed = urlparse(url)
+  path = unquote(parsed.path or "")
+  if parsed.netloc:
+    path = f"//{parsed.netloc}{path}"
+  fs_path = Path(url2pathname(path))
+  return fs_path
+
+
+def _html_to_text(html: str) -> str:
+  parser = _HTMLToTextParser()
+  parser.feed(html)
+  parser.close()
+  text = parser.get_text()
+  return text or html
+
+
+def fetch_url_text(url: str, *, timeout: float = 15.0) -> str:
+  parsed = urlparse(url)
+  scheme = (parsed.scheme or "").lower()
+
+  if scheme in {"", "file"}:
+    path = _extract_file_path(url)
+    return path.read_text(encoding="utf-8")
+
+  if scheme not in {"http", "https"}:
+    raise ValueError(f"Unsupported URL scheme: {parsed.scheme or 'unknown'}")
+
+  request = Request(url, headers={"User-Agent": DEFAULT_USER_AGENT})
+  with urlopen(request, timeout=timeout) as response:  # nosec: B310 in controlled use
+    content_type = response.headers.get("Content-Type", "")
+    charset: Optional[str] = None
+    try:
+      charset = response.headers.get_content_charset()  # type: ignore[attr-defined]
+    except Exception:  # pragma: no cover - very old Python versions only
+      charset = None
+    data = response.read()
+
+  encoding = charset or "utf-8"
+  text = data.decode(encoding, errors="replace")
+  if "html" in content_type.lower():
+    return _html_to_text(text)
+  return text
+
+
+__all__ = ["fetch_url_text"]
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"


thinking
**Compiling detailed final report**

I'll provide a clear explanation of the automated runner orchestration, referencing specific file changes with line numbers, highlighting test results with pytest, and including the recommended commit message and modified files list to fulfill all reporting requirements thoroughly.
codex
Automated runner now orchestrates MCP and URL references via prompt policies before dispatching completions.

- Commit message: `feat: implement automated task runner orchestration`
- Modified files: `src/simple_rag_writer/runner/run_tasks.py`, `src/simple_rag_writer/runner/url_fetcher.py`, `tests/test_runner_run_tasks.py`
- `src/simple_rag_writer/runner/run_tasks.py:20-205` adds prompt-policy helpers, converts MCP + URL results into normalized blobs (raw-capped or summarized via the registry), honors per-reference limits, warns/skips on URL failures, and writes outputs after building task prompts with those blobs.
- `src/simple_rag_writer/runner/url_fetcher.py:12-87` introduces a lightweight fetcher supporting http(s)/file URLs and performing basic HTML-to-text extraction so URL references can be normalized without new heavy deps.
- `tests/test_runner_run_tasks.py:69-182` covers the happy-path URL inclusion (including summary calls) and warning-path error handling with monkeypatched fetchers, plus ensures written output stays intact.
- Tests: `pytest`
file update:
diff --git a/src/simple_rag_writer/runner/run_tasks.py b/src/simple_rag_writer/runner/run_tasks.py
index 0141e4ccf4ea65806dee82d72114784e6b1c8b7b..d9fa29487a87ab4f79ef8dbcba52e97c779860b3
--- a/src/simple_rag_writer/runner/run_tasks.py
+++ b/src/simple_rag_writer/runner/run_tasks.py
@@ -2,18 +2,25 @@
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import List
+from typing import List, Optional
 
 from rich.console import Console
 
-from simple_rag_writer.config.models import AppConfig
+from simple_rag_writer.config.models import AppConfig, RawCappedPolicy, SummaryPolicy
 from simple_rag_writer.llm.registry import ModelRegistry
-from simple_rag_writer.tasks.loader import load_task, expand_task_paths
 from simple_rag_writer.mcp.client import McpClient
 from simple_rag_writer.mcp.normalization import normalize_payload
+from simple_rag_writer.mcp.types import NormalizedItem
 from simple_rag_writer.prompts.task_prompt import build_task_prompt
+from simple_rag_writer.runner.url_fetcher import fetch_url_text
+from simple_rag_writer.tasks.loader import expand_task_paths, load_task
+from simple_rag_writer.tasks.models import McpReference, ReferenceCommon, UrlReference
 
 console = Console()
+DEFAULT_SUMMARY_PROMPT = (
+  "Summarize the following reference material into key bullet points, highlighting"
+  " actionable facts and important context."
+)
 
 
 @dataclass
@@ -22,6 +29,122 @@
   failed_tasks: List[str]
 
 
+def _format_item(item: NormalizedItem) -> str:
+  parts: List[str] = []
+  if item.title:
+    parts.append(f"Title: {item.title}")
+  if item.url:
+    parts.append(f"URL: {item.url}")
+  body = (item.body or item.snippet or "").strip()
+  if body:
+    parts.append(body)
+  elif item.metadata:
+    parts.append(str(item.metadata))
+  return "\n".join(parts).strip()
+
+
+def _render_raw_blob(reference: ReferenceCommon, items: List[NormalizedItem], policy: RawCappedPolicy) -> Optional[str]:
+  if not items:
+    return None
+  per_item_limit = reference.max_chars or policy.max_chars_per_item
+  total_limit = policy.max_total_chars
+  max_items = reference.max_items or policy.max_items_per_reference
+  chunks: List[str] = []
+  used = 0
+  for item in items[:max_items]:
+    formatted = _format_item(item)
+    if not formatted:
+      continue
+    snippet = formatted[:per_item_limit].strip()
+    if not snippet:
+      continue
+    if used + len(snippet) > total_limit:
+      remaining = total_limit - used
+      if remaining <= 0:
+        break
+      snippet = snippet[:remaining].rstrip()
+    chunks.append(snippet)
+    used += len(snippet)
+    if used >= total_limit:
+      break
+  if not chunks:
+    return None
+  return "\n\n".join(chunks)
+
+
+def _build_summary_prompt(reference: ReferenceCommon, items: List[NormalizedItem], policy: SummaryPolicy) -> str:
+  ref_type = reference.item_type or next((itm.type for itm in items if itm.type), None)
+  template = None
+  if ref_type:
+    template = policy.per_type_prompts.get(ref_type)
+  if not template:
+    template = policy.default_prompt or DEFAULT_SUMMARY_PROMPT
+  sections: List[str] = []
+  for idx, item in enumerate(items, start=1):
+    heading = item.title or f"Item {idx}"
+    body = (item.body or item.snippet or "").strip()
+    lines = [f"## {heading}"]
+    if body:
+      lines.append(body)
+    if item.url:
+      lines.append(f"Source: {item.url}")
+    sections.append("\n".join(lines).strip())
+  body_text = "\n\n".join(sections)
+  return f"{template.strip()}\n\n{body_text}".strip()
+
+
+def _render_summary_blob(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  policy: SummaryPolicy,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  if not items:
+    return None
+  max_items = reference.max_items or policy.max_items_per_reference
+  limited = items[:max_items]
+  prompt = _build_summary_prompt(reference, limited, policy)
+  max_tokens = reference.summary_max_tokens or policy.summary_max_tokens
+  summary = registry.complete(
+    prompt,
+    model_id=policy.summarizer_model,
+    task_params={"max_tokens": max_tokens},
+  )
+  return summary.strip() or None
+
+
+def _apply_prompt_policy(
+  reference: ReferenceCommon,
+  items: List[NormalizedItem],
+  config: AppConfig,
+  registry: ModelRegistry,
+) -> Optional[str]:
+  mode = reference.prompt_mode or config.mcp_prompt_policy.default_mode
+  if mode == "summary":
+    return _render_summary_blob(reference, items, config.mcp_prompt_policy.summary, registry)
+  return _render_raw_blob(reference, items, config.mcp_prompt_policy.raw_capped)
+
+
+def _wrap_reference_label(reference: ReferenceCommon, text: Optional[str]) -> Optional[str]:
+  if not text:
+    return None
+  if reference.label:
+    return f"{reference.label}\n{text}"
+  return text
+
+
+def _url_items(reference: UrlReference, text: str) -> List[NormalizedItem]:
+  return [
+    NormalizedItem(
+      id=reference.url,
+      type=reference.item_type or "url",
+      title=reference.label or reference.url,
+      body=text.strip(),
+      url=reference.url,
+    )
+  ]
+
+
 def run_tasks_for_paths(
   config: AppConfig,
   registry: ModelRegistry,
@@ -41,7 +164,7 @@
       outline_context = None  # TODO: outline loading
 
       for ref in task.references:
-        if ref.type == "mcp":
+        if isinstance(ref, McpReference):
           try:
             result = client.call_tool(ref.server, ref.tool, ref.params)
           except Exception as exc:  # noqa: BLE001
@@ -50,15 +173,26 @@
               raise
             console.print(f"[yellow]MCP error (skipping reference): {exc}[/yellow]")
             continue
-
           items = normalize_payload(result.payload, item_type_hint=ref.item_type)
-          blob = "\n\n".join(
-            [
-              f"Title: {itm.title or ''}\n{itm.body or itm.snippet or ''}"
-              for itm in items
-            ]
-          )
-          reference_blobs.append(blob)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
+        elif isinstance(ref, UrlReference):
+          try:
+            fetched = fetch_url_text(ref.url)
+          except Exception as exc:  # noqa: BLE001
+            console.print(
+              f"[yellow]Failed to fetch URL {ref.url}: {exc}[/yellow]"
+            )
+            continue
+          if not fetched.strip():
+            continue
+          items = _url_items(ref, fetched)
+          blob = _apply_prompt_policy(ref, items, config, registry)
+          wrapped = _wrap_reference_label(ref, blob)
+          if wrapped:
+            reference_blobs.append(wrapped)
 
       prompt = build_task_prompt(task, outline_context, reference_blobs)
 
diff --git a/src/simple_rag_writer/runner/url_fetcher.py b/src/simple_rag_writer/runner/url_fetcher.py
new file mode 100644
index 0000000000000000000000000000000000000000..00abbf5049f05fcbcf0b5805378d5032ed50e20c
--- /dev/null
+++ b/src/simple_rag_writer/runner/url_fetcher.py
@@ -0,0 +1,90 @@
+from __future__ import annotations
+
+from html.parser import HTMLParser
+from pathlib import Path
+from typing import Optional
+from urllib.parse import unquote, urlparse
+from urllib.request import Request, url2pathname, urlopen
+
+DEFAULT_USER_AGENT = "simple-rag-writer/0.1"
+
+
+class _HTMLToTextParser(HTMLParser):
+  def __init__(self) -> None:
+    super().__init__()
+    self._parts: list[str] = []
+    self._skip_depth = 0
+
+  def handle_starttag(self, tag: str, attrs):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"br", "p", "div", "section", "article", "li", "tr"}:
+      self._parts.append("\n")
+    if lowered in {"script", "style"}:
+      self._skip_depth += 1
+
+  def handle_endtag(self, tag: str):  # type: ignore[override]
+    lowered = tag.lower()
+    if lowered in {"script", "style"} and self._skip_depth:
+      self._skip_depth -= 1
+    elif lowered in {"p", "div", "section", "article", "li"}:
+      self._parts.append("\n")
+
+  def handle_data(self, data: str):  # type: ignore[override]
+    if self._skip_depth:
+      return
+    if data.strip():
+      self._parts.append(data)
+
+  def get_text(self) -> str:
+    raw = "".join(self._parts)
+    lines = [line.strip() for line in raw.splitlines()]
+    filtered = "\n".join(line for line in lines if line)
+    return filtered.strip()
+
+
+def _extract_file_path(url: str) -> Path:
+  parsed = urlparse(url)
+  path = unquote(parsed.path or "")
+  if parsed.netloc:
+    path = f"//{parsed.netloc}{path}"
+  fs_path = Path(url2pathname(path))
+  return fs_path
+
+
+def _html_to_text(html: str) -> str:
+  parser = _HTMLToTextParser()
+  parser.feed(html)
+  parser.close()
+  text = parser.get_text()
+  return text or html
+
+
+def fetch_url_text(url: str, *, timeout: float = 15.0) -> str:
+  parsed = urlparse(url)
+  scheme = (parsed.scheme or "").lower()
+
+  if scheme in {"", "file"}:
+    path = _extract_file_path(url)
+    return path.read_text(encoding="utf-8")
+
+  if scheme not in {"http", "https"}:
+    raise ValueError(f"Unsupported URL scheme: {parsed.scheme or 'unknown'}")
+
+  request = Request(url, headers={"User-Agent": DEFAULT_USER_AGENT})
+  with urlopen(request, timeout=timeout) as response:  # nosec: B310 in controlled use
+    content_type = response.headers.get("Content-Type", "")
+    charset: Optional[str] = None
+    try:
+      charset = response.headers.get_content_charset()  # type: ignore[attr-defined]
+    except Exception:  # pragma: no cover - very old Python versions only
+      charset = None
+    data = response.read()
+
+  encoding = charset or "utf-8"
+  text = data.decode(encoding, errors="replace")
+  if "html" in content_type.lower():
+    return _html_to_text(text)
+  return text
+
+
+__all__ = ["fetch_url_text"]
diff --git a/tests/test_runner_run_tasks.py b/tests/test_runner_run_tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..ef698a31398c194a386e8f8af983e4376d2867c5
--- /dev/null
+++ b/tests/test_runner_run_tasks.py
@@ -0,0 +1,182 @@
+from __future__ import annotations
+
+from io import StringIO
+from pathlib import Path
+from textwrap import dedent
+
+from rich.console import Console
+
+from simple_rag_writer.config.models import (
+  AppConfig,
+  McpPromptPolicy,
+  ModelConfig,
+  ProviderConfig,
+  RawCappedPolicy,
+  SummaryPolicy,
+)
+from simple_rag_writer.mcp.types import McpToolResult
+from simple_rag_writer.runner.run_tasks import run_tasks_for_paths
+
+
+class DummyRegistry:
+  def __init__(self) -> None:
+    self.calls = []
+
+  def complete(self, prompt: str, model_id: str | None = None, task_params=None) -> str:
+    call = {
+      "prompt": prompt,
+      "model_id": model_id,
+      "task_params": task_params,
+    }
+    self.calls.append(call)
+    if model_id == "summary-model":
+      return "URL SUMMARY"
+    return "FINAL OUTPUT"
+
+
+def _make_config() -> AppConfig:
+  return AppConfig(
+    default_model="writer-model",
+    providers={
+      "local": ProviderConfig(type="openai", api_key="dummy"),
+    },
+    models=[
+      ModelConfig(id="writer-model", provider="local", model_name="writer"),
+      ModelConfig(id="summary-model", provider="local", model_name="summary"),
+    ],
+    mcp_prompt_policy=McpPromptPolicy(
+      default_mode="raw_capped",
+      raw_capped=RawCappedPolicy(
+        max_items_per_reference=5,
+        max_chars_per_item=200,
+        max_total_chars=2000,
+      ),
+      summary=SummaryPolicy(
+        summarizer_model="summary-model",
+        default_prompt="Summarize the material.",
+        summary_max_tokens=128,
+      ),
+    ),
+  )
+
+
+def _write_task(tmp_path: Path, body: str) -> Path:
+  path = tmp_path / "task.yaml"
+  path.write_text(dedent(body), encoding="utf-8")
+  return path
+
+
+def test_run_tasks_includes_url_reference_text(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      self.calls = []
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      self.calls.append((server, tool, params))
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[
+          {
+            "title": "Notebook entry",
+            "body": "Alpha body",
+          }
+        ],
+      )
+
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: "URL page text for " + url,
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+        prompt_mode: "summary"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 2
+  summary_call, final_call = registry.calls
+  assert summary_call["model_id"] == "summary-model"
+  assert "URL page text" in summary_call["prompt"]
+  assert final_call["model_id"] == "writer-model"
+  assert "URL SUMMARY" in final_call["prompt"]
+  assert "Notebook entry" in final_call["prompt"]
+  assert output_path.exists()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"
+
+
+def test_run_tasks_warns_and_continues_on_url_error(tmp_path, monkeypatch):
+  config = _make_config()
+  registry = DummyRegistry()
+
+  class FakeMcpClient:
+    def __init__(self, _config):
+      pass
+
+    def call_tool(self, server: str, tool: str, params: dict) -> McpToolResult:
+      return McpToolResult(
+        server_id=server,
+        tool_name=tool,
+        payload=[{"title": "Doc", "body": "Reference body"}],
+      )
+
+  console_output = StringIO()
+  monkeypatch.setattr("simple_rag_writer.runner.run_tasks.McpClient", FakeMcpClient)
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.fetch_url_text",
+    lambda url: (_ for _ in ()).throw(RuntimeError("boom")),
+  )
+  monkeypatch.setattr(
+    "simple_rag_writer.runner.run_tasks.console",
+    Console(file=console_output, force_terminal=False, color_system=None),
+  )
+
+  output_path = tmp_path / "drafts" / "chapter.md"
+  task_path = _write_task(
+    tmp_path,
+    f"""
+    title: "Chapter"
+    id: "ch01"
+    description: "Write the chapter"
+    output: "{output_path}"
+    references:
+      - type: "url"
+        label: "Spec"
+        url: "https://example.com/spec"
+      - type: "mcp"
+        label: "Notes"
+        server: "notes"
+        tool: "search"
+    """,
+  )
+
+  result = run_tasks_for_paths(config, registry, [task_path])
+
+  assert result.ok is True
+  assert len(registry.calls) == 1
+  assert "Reference body" in registry.calls[0]["prompt"]
+  log_text = console_output.getvalue()
+  assert "URL" in log_text and "failed" in log_text.lower()
+  assert output_path.read_text(encoding="utf-8") == "FINAL OUTPUT"

tokens used
89,409
Automated runner now orchestrates MCP and URL references via prompt policies before dispatching completions.

- Commit message: `feat: implement automated task runner orchestration`
- Modified files: `src/simple_rag_writer/runner/run_tasks.py`, `src/simple_rag_writer/runner/url_fetcher.py`, `tests/test_runner_run_tasks.py`
- `src/simple_rag_writer/runner/run_tasks.py:20-205` adds prompt-policy helpers, converts MCP + URL results into normalized blobs (raw-capped or summarized via the registry), honors per-reference limits, warns/skips on URL failures, and writes outputs after building task prompts with those blobs.
- `src/simple_rag_writer/runner/url_fetcher.py:12-87` introduces a lightweight fetcher supporting http(s)/file URLs and performing basic HTML-to-text extraction so URL references can be normalized without new heavy deps.
- `tests/test_runner_run_tasks.py:69-182` covers the happy-path URL inclusion (including summary calls) and warning-path error handling with monkeypatched fetchers, plus ensures written output stays intact.
- Tests: `pytest`
